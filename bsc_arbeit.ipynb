{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0esqvQHT2922"
   },
   "source": [
    "# First: load imports needed for the project and preparation of the project"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# This cell is necessary to use this notebook in google colab\n",
    "# If you are running this notebook in colab, please change colab to True\n",
    "\n",
    "import os\n",
    "\n",
    "colab = False\n",
    "cwd = os.getcwd()\n",
    "\n",
    "if colab is True and cwd != \"/content/Bsc_Thesis\":\n",
    "  ! git clone https://github.com/SergioTallo/Bsc_Thesis.git\n",
    "  % cd Bsc_Thesis\n",
    "\n",
    "print(cwd)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adt0VN_ojbV1",
    "outputId": "2db902f0-c1ac-47f9-9ea4-1f79506088d8"
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sergiotallotorres/PycharmProjects/Bsc_Thesis\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "VCwEuYFk2923",
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "47f84156-c512-450f-ea37-5d4afb8251d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: CPU\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils_bsc\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "  print('Device: GPU =', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('Device: CPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQPvc4I-4LY5",
    "outputId": "5914f428-27b6-46a3-e72f-ec3574c78d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versions of packages:\n",
      "Python: 3.9.2\n",
      "Pandas: 1.3.3\n",
      "Numpy: 1.20.3\n",
      "PyTorch: 1.10.0\n",
      "Sklearn: 1.0\n"
     ]
    }
   ],
   "source": [
    "utils_bsc.print_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICcfWNfajDhn"
   },
   "source": [
    "# Data loading and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "bjUFrMX32925"
   },
   "source": [
    "Now, we should create a dataset with all the data stored in the .csv file\n",
    "\n",
    "Description of the data:\n",
    "\n",
    "*   time: Timestamp (YYYY-MM-DD HH:MM:SS)\n",
    "*   PLN1: Power in the phase 1 (W)\n",
    "*   PLN2: Power in the phase 2 (W)\n",
    "*   PLN3: Power in the phase 3 (W)\n",
    "*   ULL1: Current Voltage between 2 phases (V)\n",
    "*   ULL2: Current Voltage between 2 phases (V)\n",
    "*   ULL3: Current Voltage between 2 phases (V)\n",
    "*   COS_PHI1: Phase shift (Cos)\n",
    "*   COS_PHI2: Phase shift (Cos)\n",
    "*   COS_PHI3: Phase shift (Cos)\n",
    "*   FREQ: Electricity Frequency (Hz)\n",
    "*   RC_DC: Fault currents\n",
    "*   RC_AC: Fault currents\n",
    "*   RC_50Hz: Fault currents\n",
    "*   RC_150Hz: Fault currents\n",
    "*   RC_<100Hz: Fault currents\n",
    "*   RC_100Hz-1kHz: Fault currents\n",
    "*   RC_>10kHz: Fault currents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "qIhc9bwK2926",
    "outputId": "42b2bd9b-47dd-4bef-8165-3b068741a330",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  time       PLN1      PLN2      PLN3      ULL1      ULL2  \\\n0  2020-06-01 00:00:00  1141.0819  519.5034  482.9381  398.8613  400.1982   \n1  2020-06-01 00:01:00  1145.1162  519.1807  491.4436  398.6934  400.1579   \n2  2020-06-01 00:02:00  1140.9558  743.3837  484.9942  398.4367  400.1205   \n3  2020-06-01 00:03:00  1151.9409  741.4836  487.4224  398.9800  400.4375   \n4  2020-06-01 00:04:00  1142.1594  741.9858  486.7629  398.7133  400.3145   \n\n       ULL3  COS_PHI1  COS_PHI2  COS_PHI3     FREQ  RC_DC  RC_AC  RC_50Hz  \\\n0  395.6010    0.8091    0.6864    0.4875  49.9927    4.0   91.0     10.0   \n1  395.5431    0.8080    0.6903    0.4904  49.9779    5.0   64.0      7.0   \n2  395.5259    0.8113    0.9274    0.4806  49.9782    4.0   64.0      7.0   \n3  395.8621    0.8249    0.9123    0.4778  49.9850    5.0   66.0      8.0   \n4  395.6446    0.8081    0.9291    0.4552  49.9856    4.0   85.0     11.0   \n\n   RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n0      39.0       36.0           86.0      82.0        7.0  \n1      27.0       25.0           60.0      55.0        2.0  \n2      27.0       25.0           60.0      55.0        2.0  \n3      28.0       25.0           61.0      57.0        2.0  \n4      45.0       41.0           75.0      68.0        6.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>PLN1</th>\n      <th>PLN2</th>\n      <th>PLN3</th>\n      <th>ULL1</th>\n      <th>ULL2</th>\n      <th>ULL3</th>\n      <th>COS_PHI1</th>\n      <th>COS_PHI2</th>\n      <th>COS_PHI3</th>\n      <th>FREQ</th>\n      <th>RC_DC</th>\n      <th>RC_AC</th>\n      <th>RC_50Hz</th>\n      <th>RC_150Hz</th>\n      <th>RC_&lt;100Hz</th>\n      <th>RC_100Hz-1kHz</th>\n      <th>RC_&gt;1kHz</th>\n      <th>RC_&gt;10kHz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-06-01 00:00:00</td>\n      <td>1141.0819</td>\n      <td>519.5034</td>\n      <td>482.9381</td>\n      <td>398.8613</td>\n      <td>400.1982</td>\n      <td>395.6010</td>\n      <td>0.8091</td>\n      <td>0.6864</td>\n      <td>0.4875</td>\n      <td>49.9927</td>\n      <td>4.0</td>\n      <td>91.0</td>\n      <td>10.0</td>\n      <td>39.0</td>\n      <td>36.0</td>\n      <td>86.0</td>\n      <td>82.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-06-01 00:01:00</td>\n      <td>1145.1162</td>\n      <td>519.1807</td>\n      <td>491.4436</td>\n      <td>398.6934</td>\n      <td>400.1579</td>\n      <td>395.5431</td>\n      <td>0.8080</td>\n      <td>0.6903</td>\n      <td>0.4904</td>\n      <td>49.9779</td>\n      <td>5.0</td>\n      <td>64.0</td>\n      <td>7.0</td>\n      <td>27.0</td>\n      <td>25.0</td>\n      <td>60.0</td>\n      <td>55.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-06-01 00:02:00</td>\n      <td>1140.9558</td>\n      <td>743.3837</td>\n      <td>484.9942</td>\n      <td>398.4367</td>\n      <td>400.1205</td>\n      <td>395.5259</td>\n      <td>0.8113</td>\n      <td>0.9274</td>\n      <td>0.4806</td>\n      <td>49.9782</td>\n      <td>4.0</td>\n      <td>64.0</td>\n      <td>7.0</td>\n      <td>27.0</td>\n      <td>25.0</td>\n      <td>60.0</td>\n      <td>55.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-06-01 00:03:00</td>\n      <td>1151.9409</td>\n      <td>741.4836</td>\n      <td>487.4224</td>\n      <td>398.9800</td>\n      <td>400.4375</td>\n      <td>395.8621</td>\n      <td>0.8249</td>\n      <td>0.9123</td>\n      <td>0.4778</td>\n      <td>49.9850</td>\n      <td>5.0</td>\n      <td>66.0</td>\n      <td>8.0</td>\n      <td>28.0</td>\n      <td>25.0</td>\n      <td>61.0</td>\n      <td>57.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-06-01 00:04:00</td>\n      <td>1142.1594</td>\n      <td>741.9858</td>\n      <td>486.7629</td>\n      <td>398.7133</td>\n      <td>400.3145</td>\n      <td>395.6446</td>\n      <td>0.8081</td>\n      <td>0.9291</td>\n      <td>0.4552</td>\n      <td>49.9856</td>\n      <td>4.0</td>\n      <td>85.0</td>\n      <td>11.0</td>\n      <td>45.0</td>\n      <td>41.0</td>\n      <td>75.0</td>\n      <td>68.0</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data_factory.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZAyQ-cA2926"
   },
   "source": [
    "Once we have the dataset, we should prepare it. Finding the missing or the NaN values and replace them with suitable values (in this case we use the previous value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNTHq6mO2927",
    "outputId": "65e42584-0761-43fe-a4dd-588f08ce6c07",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with NaN values before cleaning: 2546\n",
      "Number of rows with NaN values after cleaning: 0\n",
      "Total number of samples: 63360\n",
      "Number of features: 19\n"
     ]
    }
   ],
   "source": [
    "# Replace all mising values with NaN\n",
    "dataset = dataset.replace(' ', np.nan)\n",
    "# Search for all the rows with NaN values\n",
    "nan_values = dataset[dataset.isna().any(axis=1)]\n",
    "# Print the shape to know how many are there\n",
    "print(f'Number of rows with NaN values before cleaning: {nan_values.shape[0]}') \n",
    "\n",
    "# Fill all NaN values with the previous row value\n",
    "dataset_clean = dataset.fillna(method='ffill')\n",
    "\n",
    "# Check that there isn't any NaN values\n",
    "nan_values = dataset_clean[dataset_clean.isna().any(axis=1)]\n",
    "# Print the shape to know how many are there\n",
    "print(f'Number of rows with NaN values after cleaning: {nan_values.shape[0]}') \n",
    "\n",
    "#Total number of samples\n",
    "print(f'Total number of samples: {dataset_clean.shape[0]}')\n",
    "print(f'Number of features: {dataset_clean.shape[1]}')\n",
    "\n",
    "# Set to True to print the graphs\n",
    "print_graphs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d44xLGPbjDhp"
   },
   "source": [
    "# Distribution of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6R7YF-T2928"
   },
   "source": [
    "Now we look at the distribution of the different features of the data over different time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "tQ0vhNNv2928",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if print_graphs is True:\n",
    "\n",
    "    # PLN_1 in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 1, 'PLN_1')\n",
    "\n",
    "    # PLN_1 in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 1, 'PLN_1')\n",
    "\n",
    "    # PLN_2 in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 2, 'PLN_2')\n",
    "\n",
    "    # PLN_2 in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 2, 'PLN_2')\n",
    "\n",
    "    # PLN_3 in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 3, 'PLN_3')\n",
    "\n",
    "    # PLN_3 in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 3, 'PLN_3')\n",
    "\n",
    "    # ULL1 in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 4, 'ULL1')\n",
    "\n",
    "    # ULL1 in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 4, 'ULL1')\n",
    "\n",
    "    # ULL2 in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 5, 'ULL2')\n",
    "\n",
    "    # ULL2 in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 5, 'ULL2')\n",
    "\n",
    "    # ULL3 in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 6, 'ULL3')\n",
    "\n",
    "    # ULL3 in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 6, 'ULL3')\n",
    "\n",
    "    # COS_PHI1 in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 7, 'COS_PHI1')\n",
    "\n",
    "    # COS_PHI1 in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 7, 'COS_PHI1')\n",
    "\n",
    "    # COS_PHI2 in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 8, 'COS_PHI2')\n",
    "\n",
    "    # COS_PHI2 in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 8, 'COS_PHI2')\n",
    "\n",
    "    # COS_PHI3 in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 9, 'COS_PHI3')\n",
    "\n",
    "    # COS_PHI3 in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 9, 'COS_PHI3')\n",
    "\n",
    "    # FREQ in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 10, 'FREQ')\n",
    "\n",
    "    # FREQ in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 10, 'FREQ')\n",
    "\n",
    "    # RC_DC in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 11, 'RC_DC')\n",
    "\n",
    "    # RC_DC in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 11, 'RC_DC')\n",
    "\n",
    "    # RC_AC in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 12, 'RC_AC')\n",
    "\n",
    "    # RC_AC in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 12, 'RC_AC')\n",
    "\n",
    "    # RC_50Hz in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 13, 'RC_50Hz')\n",
    "\n",
    "    # RC_50Hz in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 13, 'RC_50Hz')\n",
    "\n",
    "    # RC_150Hz in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 14, 'RC_150Hz')\n",
    "\n",
    "    # RC_150Hz in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 14, 'RC_150Hz')\n",
    "\n",
    "    # RC_100Hz_1kHz in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 15, 'RC_100Hz_1kHz')\n",
    "\n",
    "    # RC_100Hz_1kHz in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 15, 'RC_100Hz_1kHz')\n",
    "\n",
    "    # RC_100Hz_1kHz in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 16, 'RC_100Hz_1kHz')\n",
    "\n",
    "    # RC_100Hz_1kHz in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 16, 'RC_100Hz_1kHz')\n",
    "\n",
    "    # RC_more_1kHz in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 17, 'RC_more_1kHz')\n",
    "\n",
    "    # RC_more_1kHz in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 17, 'RC_more_1kHz')\n",
    "\n",
    "    # RC_more_10kHz in a weekly interval\n",
    "\n",
    "    utils_bsc.week_plot(dataset_clean, 18, 'RC_more_10kHz')\n",
    "\n",
    "    # RC_more_10kHz in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "\n",
    "    utils_bsc.daily_plot(dataset_clean, 18, 'RC_more_10kHz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJeKUzS0jDhq"
   },
   "source": [
    "# Preparation Training and Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvocvIBA292-"
   },
   "source": [
    "Once the dataset is prepared, make batches of data,put them togheter in an array and split them into train and test sets.\n",
    "After looking through the dataset and the features, i decided to takeonly the values with a timestap of a weekday between 4:00 and 19:30. In many of the features in the interval otside those timestamps there i only noise, which can be a sign that the machine is off in that time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "M0CY804_292-",
    "scrolled": true,
    "outputId": "5bccce00-ef58-4d43-a05f-dca7398a1cb2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27840 sequences of longitud 60 with 18 features\n",
      "length of training set: 2784\n",
      "length of test set: 25056\n"
     ]
    }
   ],
   "source": [
    "# Create 27840 batches of longitud 60\n",
    "\n",
    "endset = utils_bsc.create_batches(dataset=dataset_clean, batch_size=60, device=device)\n",
    "    \n",
    "print(f'{len(endset)} sequences of longitud {endset[0].shape[0]} with {endset[0].shape[1]} features')\n",
    "\n",
    "# Spliting into train and test sets\n",
    "\n",
    "training_data, testing_data = train_test_split(endset, test_size=0.9, random_state=25)\n",
    "\n",
    "train_set = torch.stack(training_data).float().to(device)\n",
    "test_set = torch.stack(testing_data).float().to(device)\n",
    "\n",
    "print(f'length of training set: {train_set.shape[0]}')\n",
    "print(f'length of test set: {test_set.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXX8lu3jjDhr"
   },
   "source": [
    "# Model settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dUCsWWo292_"
   },
   "source": [
    "Now, we define a class with the transformer model that we are going to use:\n",
    "\n",
    "Using the already written pytorch library for Transformers:\n",
    "\n",
    "1) torch.nn.TransformerEncoderLayer\n",
    "\n",
    "*   d_model –> the number of expected features in the input (required).\n",
    "*   nhead –> the number of heads in the multiheadattention models (required).\n",
    "*   dropout –> the dropout value (default=0.1).\n",
    "*   activation –> the activation function of the intermediate layer, can be a string (“relu” or “gelu”) or a unary callable. (default: relu)\n",
    "*   layer_norm_eps –> the eps value in layer normalization components (default=1e-5).\n",
    "*   batch_first –> If True, then the input and output tensors are provided as (batch, seq, feature). (default: False)\n",
    "*   norm_first –> if True, layer norm is done prior to attention and feedforward operations, respectivaly. Otherwise it’s done after. (default: False (after))\n",
    "\n",
    "2) torch.nn.TransformerDecoderLayer\n",
    "\n",
    "* d_model –> the number of expected features in the input (required).\n",
    "* nhead –> the number of heads in the multiheadattention models (required).\n",
    "* dim_feedforward –> the dimension of the feedforward network model (default=2048).\n",
    "* dropout –> the dropout value (default=0.1).\n",
    "* activation –> the activation function of the intermediate layer, can be a string (“relu” or “gelu”) or a unary callable. Default: relu\n",
    "* layer_norm_eps –> the eps value in layer normalization components (default=1e-5).\n",
    "* batch_first –> If True, then the input and output tensors are provided as (batch, seq, feature). Default: False.\n",
    "* norm_first –> if True, layer norm is done prior to self attention, multihead attention and feedforward operations, respectivaly. Otherwise it’s done after. Default: False (after).\n",
    "\n",
    "3) torch.nn.TransformerEncoder\n",
    "\n",
    "* encoder_layer –> an instance of the TransformerEncoderLayer() class (required).\n",
    "* num_layers –> the number of sub-encoder-layers in the encoder (required).\n",
    "* norm –> the layer normalization component (optional).\n",
    "\n",
    "\n",
    "4) torch.nn.TransformerDecoder\n",
    "\n",
    "* decoder_layer – an instance of the TransformerDecoderLayer() class (required).\n",
    "* num_layers – the number of sub-decoder-layers in the decoder (required).\n",
    "* norm – the layer normalization component (optional).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tCC_Bava293A",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, feature_size, output_size, num_encoder_layers, num_heads, num_decoder_layers, device, debug: bool = False, dropout: float =0.1, batch_first: bool = False):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model= feature_size, nhead= num_heads, dropout=dropout, device=device, batch_first=batch_first)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model= feature_size, nhead= num_heads, dropout=dropout, device=device, batch_first=batch_first)\n",
    "        \n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers= num_encoder_layers)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers= num_decoder_layers)\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.device = device\n",
    "        self.debug = debug\n",
    "\n",
    "    def generate_square_mask(self, dim):\n",
    "        return torch.triu(torch.ones(dim, dim) * float('-inf'), diagonal=1).to(self.device)\n",
    "        \n",
    "    def forward (self, src):\n",
    "        mask = self.generate_square_mask(len(src[0]))\n",
    "        if self.debug is True:\n",
    "            print('mask creation: ok')\n",
    "        output = self.encoder (src, mask)\n",
    "        if self.debug is True:\n",
    "            print('encoder pass: ok')\n",
    "        output = self.decoder (src, output)\n",
    "        if self.debug is True:\n",
    "            print('decoder pass: ok')\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We should define an optimizer too.\n",
    "For this, we use the pytorch library:\n",
    "\n",
    "* SGD –> Stochastic gradient descent.\n",
    "\n",
    "1) torch.optim.SDG (https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)\n",
    "\n",
    "* params (iterable) – iterable of parameters to optimize or dicts defining parameter groups\n",
    "* lr (float) – learning rate\n",
    "* momentum (float, optional) – momentum factor (default: 0)\n",
    "* weight_decay (float, optional) – weight decay (L2 penalty) (default: 0)\n",
    "* dampening (float, optional) – dampening for momentum (default: 0)\n",
    "* nesterov (bool, optional) – enables Nesterov momentum (default: False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup model Ok\n",
      "Setup optimizer Ok\n",
      "First Forward pass Ok\n",
      "torch.Size([2784, 60, 18])\n",
      "torch.Size([2784, 60, 18])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/2s/vg97_p793_97vgjwtr42qdm80000gn/T/ipykernel_10466/38632317.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     36\u001B[0m     \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet_out\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mtrain_set\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m**\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m     \u001B[0mloss_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m     \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m     \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'step: '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    305\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    306\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 307\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    308\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    309\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    152\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 154\u001B[0;31m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[1;32m    155\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize Transformer Model and Optimizer\n",
    "\n",
    "model = Transformer (num_encoder_layers=1,\n",
    "                     num_decoder_layers=1,\n",
    "                     feature_size=18,\n",
    "                     output_size=18,\n",
    "                     num_heads=3,\n",
    "                     device = device,\n",
    "                     batch_first=True,\n",
    "                     debug=False)\n",
    "\n",
    "print('Setup model Ok')\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "print('Setup optimizer Ok')\n",
    "\n",
    "# List to keep track of the losses\n",
    "loss_list = []\n",
    "# Initialize optimizer gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "#Forward pass and calculate loss\n",
    "net_out = model.forward(train_set)\n",
    "\n",
    "print('First Forward pass Ok')\n",
    "\n",
    "print(net_out.shape)\n",
    "print(train_set.shape)\n",
    "\n",
    "#print(net_out.shape,Y.shape)\n",
    "loss = torch.mean((net_out - train_set) ** 2).to(device)\n",
    "\n",
    "for b in range(len(train_set)):\n",
    "    net_out = model.forward(train_set)\n",
    "    loss = torch.mean((net_out - train_set) ** 2).to(device)\n",
    "    loss_list.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('step: ', b)\n",
    "\n",
    "print(loss_list)\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Muhz9Q2qjDhs",
    "outputId": "36c091be-8e43-4c9d-cef4-9e907067ba68",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgrbFBLS293A",
    "scrolled": true,
    "outputId": "0d1b55c3-cf78-47af-e1e3-5e92db1b85b3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    }
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iS8DcLC-293B"
   },
   "source": [
    "Ideas, things to remember, to search, etc...\n",
    "\n",
    "reconstruction, vergelich mit base line model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "bsc_arbeit.ipynb",
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python392jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}