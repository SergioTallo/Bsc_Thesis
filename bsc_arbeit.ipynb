{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0esqvQHT2922"
      },
      "source": [
        "# First: load imports needed for the project and preparation of the project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is necessary to use this notebook in google colab\n",
        "# If you are running this notebook in colab, please change colab to True\n",
        "\n",
        "import os\n",
        "\n",
        "colab = True\n",
        "cwd = os.getcwd()\n",
        "\n",
        "if colab is True and cwd != \"/content/Bsc_Thesis\":\n",
        "  ! git clone https://github.com/SergioTallo/Bsc_Thesis.git\n",
        "  % cd Bsc_Thesis\n",
        "\n",
        "print(cwd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adt0VN_ojbV1",
        "outputId": "eaddf65e-11b6-4e37-c028-109a983f1e0a"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Bsc_Thesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "VCwEuYFk2923",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f871e6-e601-45e0-e8b4-7d27467443cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: GPU = Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "from torch import Tensor, float32, sin, cos\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import utils_bsc\n",
        "import datetime\n",
        "import statistics\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "  print('Device: GPU =', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print('Device: CPU')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQPvc4I-4LY5",
        "outputId": "81876f84-9a45-4330-d960-13693d5b3de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "versions of packages:\n",
            "Python: 3.7.13\n",
            "Pandas: 1.3.5\n",
            "Numpy: 1.21.5\n",
            "PyTorch: 1.10.0+cu111\n",
            "Sklearn: 1.0.2\n",
            "seaborn: 0.11.2\n"
          ]
        }
      ],
      "source": [
        "utils_bsc.print_versions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICcfWNfajDhn"
      },
      "source": [
        "# Data loading and preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "bjUFrMX32925"
      },
      "source": [
        "Now, we should create a dataset with all the data stored in the .csv file\n",
        "\n",
        "Description of the data:\n",
        "\n",
        "*   time: Timestamp (YYYY-MM-DD HH:MM:SS)\n",
        "*   PLN1: Power in the phase 1 (W)\n",
        "*   PLN2: Power in the phase 2 (W)\n",
        "*   PLN3: Power in the phase 3 (W)\n",
        "*   ULL1: Current Voltage between 2 phases (V)\n",
        "*   ULL2: Current Voltage between 2 phases (V)\n",
        "*   ULL3: Current Voltage between 2 phases (V)\n",
        "*   COS_PHI1: Phase shift (Cos)\n",
        "*   COS_PHI2: Phase shift (Cos)\n",
        "*   COS_PHI3: Phase shift (Cos)\n",
        "*   FREQ: Electricity Frequency (Hz)\n",
        "*   RC_DC: Fault currents\n",
        "*   RC_AC: Fault currents\n",
        "*   RC_50Hz: Fault currents\n",
        "*   RC_150Hz: Fault currents\n",
        "*   RC_<100Hz: Fault currents\n",
        "*   RC_100Hz-1kHz: Fault currents\n",
        "*   RC_>10kHz: Fault currents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "qIhc9bwK2926",
        "outputId": "a900f11f-ccf7-4fb4-8c0c-7b2ed2e82a93",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  time       PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "0  2020-06-01 00:00:00  1141.0819  519.5034  482.9381  398.8613  400.1982   \n",
              "1  2020-06-01 00:01:00  1145.1162  519.1807  491.4436  398.6934  400.1579   \n",
              "2  2020-06-01 00:02:00  1140.9558  743.3837  484.9942  398.4367  400.1205   \n",
              "3  2020-06-01 00:03:00  1151.9409  741.4836  487.4224  398.9800  400.4375   \n",
              "4  2020-06-01 00:04:00  1142.1594  741.9858  486.7629  398.7133  400.3145   \n",
              "\n",
              "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3     FREQ  RC_DC  RC_AC  RC_50Hz  \\\n",
              "0  395.6010    0.8091    0.6864    0.4875  49.9927    4.0   91.0     10.0   \n",
              "1  395.5431    0.8080    0.6903    0.4904  49.9779    5.0   64.0      7.0   \n",
              "2  395.5259    0.8113    0.9274    0.4806  49.9782    4.0   64.0      7.0   \n",
              "3  395.8621    0.8249    0.9123    0.4778  49.9850    5.0   66.0      8.0   \n",
              "4  395.6446    0.8081    0.9291    0.4552  49.9856    4.0   85.0     11.0   \n",
              "\n",
              "   RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "0      39.0       36.0           86.0      82.0        7.0  \n",
              "1      27.0       25.0           60.0      55.0        2.0  \n",
              "2      27.0       25.0           60.0      55.0        2.0  \n",
              "3      28.0       25.0           61.0      57.0        2.0  \n",
              "4      45.0       41.0           75.0      68.0        6.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6b27129-d120-4bb4-8be9-f0e0f0801159\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-01 00:00:00</td>\n",
              "      <td>1141.0819</td>\n",
              "      <td>519.5034</td>\n",
              "      <td>482.9381</td>\n",
              "      <td>398.8613</td>\n",
              "      <td>400.1982</td>\n",
              "      <td>395.6010</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.6864</td>\n",
              "      <td>0.4875</td>\n",
              "      <td>49.9927</td>\n",
              "      <td>4.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-01 00:01:00</td>\n",
              "      <td>1145.1162</td>\n",
              "      <td>519.1807</td>\n",
              "      <td>491.4436</td>\n",
              "      <td>398.6934</td>\n",
              "      <td>400.1579</td>\n",
              "      <td>395.5431</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6903</td>\n",
              "      <td>0.4904</td>\n",
              "      <td>49.9779</td>\n",
              "      <td>5.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-01 00:02:00</td>\n",
              "      <td>1140.9558</td>\n",
              "      <td>743.3837</td>\n",
              "      <td>484.9942</td>\n",
              "      <td>398.4367</td>\n",
              "      <td>400.1205</td>\n",
              "      <td>395.5259</td>\n",
              "      <td>0.8113</td>\n",
              "      <td>0.9274</td>\n",
              "      <td>0.4806</td>\n",
              "      <td>49.9782</td>\n",
              "      <td>4.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-01 00:03:00</td>\n",
              "      <td>1151.9409</td>\n",
              "      <td>741.4836</td>\n",
              "      <td>487.4224</td>\n",
              "      <td>398.9800</td>\n",
              "      <td>400.4375</td>\n",
              "      <td>395.8621</td>\n",
              "      <td>0.8249</td>\n",
              "      <td>0.9123</td>\n",
              "      <td>0.4778</td>\n",
              "      <td>49.9850</td>\n",
              "      <td>5.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-01 00:04:00</td>\n",
              "      <td>1142.1594</td>\n",
              "      <td>741.9858</td>\n",
              "      <td>486.7629</td>\n",
              "      <td>398.7133</td>\n",
              "      <td>400.3145</td>\n",
              "      <td>395.6446</td>\n",
              "      <td>0.8081</td>\n",
              "      <td>0.9291</td>\n",
              "      <td>0.4552</td>\n",
              "      <td>49.9856</td>\n",
              "      <td>4.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6b27129-d120-4bb4-8be9-f0e0f0801159')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6b27129-d120-4bb4-8be9-f0e0f0801159 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6b27129-d120-4bb4-8be9-f0e0f0801159');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ],
      "source": [
        "dataset = pd.read_csv('data_factory.csv')\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZAyQ-cA2926"
      },
      "source": [
        "Once we have the dataset, we should prepare it. Finding the missing or the NaN values and replace them with suitable values (in this case we use the previous value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNTHq6mO2927",
        "outputId": "2251dd68-12ed-44e6-bf72-68ec6c95c929",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with NaN values before cleaning: 2546\n",
            "Number of rows with NaN values after cleaning: 0\n",
            "Total number of samples: 63360\n",
            "Number of features: 19\n"
          ]
        }
      ],
      "source": [
        "# Replace all mising values with NaN\n",
        "dataset = dataset.replace(' ', np.nan)\n",
        "# Search for all the rows with NaN values\n",
        "nan_values = dataset[dataset.isna().any(axis=1)]\n",
        "# Print the shape to know how many are there\n",
        "print(f'Number of rows with NaN values before cleaning: {nan_values.shape[0]}') \n",
        "\n",
        "# Fill all NaN values with the previous row value\n",
        "dataset_clean = dataset.fillna(method='ffill')\n",
        "\n",
        "# Check that there isn't any NaN values\n",
        "nan_values = dataset_clean[dataset_clean.isna().any(axis=1)]\n",
        "# Print the shape to know how many are there\n",
        "print(f'Number of rows with NaN values after cleaning: {nan_values.shape[0]}') \n",
        "\n",
        "#Total number of samples\n",
        "print(f'Total number of samples: {dataset_clean.shape[0]}')\n",
        "print(f'Number of features: {dataset_clean.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d44xLGPbjDhp"
      },
      "source": [
        "# Distribution of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6R7YF-T2928"
      },
      "source": [
        "Now we look at the distribution of the different features of the data over different time intervals.\n",
        "First we take a look of the min and max values, mean and median value and the standard deviation of every feature."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_data = False\n",
        "\n",
        "if print_data is True:\n",
        "  for column in dataset_clean.columns:\n",
        "    if column == 'time':\n",
        "      print(column)\n",
        "      print('Min value: ', dataset_clean[column].min())\n",
        "      print('Max value: ', dataset_clean[column].max())\n",
        "      print('')\n",
        "    else:\n",
        "      print(column)\n",
        "      print('Min value: ', dataset_clean[column].min())\n",
        "      print('Max value: ', dataset_clean[column].max())\n",
        "      print('Mean value: ', dataset_clean[column].mean())\n",
        "      print('Median value: ', dataset_clean[column].median())\n",
        "      print('Standard deviation: ', dataset_clean[column].std())\n",
        "      print('')"
      ],
      "metadata": {
        "id": "pseEB_3qChk4"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "tQ0vhNNv2928",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Set to True to print the graphs\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "\n",
        "  for i, column in enumerate(dataset_clean.columns):\n",
        "    if i > 0:\n",
        "      # Feature in a weekly interval\n",
        "      utils_bsc.week_plot(dataset_clean, i, column)\n",
        "      # Feature in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
        "      utils_bsc.daily_plot(dataset_clean, i, column)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We print some graphs showing the density distribution of every feature\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_clean.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_clean, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "sJIFPsqkiezx"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After looking to the different data graphs i notice there two very different \"time slots\" when the data differs. One is Weekdays between 4:00 and 19:30. The other is Weekdays bewteen 19:30 and 4:00 and Weekends."
      ],
      "metadata": {
        "id": "cWFCmrIH5oA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create two extra data sets, one with the weekdays between 4:00 and 18:30 and one with the rest.\n",
        "dataset_clean_time = pd.to_datetime(dataset_clean['time'])\n",
        "\n",
        "day_mask = dataset_clean_time.dt.day_name()\n",
        "\n",
        "time_mask = (dataset_clean_time.dt.hour >= 4) & ((dataset_clean_time.dt.hour < 19) | ((dataset_clean_time.dt.hour == 19) & (dataset_clean_time.dt.minute <= 30))) & ((day_mask == ('Monday')) | (day_mask == ('Tuesday')) | (day_mask == ('Wednesday')) | (day_mask == ('Thursday')) | (day_mask == ('Friday')))\n",
        "\n",
        "dataset_weekdays = dataset_clean[time_mask]\n",
        "\n",
        "for i in range(len(time_mask)):\n",
        "  if time_mask[i] == False:\n",
        "    time_mask[i] = True\n",
        "  elif time_mask[i] == True:\n",
        "    time_mask[i] = False\n",
        "\n",
        "dataset_weekend = dataset_clean[time_mask]\n",
        "\n",
        "print(f'Weekdays dataset size: {len(dataset_weekdays)}')\n",
        "print(f'Weekend dataset size: {len(dataset_weekend)}')"
      ],
      "metadata": {
        "id": "hVOHl2YDmFV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a4d7bab-050e-4f69-edc8-eaab5874a104"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weekdays dataset size: 29792\n",
            "Weekend dataset size: 33568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekdays.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekdays, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "jYbGTF6mSz5v"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekend.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekend, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "hqupNsJw6bzH"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this time we have three different datasets:\n",
        "\n",
        "* dataset_clean (Whole dataset)\n",
        "* dataset_weekdays (Entries from weekdays from 4:00 to 19:30)\n",
        "* dataset_weekend (Entries from Weekends and from weekdays from 19:30 to 4:00)\n",
        "\n"
      ],
      "metadata": {
        "id": "mgEydMmqTHtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset normalisation\n",
        "\n",
        "The scale of the data of the different features is very dofferent. Its better to have all of the features in the same scale. Therefore we perform a data normalisation. We choose to do a mean/stddev normalisation. We substract from every value the mean value of the feature and divide the result value by the std dev of this specific feature to have feature values with mean 0 and stddev of 1."
      ],
      "metadata": {
        "id": "B6iRPxmuJzVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the mean / stddev scaling in Pandas using the .mean() and .std() methods\n",
        "def normalize_mean_std_dataset(df):\n",
        "    # copy the dataframe\n",
        "    df_norm = df.copy()\n",
        "    # apply mean / stddev scaling\n",
        "    for column in tqdm(df_norm.columns):\n",
        "      if column != 'time':\n",
        "        df_norm[column] = (df_norm[column] - df_norm[column].mean()) / df_norm[column].std()\n",
        "    return df_norm"
      ],
      "metadata": {
        "id": "HBGfdNkAxxbN"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the data normalisation in the whole dataset. We can print the distribution of the data if we want.\n",
        "dataset_norm = normalize_mean_std_dataset(dataset_clean)\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_norm.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_norm, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "1VhzsSn37b_0",
        "outputId": "2cfab5df-5f46-412d-8356-58d1d2debe50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 782.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the data normalisation in the weekdays dataset. We can print the distribution of the data if we want.\n",
        "dataset_weekdays_norm = normalize_mean_std_dataset(dataset_weekdays)\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekdays_norm.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekdays_norm, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "SuS8dhouVCec",
        "outputId": "ec46f8c1-788d-42a4-88ea-618de9d8065c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 1116.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the data normalisation in the weekdays dataset. We can print the distribution of the data if we want.\n",
        "dataset_weekend_norm = normalize_mean_std_dataset(dataset_weekend)\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekend_norm.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekend_norm, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "MH07VtqpVdez",
        "outputId": "d8fe350c-c223-4394-82a0-f461a8ec23e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 502.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_norm.head()"
      ],
      "metadata": {
        "id": "FDUnKkascXyI",
        "outputId": "b57230db-68dc-437f-cb4d-822ff9054d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "0  2020-06-01 00:00:00 -1.075593 -1.045021 -1.051232  0.063478 -0.098312   \n",
              "1  2020-06-01 00:01:00 -1.074875 -1.045103 -1.048747  0.027004 -0.107515   \n",
              "2  2020-06-01 00:02:00 -1.075615 -0.988316 -1.050631 -0.028760 -0.116055   \n",
              "3  2020-06-01 00:03:00 -1.073661 -0.988798 -1.049922  0.089264 -0.043667   \n",
              "4  2020-06-01 00:04:00 -1.075401 -0.988670 -1.050114  0.031327 -0.071754   \n",
              "\n",
              "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
              "0 -0.618908 -1.868350 -1.835847 -1.500292 -0.345935 -0.817380  0.632551   \n",
              "1 -0.632738 -1.884005 -1.803753 -1.486828 -1.139728  0.678985 -0.849829   \n",
              "2 -0.636846 -1.837041  0.147415 -1.532327 -1.123638 -0.817380 -0.849829   \n",
              "3 -0.556540 -1.643493  0.023152 -1.545327 -0.758922  0.678985 -0.740023   \n",
              "4 -0.608493 -1.882582  0.161405 -1.650254 -0.726741 -0.817380  0.303134   \n",
              "\n",
              "    RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "0  1.075812  0.995360   1.143832       0.694697  0.747095   2.141318  \n",
              "1 -0.918340 -0.792166  -0.630653      -0.822036 -0.777047  -1.175568  \n",
              "2 -0.918340 -0.792166  -0.630653      -0.822036 -0.777047  -1.175568  \n",
              "3 -0.253623 -0.643206  -0.630653      -0.763700 -0.664147  -1.175568  \n",
              "4  1.740530  1.889123   1.950416       0.053002 -0.043201   1.477941  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-943dbbc5-39b6-4ed6-ab5e-7924e64f86f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-01 00:00:00</td>\n",
              "      <td>-1.075593</td>\n",
              "      <td>-1.045021</td>\n",
              "      <td>-1.051232</td>\n",
              "      <td>0.063478</td>\n",
              "      <td>-0.098312</td>\n",
              "      <td>-0.618908</td>\n",
              "      <td>-1.868350</td>\n",
              "      <td>-1.835847</td>\n",
              "      <td>-1.500292</td>\n",
              "      <td>-0.345935</td>\n",
              "      <td>-0.817380</td>\n",
              "      <td>0.632551</td>\n",
              "      <td>1.075812</td>\n",
              "      <td>0.995360</td>\n",
              "      <td>1.143832</td>\n",
              "      <td>0.694697</td>\n",
              "      <td>0.747095</td>\n",
              "      <td>2.141318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-01 00:01:00</td>\n",
              "      <td>-1.074875</td>\n",
              "      <td>-1.045103</td>\n",
              "      <td>-1.048747</td>\n",
              "      <td>0.027004</td>\n",
              "      <td>-0.107515</td>\n",
              "      <td>-0.632738</td>\n",
              "      <td>-1.884005</td>\n",
              "      <td>-1.803753</td>\n",
              "      <td>-1.486828</td>\n",
              "      <td>-1.139728</td>\n",
              "      <td>0.678985</td>\n",
              "      <td>-0.849829</td>\n",
              "      <td>-0.918340</td>\n",
              "      <td>-0.792166</td>\n",
              "      <td>-0.630653</td>\n",
              "      <td>-0.822036</td>\n",
              "      <td>-0.777047</td>\n",
              "      <td>-1.175568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-01 00:02:00</td>\n",
              "      <td>-1.075615</td>\n",
              "      <td>-0.988316</td>\n",
              "      <td>-1.050631</td>\n",
              "      <td>-0.028760</td>\n",
              "      <td>-0.116055</td>\n",
              "      <td>-0.636846</td>\n",
              "      <td>-1.837041</td>\n",
              "      <td>0.147415</td>\n",
              "      <td>-1.532327</td>\n",
              "      <td>-1.123638</td>\n",
              "      <td>-0.817380</td>\n",
              "      <td>-0.849829</td>\n",
              "      <td>-0.918340</td>\n",
              "      <td>-0.792166</td>\n",
              "      <td>-0.630653</td>\n",
              "      <td>-0.822036</td>\n",
              "      <td>-0.777047</td>\n",
              "      <td>-1.175568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-01 00:03:00</td>\n",
              "      <td>-1.073661</td>\n",
              "      <td>-0.988798</td>\n",
              "      <td>-1.049922</td>\n",
              "      <td>0.089264</td>\n",
              "      <td>-0.043667</td>\n",
              "      <td>-0.556540</td>\n",
              "      <td>-1.643493</td>\n",
              "      <td>0.023152</td>\n",
              "      <td>-1.545327</td>\n",
              "      <td>-0.758922</td>\n",
              "      <td>0.678985</td>\n",
              "      <td>-0.740023</td>\n",
              "      <td>-0.253623</td>\n",
              "      <td>-0.643206</td>\n",
              "      <td>-0.630653</td>\n",
              "      <td>-0.763700</td>\n",
              "      <td>-0.664147</td>\n",
              "      <td>-1.175568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-01 00:04:00</td>\n",
              "      <td>-1.075401</td>\n",
              "      <td>-0.988670</td>\n",
              "      <td>-1.050114</td>\n",
              "      <td>0.031327</td>\n",
              "      <td>-0.071754</td>\n",
              "      <td>-0.608493</td>\n",
              "      <td>-1.882582</td>\n",
              "      <td>0.161405</td>\n",
              "      <td>-1.650254</td>\n",
              "      <td>-0.726741</td>\n",
              "      <td>-0.817380</td>\n",
              "      <td>0.303134</td>\n",
              "      <td>1.740530</td>\n",
              "      <td>1.889123</td>\n",
              "      <td>1.950416</td>\n",
              "      <td>0.053002</td>\n",
              "      <td>-0.043201</td>\n",
              "      <td>1.477941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-943dbbc5-39b6-4ed6-ab5e-7924e64f86f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-943dbbc5-39b6-4ed6-ab5e-7924e64f86f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-943dbbc5-39b6-4ed6-ab5e-7924e64f86f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_weekdays_norm.head()"
      ],
      "metadata": {
        "id": "mQo9ewweclhz",
        "outputId": "52819585-f585-4573-8476-c45b15524dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "240  2020-06-01 04:00:00 -3.844526 -2.815111 -3.811858  1.679619  1.570822   \n",
              "241  2020-06-01 04:01:00 -3.846186 -3.787824 -3.823188  1.763631  1.696076   \n",
              "242  2020-06-01 04:02:00 -3.839272 -1.875102 -2.712874  1.852445  1.730759   \n",
              "243  2020-06-01 04:03:00 -3.842709 -3.088604 -3.827000  1.832063  1.744944   \n",
              "244  2020-06-01 04:04:00 -3.844287 -2.842539 -3.450520  1.753998  1.623568   \n",
              "\n",
              "         ULL3  COS_PHI1  COS_PHI2   COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
              "240  1.782563 -1.458455 -0.043591 -11.695581 -0.570289 -0.884008 -3.224201   \n",
              "241  1.843617 -1.467086 -2.835547 -11.782866  0.903443  2.133621 -3.224201   \n",
              "242  1.917486 -1.557711  0.058113  -1.543490  0.445873  0.624807 -1.273229   \n",
              "243  1.905749 -1.475716 -0.716154 -12.237347 -0.219683  0.624807 -1.923553   \n",
              "244  1.808403 -1.527502 -0.430725  -5.973931 -0.611886 -0.884008 -1.842262   \n",
              "\n",
              "      RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "240 -1.568103 -1.701045  -1.466370      -3.271799 -2.865462  -1.695805  \n",
              "241 -1.568103 -1.701045  -1.466370      -3.357651 -2.939190  -1.695805  \n",
              "242 -0.765503 -1.118658  -0.885575      -1.211362 -0.948518  -0.928865  \n",
              "243 -1.568103 -1.312787  -1.272772      -2.069878 -1.538347  -0.928865  \n",
              "244 -0.765503 -1.312787  -1.272772      -2.069878 -1.464618  -0.928865  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba9ba096-f88a-4655-9c91-c4d06b667aa2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>2020-06-01 04:00:00</td>\n",
              "      <td>-3.844526</td>\n",
              "      <td>-2.815111</td>\n",
              "      <td>-3.811858</td>\n",
              "      <td>1.679619</td>\n",
              "      <td>1.570822</td>\n",
              "      <td>1.782563</td>\n",
              "      <td>-1.458455</td>\n",
              "      <td>-0.043591</td>\n",
              "      <td>-11.695581</td>\n",
              "      <td>-0.570289</td>\n",
              "      <td>-0.884008</td>\n",
              "      <td>-3.224201</td>\n",
              "      <td>-1.568103</td>\n",
              "      <td>-1.701045</td>\n",
              "      <td>-1.466370</td>\n",
              "      <td>-3.271799</td>\n",
              "      <td>-2.865462</td>\n",
              "      <td>-1.695805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>2020-06-01 04:01:00</td>\n",
              "      <td>-3.846186</td>\n",
              "      <td>-3.787824</td>\n",
              "      <td>-3.823188</td>\n",
              "      <td>1.763631</td>\n",
              "      <td>1.696076</td>\n",
              "      <td>1.843617</td>\n",
              "      <td>-1.467086</td>\n",
              "      <td>-2.835547</td>\n",
              "      <td>-11.782866</td>\n",
              "      <td>0.903443</td>\n",
              "      <td>2.133621</td>\n",
              "      <td>-3.224201</td>\n",
              "      <td>-1.568103</td>\n",
              "      <td>-1.701045</td>\n",
              "      <td>-1.466370</td>\n",
              "      <td>-3.357651</td>\n",
              "      <td>-2.939190</td>\n",
              "      <td>-1.695805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>2020-06-01 04:02:00</td>\n",
              "      <td>-3.839272</td>\n",
              "      <td>-1.875102</td>\n",
              "      <td>-2.712874</td>\n",
              "      <td>1.852445</td>\n",
              "      <td>1.730759</td>\n",
              "      <td>1.917486</td>\n",
              "      <td>-1.557711</td>\n",
              "      <td>0.058113</td>\n",
              "      <td>-1.543490</td>\n",
              "      <td>0.445873</td>\n",
              "      <td>0.624807</td>\n",
              "      <td>-1.273229</td>\n",
              "      <td>-0.765503</td>\n",
              "      <td>-1.118658</td>\n",
              "      <td>-0.885575</td>\n",
              "      <td>-1.211362</td>\n",
              "      <td>-0.948518</td>\n",
              "      <td>-0.928865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>2020-06-01 04:03:00</td>\n",
              "      <td>-3.842709</td>\n",
              "      <td>-3.088604</td>\n",
              "      <td>-3.827000</td>\n",
              "      <td>1.832063</td>\n",
              "      <td>1.744944</td>\n",
              "      <td>1.905749</td>\n",
              "      <td>-1.475716</td>\n",
              "      <td>-0.716154</td>\n",
              "      <td>-12.237347</td>\n",
              "      <td>-0.219683</td>\n",
              "      <td>0.624807</td>\n",
              "      <td>-1.923553</td>\n",
              "      <td>-1.568103</td>\n",
              "      <td>-1.312787</td>\n",
              "      <td>-1.272772</td>\n",
              "      <td>-2.069878</td>\n",
              "      <td>-1.538347</td>\n",
              "      <td>-0.928865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>2020-06-01 04:04:00</td>\n",
              "      <td>-3.844287</td>\n",
              "      <td>-2.842539</td>\n",
              "      <td>-3.450520</td>\n",
              "      <td>1.753998</td>\n",
              "      <td>1.623568</td>\n",
              "      <td>1.808403</td>\n",
              "      <td>-1.527502</td>\n",
              "      <td>-0.430725</td>\n",
              "      <td>-5.973931</td>\n",
              "      <td>-0.611886</td>\n",
              "      <td>-0.884008</td>\n",
              "      <td>-1.842262</td>\n",
              "      <td>-0.765503</td>\n",
              "      <td>-1.312787</td>\n",
              "      <td>-1.272772</td>\n",
              "      <td>-2.069878</td>\n",
              "      <td>-1.464618</td>\n",
              "      <td>-0.928865</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba9ba096-f88a-4655-9c91-c4d06b667aa2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba9ba096-f88a-4655-9c91-c4d06b667aa2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba9ba096-f88a-4655-9c91-c4d06b667aa2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_weekend_norm.head()"
      ],
      "metadata": {
        "id": "TBgx07hRcodl",
        "outputId": "9ffb5213-fbe9-4da2-c480-57b20aed3fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "0  2020-06-01 00:00:00 -0.520051 -0.469417 -0.491179 -0.852017 -1.003068   \n",
              "1  2020-06-01 00:01:00 -0.518390 -0.469592 -0.485656 -0.905465 -1.016009   \n",
              "2  2020-06-01 00:02:00 -0.520102 -0.348132 -0.489844 -0.987181 -1.028018   \n",
              "3  2020-06-01 00:03:00 -0.515582 -0.349161 -0.488267 -0.814230 -0.926227   \n",
              "4  2020-06-01 00:04:00 -0.519607 -0.348889 -0.488696 -0.899130 -0.965723   \n",
              "\n",
              "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
              "0 -1.783292 -1.338808 -1.189834 -0.885658 -0.479759 -0.761410  1.276387   \n",
              "1 -1.803094 -1.356629 -1.159350 -0.870606 -1.233069  0.728477 -0.330467   \n",
              "2 -1.808977 -1.303165  0.693881 -0.921471 -1.217799 -0.761410 -0.330467   \n",
              "3 -1.693993 -1.082826  0.575856 -0.936003 -0.871684  0.728477 -0.211441   \n",
              "4 -1.768380 -1.355009  0.707168 -1.053303 -0.841144 -0.761410  0.919308   \n",
              "\n",
              "    RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "0  1.388355  1.509262   1.555410       1.427389  1.381491   2.307679  \n",
              "1 -0.570467 -0.350376  -0.254028      -0.283821 -0.298828  -0.881879  \n",
              "2 -0.570467 -0.350376  -0.254028      -0.283821 -0.298828  -0.881879  \n",
              "3  0.082473 -0.195407  -0.254028      -0.218005 -0.174360  -0.881879  \n",
              "4  2.041296  2.439081   2.377882       0.703416  0.510214   1.669767  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6805c151-e6c6-4d48-a3fc-574f28a5f776\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-01 00:00:00</td>\n",
              "      <td>-0.520051</td>\n",
              "      <td>-0.469417</td>\n",
              "      <td>-0.491179</td>\n",
              "      <td>-0.852017</td>\n",
              "      <td>-1.003068</td>\n",
              "      <td>-1.783292</td>\n",
              "      <td>-1.338808</td>\n",
              "      <td>-1.189834</td>\n",
              "      <td>-0.885658</td>\n",
              "      <td>-0.479759</td>\n",
              "      <td>-0.761410</td>\n",
              "      <td>1.276387</td>\n",
              "      <td>1.388355</td>\n",
              "      <td>1.509262</td>\n",
              "      <td>1.555410</td>\n",
              "      <td>1.427389</td>\n",
              "      <td>1.381491</td>\n",
              "      <td>2.307679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-01 00:01:00</td>\n",
              "      <td>-0.518390</td>\n",
              "      <td>-0.469592</td>\n",
              "      <td>-0.485656</td>\n",
              "      <td>-0.905465</td>\n",
              "      <td>-1.016009</td>\n",
              "      <td>-1.803094</td>\n",
              "      <td>-1.356629</td>\n",
              "      <td>-1.159350</td>\n",
              "      <td>-0.870606</td>\n",
              "      <td>-1.233069</td>\n",
              "      <td>0.728477</td>\n",
              "      <td>-0.330467</td>\n",
              "      <td>-0.570467</td>\n",
              "      <td>-0.350376</td>\n",
              "      <td>-0.254028</td>\n",
              "      <td>-0.283821</td>\n",
              "      <td>-0.298828</td>\n",
              "      <td>-0.881879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-01 00:02:00</td>\n",
              "      <td>-0.520102</td>\n",
              "      <td>-0.348132</td>\n",
              "      <td>-0.489844</td>\n",
              "      <td>-0.987181</td>\n",
              "      <td>-1.028018</td>\n",
              "      <td>-1.808977</td>\n",
              "      <td>-1.303165</td>\n",
              "      <td>0.693881</td>\n",
              "      <td>-0.921471</td>\n",
              "      <td>-1.217799</td>\n",
              "      <td>-0.761410</td>\n",
              "      <td>-0.330467</td>\n",
              "      <td>-0.570467</td>\n",
              "      <td>-0.350376</td>\n",
              "      <td>-0.254028</td>\n",
              "      <td>-0.283821</td>\n",
              "      <td>-0.298828</td>\n",
              "      <td>-0.881879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-01 00:03:00</td>\n",
              "      <td>-0.515582</td>\n",
              "      <td>-0.349161</td>\n",
              "      <td>-0.488267</td>\n",
              "      <td>-0.814230</td>\n",
              "      <td>-0.926227</td>\n",
              "      <td>-1.693993</td>\n",
              "      <td>-1.082826</td>\n",
              "      <td>0.575856</td>\n",
              "      <td>-0.936003</td>\n",
              "      <td>-0.871684</td>\n",
              "      <td>0.728477</td>\n",
              "      <td>-0.211441</td>\n",
              "      <td>0.082473</td>\n",
              "      <td>-0.195407</td>\n",
              "      <td>-0.254028</td>\n",
              "      <td>-0.218005</td>\n",
              "      <td>-0.174360</td>\n",
              "      <td>-0.881879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-01 00:04:00</td>\n",
              "      <td>-0.519607</td>\n",
              "      <td>-0.348889</td>\n",
              "      <td>-0.488696</td>\n",
              "      <td>-0.899130</td>\n",
              "      <td>-0.965723</td>\n",
              "      <td>-1.768380</td>\n",
              "      <td>-1.355009</td>\n",
              "      <td>0.707168</td>\n",
              "      <td>-1.053303</td>\n",
              "      <td>-0.841144</td>\n",
              "      <td>-0.761410</td>\n",
              "      <td>0.919308</td>\n",
              "      <td>2.041296</td>\n",
              "      <td>2.439081</td>\n",
              "      <td>2.377882</td>\n",
              "      <td>0.703416</td>\n",
              "      <td>0.510214</td>\n",
              "      <td>1.669767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6805c151-e6c6-4d48-a3fc-574f28a5f776')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6805c151-e6c6-4d48-a3fc-574f28a5f776 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6805c151-e6c6-4d48-a3fc-574f28a5f776');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this moment we have six different datasets to use:\n",
        "* dataset_clean (Whole dataset)\n",
        "* dataset_weekdays (Entries from weekdays from 4:00 to 19:30)\n",
        "* dataset_weekend (Entries from Weekends and from weekdays from 19:30 to 4:00)\n",
        "* dataset_norm (Whole dataset, mean/stddev normalised)\n",
        "* dataset_weekdays_norm (Entries from weekdays from 4:00 to 19:30, mean/stddev normalised)\n",
        "* dataset_weekend_norm (Entries from Weekends and from weekdays from 19:30 to 4:00, mean/stddev normalised)"
      ],
      "metadata": {
        "id": "hnu9AcwDW8ZH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJeKUzS0jDhq"
      },
      "source": [
        "# Preparation Training and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvocvIBA292-"
      },
      "source": [
        "Once the dataset is prepared, make batches of data,put them togheter in an array and split them into train and test sets.\n",
        "After looking through the dataset and the features, i decided to takeonly the values with a timestap of a weekday between 4:00 and 19:30. In many of the features in the interval outside those timestamps there i only noise, which can be a sign that the machine is off in that time interval."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloaders(dataset_norm):\n",
        "\n",
        "  # Create a dataset with pairs data / Target (in this case data is one measure (18 features) and target is the next measure (18 features))\n",
        "  # When you plug in one measure, the model should out the next measure\n",
        "\n",
        "  pair_set = []\n",
        "\n",
        "  for i in tqdm(range(len(dataset_norm) -1)):\n",
        "    data = np.array([j for j in dataset_norm.iloc[i, 1:]])\n",
        "    target = np.array([j for j in dataset_norm.iloc[i+1, 1:]])\n",
        "    \n",
        "    pair_set.append((data, target))\n",
        "\n",
        "  dataset_pairs = np.array(pair_set)\n",
        "\n",
        "  training_data_pairs, testing_data_pairs = train_test_split(dataset_pairs, test_size=0.1, random_state=25)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in training_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  training_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  training_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in testing_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  test_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  test_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  print(f'length of training set (whole dataset): {training_data.shape[0]}')\n",
        "  print(f'length of test set (whole dataset): {test_data.shape[0]}')\n",
        "  print('\\n')\n",
        "\n",
        "  # Create data loader to feed the FFN in mini batches\n",
        "\n",
        "  loader_train = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(training_data, training_target),\n",
        "      batch_size=64,\n",
        "      shuffle=True\n",
        "  )\n",
        "\n",
        "  # Create data loader for testing the model\n",
        "  loader_test = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(test_data, test_target),\n",
        "      batch_size=64,\n",
        "      shuffle=True\n",
        "  )\n",
        "\n",
        "  return loader_train, loader_test"
      ],
      "metadata": {
        "id": "eI6P8KvabrMO"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_train, loader_test = create_dataloaders(dataset_norm)"
      ],
      "metadata": {
        "id": "kgHc7L9_cfN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47306111-3609-4cec-a200-6239adbf178c"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63359/63359 [00:21<00:00, 2893.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set (whole dataset): 57023\n",
            "length of test set (whole dataset): 6336\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Baseline Model\n",
        "\n",
        "I am taking the Last step as prediction of all features to create a baselinemodel. I will use this baseline model to compare the results of the actual model with it. Everything that works better than this baseline model could be an improvement."
      ],
      "metadata": {
        "id": "VazanvM-f9cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "\n",
        "losses_train = []\n",
        "\n",
        "for i in loader_train:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_train.append(loss.item())\n",
        "\n",
        "losses_test = []\n",
        "\n",
        "for i in loader_test:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_test.append(loss.item())\n",
        "\n",
        "print(\"Training set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_train))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_train))\n",
        "print('\\n')\n",
        "print(\"Test set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_test))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_test))\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me_JXHtgZyuE",
        "outputId": "8602d210-fd5c-4023-cc90-1fd9c5d70ba6"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set\n",
            "Mean Loss of baselinemodel:  0.4737895984206804\n",
            "Standard deviation Loss of baselinemodel:  0.0921930851126969\n",
            "\n",
            "\n",
            "Test set\n",
            "Mean Loss of baselinemodel:  0.4659305726638948\n",
            "Standard deviation Loss of baselinemodel:  0.08732699834948955\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a simple Feed Forward Neural Network\n",
        "\n",
        "I trained a simple FFN Network to have a second baseline model. The final model training should have also a better performance than this FFN."
      ],
      "metadata": {
        "id": "aX-B-7HMqFeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN_relu(nn.Module):\n",
        "\n",
        "    def __init__(self, D_in, D_out):\n",
        "        super(ANN_relu, self).__init__()\n",
        "        self.linear1 = nn.Linear(D_in, 180)\n",
        "        self.linear2 = nn.Linear(180, 360)\n",
        "        self.linear3 = nn.Linear(360, 360)\n",
        "        self.linear4 = nn.Linear(360, 180)\n",
        "        self.linear5 = nn.Linear(180, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.linear1(x))\n",
        "        x = torch.relu(self.linear2(x))\n",
        "        x = torch.relu(self.linear3(x))\n",
        "        x = torch.relu(self.linear4(x))\n",
        "        return self.linear5(x)\n",
        "\n",
        "# This function trains the model for one epoch\n",
        "def train(model, criterion, optimizer, train_loader, test_loader, n_epochs):\n",
        "\n",
        "    epoch_loss_train = []\n",
        "    epoch_loss_test = []\n",
        "\n",
        "    for e in range(1, n_epochs +1):\n",
        "      print(f'\\nEpoch {e}:')\n",
        "\n",
        "      print('Train')\n",
        "      model.train()\n",
        "\n",
        "      for i in tqdm(train_loader):\n",
        "\n",
        "        data, target = i[0], i[1]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward Pass\n",
        "        output = model(data)\n",
        "\n",
        "        #Compute loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        #Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        #Optimization\n",
        "        optimizer.step()\n",
        "\n",
        "      losses = []\n",
        "\n",
        "      print('\\nTest with training set')\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for i in tqdm(train_loader):\n",
        "\n",
        "          data, target = i[0], i[1]\n",
        "\n",
        "          output = model(data)\n",
        "              \n",
        "          losses.append (float(criterion(output, target).item()))\n",
        "\n",
        "      print('\\nCurrent Mean loss Train: ', np.mean(losses))\n",
        "      epoch_loss_train.append(losses)\n",
        "\n",
        "      losses = []\n",
        "\n",
        "      print('\\nTest with test set')\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for i in tqdm(test_loader):\n",
        "\n",
        "          data, target = i[0], i[1]\n",
        "\n",
        "          output = model(data)\n",
        "            \n",
        "          losses.append (float(criterion(output, target).item()))\n",
        "\n",
        "\n",
        "      print('\\nCurrent Mean loss: ', np.mean(losses))\n",
        "      epoch_loss_test.append(losses)\n",
        "\n",
        "    return model, epoch_loss_train, epoch_loss_test"
      ],
      "metadata": {
        "id": "n9961Y_qY190"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 50\n",
        "lr=0.01\n",
        "\n",
        "# Create model FFN instance\n",
        "model_FFN = ANN_relu(18, 18).to(device)\n",
        "print(model_FFN)\n",
        "\n",
        "# Define Loss\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer = torch.optim.SGD(model_FFN.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "train_FFN = False\n",
        "\n",
        "if train_FFN is True:\n",
        "  trained_model_FFN , train_losses, test_losses = train(model_FFN, criterion, optimizer, loader_train, loader_test, n_epochs)\n"
      ],
      "metadata": {
        "id": "XXhL658rVs8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show results of the loss function\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ion()\n",
        "\n",
        "fig.show()\n",
        "fig.canvas.draw()\n",
        "\n",
        "baseline = [np.mean(losses_train) for i in range(len(train_losses))]\n",
        "\n",
        "ax.plot(baseline)\n",
        "ax.plot([np.mean(i) for i in train_losses])\n",
        "ax.plot([np.mean(i) for i in test_losses])\n",
        "ax.set_title(\"Mean Squared Error FFN\")\n",
        "fig.canvas.draw()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "Lw2ntQMUafOF",
        "outputId": "f5ceb219-1b9a-4f5d-aee6-84f6bfcdfa38"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last basemodel i am going to use is a simple RNN. The final model should also have a better performance than this RNN."
      ],
      "metadata": {
        "id": "Y93gczvmqiT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequece_dataloaders(dataset_norm):\n",
        "\n",
        "  # Create a dataset with pairs data / Target (in this case data is one sequence of 30 measures (18 features) and target are the next sequence of 30 \n",
        "  # measures (18 features)). When you plug in one measure, the model should out the next measure\n",
        "\n",
        "  pair_set = []\n",
        "\n",
        "  for i in tqdm(range(len(dataset_norm) - 60)):\n",
        "    data = np.array(dataset_norm.iloc[i:i+30, 1:])\n",
        "    target = np.array(dataset_norm.iloc[i+30:i+60, 1:])\n",
        "    \n",
        "    pair_set.append((data, target))\n",
        "\n",
        "  dataset_pairs = np.array(pair_set)\n",
        "\n",
        "  training_data_pairs, testing_data_pairs = train_test_split(dataset_pairs, test_size=0.1, random_state=25)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in training_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  training_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  training_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in testing_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  test_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  test_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  print(f'length of training set (whole dataset): {training_data.shape[0]}')\n",
        "  print(f'length of test set (whole dataset): {test_data.shape[0]}')\n",
        "  print('\\n')\n",
        "\n",
        "  # Create data loader to feed the FFN in mini batches\n",
        "\n",
        "  loader_train = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(training_data, training_target),\n",
        "      batch_size=64,\n",
        "      shuffle=False\n",
        "  )\n",
        "\n",
        "  # Create data loader for testing the model\n",
        "  loader_test = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(test_data, test_target),\n",
        "      batch_size=64,\n",
        "      shuffle=False\n",
        "  )\n",
        "\n",
        "  return loader_train, loader_test"
      ],
      "metadata": {
        "id": "6E3nOOEDkOCp"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_train, loader_test = create_sequece_dataloaders(dataset_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loolRFt_jhgV",
        "outputId": "9845d9eb-ac35-4415-e11a-c12fe6eea0d3"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63300/63300 [00:21<00:00, 2905.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set (whole dataset): 56970\n",
            "length of test set (whole dataset): 6330\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "\n",
        "losses_train = []\n",
        "\n",
        "for i in loader_train:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_train.append(loss.item())\n",
        "\n",
        "losses_test = []\n",
        "\n",
        "for i in loader_test:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_test.append(loss.item())\n",
        "\n",
        "print(\"Training set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_train))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_train))\n",
        "print('\\n')\n",
        "print(\"Test set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_test))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_test))\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeZYKAbqkvUY",
        "outputId": "6e8b2e1b-d989-4505-9ad5-dc521eceff14"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set\n",
            "Mean Loss of baselinemodel:  0.7443890079237128\n",
            "Standard deviation Loss of baselinemodel:  0.05472206398141798\n",
            "\n",
            "\n",
            "Test set\n",
            "Mean Loss of baselinemodel:  0.7505416827972489\n",
            "Standard deviation Loss of baselinemodel:  0.05128823597546373\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Model\n",
        "\n",
        "We train before a standard RNN and see which results we can expected with a small and easy solution.\n",
        "I am using this template (https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb) and make changes using it as a base.\n",
        "\n",
        "1) torch.nn.RNN (https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)\n",
        "\n",
        "Parameters\n",
        "* input_size – The number of expected features in the input x\n",
        "* hidden_size – The number of features in the hidden state h\n",
        "* num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1\n",
        "* nonlinearity – The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'\n",
        "* bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
        "* batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: False\n",
        "* dropout – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
        "* bidirectional – If True, becomes a bidirectional RNN. Default: False\n",
        "\n",
        "2) torch.nn.Linear (https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
        "\n",
        "Parameters\n",
        "* in_features – size of each input sample\n",
        "* out_features – size of each output sample\n",
        "* bias – If set to False, the layer will not learn an additive bias. Default: True\n"
      ],
      "metadata": {
        "id": "wLCXaTbSsHRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers, device, batch_first = True, dropout = 0):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.device = device\n",
        "\n",
        "        #Defining the layers\n",
        "        self.fc1 = nn.Linear(input_size, input_size)\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_size = hidden_dim, num_layers = n_layers, batch_first = batch_first, nonlinearity='relu', dropout = dropout)   \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size).to(self.device)\n",
        "\n",
        "        out = torch.relu(self.fc1(x))\n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(out, hidden)\n",
        "\n",
        "        out = torch.relu(out)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "VOL1v_mjsEDe"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_RNN(model, criterion, optimizer, train_loader, test_loader, n_epochs):\n",
        "\n",
        "  epoch_loss_train = []\n",
        "  epoch_loss_test = []\n",
        "\n",
        "  # Training Run\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "    print(f'Epoch {epoch}')\n",
        "\n",
        "    losses_train = []\n",
        "    losses_test = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    print('\\nTraining:')\n",
        "    for i in tqdm(train_loader):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      input = i[0]\n",
        "\n",
        "      target = i[1]\n",
        "\n",
        "      output, hidden = model_rnn(input)\n",
        "\n",
        "      #Compute loss\n",
        "      loss = criterion(output, target)\n",
        "\n",
        "      #Backpropagation\n",
        "      loss.backward()\n",
        "\n",
        "      #Optimization\n",
        "      optimizer.step()\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(train_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        output, hidden = model(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_train.append (float(criterion(output, target).item()))\n",
        "\n",
        "    print('\\nTest with test set')\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(test_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        output, hidden = model(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_test.append (float(criterion(output, target).item()))\n",
        "\n",
        "\n",
        "    print('\\nCurrent Mean loss Train Set: ', np.mean(losses_train))\n",
        "    epoch_loss_train.append(np.mean(losses_train))\n",
        "\n",
        "    print('\\nCurrent Mean loss Test Set: ', np.mean(losses_test))\n",
        "    epoch_loss_test.append(np.mean(losses_test))\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "  return epoch_loss_train, epoch_loss_test, model"
      ],
      "metadata": {
        "id": "IzAT4IPPwfZx"
      },
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model with hyperparameters\n",
        "model_rnn = RNN(input_size = 18,\n",
        "                output_size = 18,\n",
        "                hidden_dim = 64,\n",
        "                n_layers = 4,\n",
        "                batch_first = True,\n",
        "                dropout = 0,\n",
        "                device = device)\n",
        "\n",
        "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
        "model_rnn = model_rnn.to(device)\n",
        "\n",
        "# Define hyperparameters\n",
        "n_epochs = 50\n",
        "lr=0.01\n",
        "\n",
        "# Define Loss, Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model_rnn.parameters(), lr=lr)\n",
        "\n",
        "train_RNN = True\n",
        "\n",
        "if train_RNN is True:\n",
        "  train_losses, test_losses, trained_model_RNN = training_RNN(model_rnn, criterion, optimizer, loader_train, loader_test, n_epochs)"
      ],
      "metadata": {
        "id": "kZQzvqz0aU5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show results of the loss function\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ion()\n",
        "\n",
        "fig.show()\n",
        "fig.canvas.draw()\n",
        "\n",
        "baseline = [np.mean(losses_train) for i in range(len(train_losses))]\n",
        "\n",
        "ax.plot(baseline)\n",
        "ax.plot([np.mean(i) for i in train_losses])\n",
        "ax.plot([np.mean(i) for i in test_losses])\n",
        "ax.set_title(\"Mean Squared Error RNN\")\n",
        "fig.canvas.draw()"
      ],
      "metadata": {
        "id": "989Pq-hNLX7r",
        "outputId": "19f3bb12-44f5-43fa-dae7-ab504b5a0a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXX8lu3jjDhr"
      },
      "source": [
        "# Transformer Model settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dUCsWWo292_"
      },
      "source": [
        "Now, we define a class with the transformer model that we are going to use:\n",
        "\n",
        "Using the already written pytorch library for Transformers:\n",
        "\n",
        "1) torch.nn.TransformerEncoderLayer (https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html)\n",
        "\n",
        "*   d_model –> the number of expected features in the input (required).\n",
        "*   nhead –> the number of heads in the multiheadattention models (required).\n",
        "*   dropout –> the dropout value (default=0.1).\n",
        "*   activation –> the activation function of the intermediate layer, can be a string (“relu” or “gelu”) or a unary callable. (default: relu)\n",
        "*   layer_norm_eps –> the eps value in layer normalization components (default=1e-5).\n",
        "*   batch_first –> If True, then the input and output tensors are provided as (batch, seq, feature). (default: False)\n",
        "*   norm_first –> if True, layer norm is done prior to attention and feedforward operations, respectivaly. Otherwise it’s done after. (default: False (after))\n",
        "\n",
        "2) torch.nn.TransformerDecoderLayer\n",
        "\n",
        "* d_model –> the number of expected features in the input (required).\n",
        "* nhead –> the number of heads in the multiheadattention models (required).\n",
        "* dim_feedforward –> the dimension of the feedforward network model (default=2048).\n",
        "* dropout –> the dropout value (default=0.1).\n",
        "* activation –> the activation function of the intermediate layer, can be a string (“relu” or “gelu”) or a unary callable. Default: relu\n",
        "* layer_norm_eps –> the eps value in layer normalization components (default=1e-5).\n",
        "* batch_first –> If True, then the input and output tensors are provided as (batch, seq, feature). Default: False.\n",
        "* norm_first –> if True, layer norm is done prior to self attention, multihead attention and feedforward operations, respectivaly. Otherwise it’s done after. Default: False (after).\n",
        "\n",
        "3) torch.nn.TransformerEncoder\n",
        "\n",
        "* encoder_layer –> an instance of the TransformerEncoderLayer() class (required).\n",
        "* num_layers –> the number of sub-encoder-layers in the encoder (required).\n",
        "* norm –> the layer normalization component (optional).\n",
        "\n",
        "\n",
        "4) torch.nn.TransformerDecoder\n",
        "\n",
        "* decoder_layer – an instance of the TransformerDecoderLayer() class (required).\n",
        "* num_layers – the number of sub-decoder-layers in the decoder (required).\n",
        "* norm – the layer normalization component (optional).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "id": "tCC_Bava293A",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def positional_encoding(seq_len: int, dim_model: int, device):\n",
        "    \n",
        "    # Tensor with the positions of every sequence element (0 to seq_len)\n",
        "    pos = torch.arange(seq_len, dtype=float32, device=device).reshape(1, -1, 1)\n",
        "    \n",
        "    # Tensor with the positions of every feature in the sequence (0 to dim_model)\n",
        "    dim = torch.arange(dim_model, dtype=float32, device=device).reshape(1, 1, -1)\n",
        "\n",
        "    phase = pos / (1e4 ** (torch.div(dim, dim_model, rounding_mode='floor')))\n",
        "\n",
        "    position_encoding = torch.where(dim.long() % 2 == 0, sin(phase), cos(phase))\n",
        "\n",
        "    return position_encoding.to(device)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, feature_size, output_size, num_encoder_layers, num_heads, num_decoder_layers, device, dropout: float =0.1, batch_first: bool = False):\n",
        "        super(Transformer, self).__init__()\n",
        "        \n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model= feature_size, nhead= num_heads, dropout=dropout, device=device, batch_first=batch_first)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model= feature_size, nhead= num_heads, dropout=dropout, device=device, batch_first=batch_first)\n",
        "        \n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers= num_encoder_layers)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers= num_decoder_layers)\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.device = device\n",
        "\n",
        "    def generate_square_mask(self, dim):\n",
        "        return torch.triu(torch.ones(dim, dim) * float('-inf'), diagonal=1).to(self.device)\n",
        "        \n",
        "    def forward (self, src):\n",
        "        \n",
        "        mask = self.generate_square_mask(len(src))\n",
        "\n",
        "        src_pos = src + positional_encoding(src.shape[1], src.shape[2], self.device)\n",
        "\n",
        "        output = self.encoder (src, mask)\n",
        "        \n",
        "        output = self.decoder (src_pos, output, mask)\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should define an optimizer too.\n",
        "For this, we use the pytorch library:\n",
        "\n",
        "* SGD –> Stochastic gradient descent.\n",
        "\n",
        "1) torch.optim.SDG (https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)\n",
        "\n",
        "* params (iterable) – iterable of parameters to optimize or dicts defining parameter groups\n",
        "* lr (float) – learning rate\n",
        "* momentum (float, optional) – momentum factor (default: 0)\n",
        "* weight_decay (float, optional) – weight decay (L2 penalty) (default: 0)\n",
        "* dampening (float, optional) – dampening for momentum (default: 0)\n",
        "* nesterov (bool, optional) – enables Nesterov momentum (default: False)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8EANo5UFE15A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_transformer(model, optimizer, criterion, train_loader, test_loader, n_epochs):\n",
        "  epoch_loss_train = []\n",
        "  epoch_loss_test = []\n",
        "\n",
        "  n_epochs = 4\n",
        "\n",
        "  for e in range(1, n_epochs + 1):\n",
        "\n",
        "    print('Epoch: ', e)\n",
        "\n",
        "    print('Training:')\n",
        "    model.train()\n",
        "\n",
        "    for i in tqdm(train_loader):\n",
        "\n",
        "      # Initialize optimizer gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      input = i[0]\n",
        "\n",
        "      target = i[1]\n",
        "\n",
        "      net_out = model.forward(input)\n",
        "\n",
        "      #Compute loss\n",
        "      loss = criterion(net_out, target)\n",
        "\n",
        "      #Backpropagation\n",
        "      loss.backward()\n",
        "\n",
        "      #Optimization\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    losses_train = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(train_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        net_out = model.forward(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_train.append (float(criterion(net_out, target).item()))\n",
        "\n",
        "    \n",
        "    print('\\nCurrent Mean loss Train Set: ', np.mean(losses_train))\n",
        "    epoch_loss_train.append(losses_train)\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    losses_test = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(test_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        net_out = model.forward(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_test.append (float(criterion(net_out, target).item()))\n",
        "\n",
        "    print('\\nCurrent Mean loss Test Set: ', np.mean(losses_test))\n",
        "    epoch_loss_test.append(losses_test)\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "  return model, epoch_loss_train, epoch_loss_test"
      ],
      "metadata": {
        "id": "SZ8UZSHPQLT5"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup model Ok\n",
            "Setup optimizer Ok\n",
            "Epoch:  1\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 128/891 [00:02<00:17, 42.68it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-331-26ed60183b8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain_transformer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mtrained_model_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-327-58c197b3d48a>\u001b[0m in \u001b[0;36mtraining_transformer\u001b[0;34m(model, optimizer, criterion, train_loader, test_loader, n_epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0;31m#Optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Initialize Transformer Model and Optimizer\n",
        "\n",
        "model_transformer = Transformer (num_encoder_layers=3,\n",
        "                     num_decoder_layers=3,\n",
        "                     feature_size=18,\n",
        "                     output_size=18,\n",
        "                     num_heads=3,\n",
        "                     device = device,\n",
        "                     batch_first=False)\n",
        "\n",
        "n_epochs = 50\n",
        "\n",
        "print('Setup model Ok')\n",
        "\n",
        "optimizer = torch.optim.Adam(model_transformer.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print('Setup optimizer Ok')\n",
        "\n",
        "\n",
        "train_transformer = True\n",
        "\n",
        "if train_transformer is True:\n",
        "  trained_model_transformer, train_losses, test_losses = training_transformer(model_transformer, optimizer, criterion, loader_train, loader_test, n_epochs)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Muhz9Q2qjDhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "63b21baa-e4fb-4ac1-b13e-b1b239f83894"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "id": "FgrbFBLS293A",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "0deb95d6-c077-420a-d415-b8ea9a32c88d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Show results of the loss function\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ion()\n",
        "\n",
        "fig.show()\n",
        "fig.canvas.draw()\n",
        "\n",
        "baseline = [np.mean(losses_train) for i in range(len(train_losses))]\n",
        "\n",
        "ax.plot(baseline)\n",
        "ax.plot([np.mean(i) for i in train_losses])\n",
        "ax.plot([np.mean(i) for i in test_losses])\n",
        "ax.set_title(\"Mean Squared Error RNN\")\n",
        "fig.canvas.draw()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS8DcLC-293B"
      },
      "source": [
        "Ideas, things to remember, to search, etc...\n",
        "\n",
        "reconstruction, vergelich mit base line model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "bsc_arbeit.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python392jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}