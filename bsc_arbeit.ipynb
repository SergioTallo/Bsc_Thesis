{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0esqvQHT2922"
      },
      "source": [
        "# First: load imports needed for the project and preparation of the project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is necessary to use this notebook in google colab\n",
        "# If you are running this notebook in colab, please change colab to True\n",
        "\n",
        "import os\n",
        "\n",
        "colab = True\n",
        "cwd = os.getcwd()\n",
        "\n",
        "if colab is True and cwd != \"/content/Bsc_Thesis\":\n",
        "  ! git clone https://github.com/SergioTallo/Bsc_Thesis.git\n",
        "  % cd Bsc_Thesis\n",
        "\n",
        "print(cwd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adt0VN_ojbV1",
        "outputId": "5c6c2787-4d9b-447a-dee0-f3ede7299a35"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Bsc_Thesis'...\n",
            "remote: Enumerating objects: 215, done.\u001b[K\n",
            "remote: Counting objects: 100% (215/215), done.\u001b[K\n",
            "remote: Compressing objects: 100% (203/203), done.\u001b[K\n",
            "remote: Total 215 (delta 134), reused 26 (delta 12), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (215/215), 3.92 MiB | 7.88 MiB/s, done.\n",
            "Resolving deltas: 100% (134/134), done.\n",
            "/content/Bsc_Thesis\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VCwEuYFk2923",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ca9bf8-2065-46fd-831b-c2823b1cfd2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: GPU = Tesla P100-PCIE-16GB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "from torch import Tensor, float32, sin, cos\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import utils_bsc\n",
        "import datetime\n",
        "import statistics\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "  print('Device: GPU =', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print('Device: CPU')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQPvc4I-4LY5",
        "outputId": "78168209-755d-4529-8ca8-a8f857db1782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "versions of packages:\n",
            "Python: 3.7.13\n",
            "Pandas: 1.3.5\n",
            "Numpy: 1.21.6\n",
            "PyTorch: 1.10.0+cu111\n",
            "Sklearn: 1.0.2\n",
            "seaborn: 0.11.2\n"
          ]
        }
      ],
      "source": [
        "utils_bsc.print_versions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICcfWNfajDhn"
      },
      "source": [
        "# Data loading and preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "bjUFrMX32925"
      },
      "source": [
        "Now, we should create a dataset with all the data stored in the .csv file\n",
        "\n",
        "Description of the data:\n",
        "\n",
        "*   time: Timestamp (YYYY-MM-DD HH:MM:SS)\n",
        "*   PLN1: Power in the phase 1 (W)\n",
        "*   PLN2: Power in the phase 2 (W)\n",
        "*   PLN3: Power in the phase 3 (W)\n",
        "*   ULL1: Current Voltage between 2 phases (V)\n",
        "*   ULL2: Current Voltage between 2 phases (V)\n",
        "*   ULL3: Current Voltage between 2 phases (V)\n",
        "*   COS_PHI1: Phase shift (Cos)\n",
        "*   COS_PHI2: Phase shift (Cos)\n",
        "*   COS_PHI3: Phase shift (Cos)\n",
        "*   FREQ: Electricity Frequency (Hz)\n",
        "*   RC_DC: Fault currents\n",
        "*   RC_AC: Fault currents\n",
        "*   RC_50Hz: Fault currents\n",
        "*   RC_150Hz: Fault currents\n",
        "*   RC_<100Hz: Fault currents\n",
        "*   RC_100Hz-1kHz: Fault currents\n",
        "*   RC_>10kHz: Fault currents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "qIhc9bwK2926",
        "outputId": "f3cd8e82-1fac-45b9-d214-dfaf8ba43b4d",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  time       PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "0  2020-06-01 00:00:00  1141.0819  519.5034  482.9381  398.8613  400.1982   \n",
              "1  2020-06-01 00:01:00  1145.1162  519.1807  491.4436  398.6934  400.1579   \n",
              "2  2020-06-01 00:02:00  1140.9558  743.3837  484.9942  398.4367  400.1205   \n",
              "3  2020-06-01 00:03:00  1151.9409  741.4836  487.4224  398.9800  400.4375   \n",
              "4  2020-06-01 00:04:00  1142.1594  741.9858  486.7629  398.7133  400.3145   \n",
              "\n",
              "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3     FREQ  RC_DC  RC_AC  RC_50Hz  \\\n",
              "0  395.6010    0.8091    0.6864    0.4875  49.9927    4.0   91.0     10.0   \n",
              "1  395.5431    0.8080    0.6903    0.4904  49.9779    5.0   64.0      7.0   \n",
              "2  395.5259    0.8113    0.9274    0.4806  49.9782    4.0   64.0      7.0   \n",
              "3  395.8621    0.8249    0.9123    0.4778  49.9850    5.0   66.0      8.0   \n",
              "4  395.6446    0.8081    0.9291    0.4552  49.9856    4.0   85.0     11.0   \n",
              "\n",
              "   RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "0      39.0       36.0           86.0      82.0        7.0  \n",
              "1      27.0       25.0           60.0      55.0        2.0  \n",
              "2      27.0       25.0           60.0      55.0        2.0  \n",
              "3      28.0       25.0           61.0      57.0        2.0  \n",
              "4      45.0       41.0           75.0      68.0        6.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a35b230e-9302-4446-8a38-7c61af9b043d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-01 00:00:00</td>\n",
              "      <td>1141.0819</td>\n",
              "      <td>519.5034</td>\n",
              "      <td>482.9381</td>\n",
              "      <td>398.8613</td>\n",
              "      <td>400.1982</td>\n",
              "      <td>395.6010</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.6864</td>\n",
              "      <td>0.4875</td>\n",
              "      <td>49.9927</td>\n",
              "      <td>4.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-01 00:01:00</td>\n",
              "      <td>1145.1162</td>\n",
              "      <td>519.1807</td>\n",
              "      <td>491.4436</td>\n",
              "      <td>398.6934</td>\n",
              "      <td>400.1579</td>\n",
              "      <td>395.5431</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6903</td>\n",
              "      <td>0.4904</td>\n",
              "      <td>49.9779</td>\n",
              "      <td>5.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-01 00:02:00</td>\n",
              "      <td>1140.9558</td>\n",
              "      <td>743.3837</td>\n",
              "      <td>484.9942</td>\n",
              "      <td>398.4367</td>\n",
              "      <td>400.1205</td>\n",
              "      <td>395.5259</td>\n",
              "      <td>0.8113</td>\n",
              "      <td>0.9274</td>\n",
              "      <td>0.4806</td>\n",
              "      <td>49.9782</td>\n",
              "      <td>4.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-01 00:03:00</td>\n",
              "      <td>1151.9409</td>\n",
              "      <td>741.4836</td>\n",
              "      <td>487.4224</td>\n",
              "      <td>398.9800</td>\n",
              "      <td>400.4375</td>\n",
              "      <td>395.8621</td>\n",
              "      <td>0.8249</td>\n",
              "      <td>0.9123</td>\n",
              "      <td>0.4778</td>\n",
              "      <td>49.9850</td>\n",
              "      <td>5.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-01 00:04:00</td>\n",
              "      <td>1142.1594</td>\n",
              "      <td>741.9858</td>\n",
              "      <td>486.7629</td>\n",
              "      <td>398.7133</td>\n",
              "      <td>400.3145</td>\n",
              "      <td>395.6446</td>\n",
              "      <td>0.8081</td>\n",
              "      <td>0.9291</td>\n",
              "      <td>0.4552</td>\n",
              "      <td>49.9856</td>\n",
              "      <td>4.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a35b230e-9302-4446-8a38-7c61af9b043d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a35b230e-9302-4446-8a38-7c61af9b043d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a35b230e-9302-4446-8a38-7c61af9b043d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset = pd.read_csv('data_factory.csv')\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZAyQ-cA2926"
      },
      "source": [
        "Once we have the dataset, we should prepare it. Finding the missing or the NaN values and replace them with suitable values (in this case we use the previous value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNTHq6mO2927",
        "outputId": "d8645332-4ba5-4b3f-e322-1c80116cd3fb",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with NaN values before cleaning: 2546\n",
            "Number of rows with NaN values after cleaning: 0\n",
            "Total number of samples: 63360\n",
            "Number of features: 19\n"
          ]
        }
      ],
      "source": [
        "# Replace all mising values with NaN\n",
        "dataset = dataset.replace(' ', np.nan)\n",
        "# Search for all the rows with NaN values\n",
        "nan_values = dataset[dataset.isna().any(axis=1)]\n",
        "# Print the shape to know how many are there\n",
        "print(f'Number of rows with NaN values before cleaning: {nan_values.shape[0]}') \n",
        "\n",
        "# Fill all NaN values with the previous row value\n",
        "dataset_clean = dataset.fillna(method='ffill')\n",
        "\n",
        "# Check that there isn't any NaN values\n",
        "nan_values = dataset_clean[dataset_clean.isna().any(axis=1)]\n",
        "# Print the shape to know how many are there\n",
        "print(f'Number of rows with NaN values after cleaning: {nan_values.shape[0]}') \n",
        "\n",
        "#Total number of samples\n",
        "print(f'Total number of samples: {dataset_clean.shape[0]}')\n",
        "print(f'Number of features: {dataset_clean.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d44xLGPbjDhp"
      },
      "source": [
        "# Distribution of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6R7YF-T2928"
      },
      "source": [
        "Now we look at the distribution of the different features of the data over different time intervals.\n",
        "First we take a look of the min and max values, mean and median value and the standard deviation of every feature."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_data = False\n",
        "\n",
        "if print_data is True:\n",
        "  for column in dataset_clean.columns:\n",
        "    if column == 'time':\n",
        "      print(column)\n",
        "      print('Min value: ', dataset_clean[column].min())\n",
        "      print('Max value: ', dataset_clean[column].max())\n",
        "      print('')\n",
        "    else:\n",
        "      print(column)\n",
        "      print('Min value: ', dataset_clean[column].min())\n",
        "      print('Max value: ', dataset_clean[column].max())\n",
        "      print('Mean value: ', dataset_clean[column].mean())\n",
        "      print('Median value: ', dataset_clean[column].median())\n",
        "      print('Standard deviation: ', dataset_clean[column].std())\n",
        "      print('')"
      ],
      "metadata": {
        "id": "pseEB_3qChk4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tQ0vhNNv2928",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Set to True to print the graphs\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "\n",
        "  for i, column in enumerate(dataset_clean.columns):\n",
        "    if i > 0:\n",
        "      # Feature in a weekly interval\n",
        "      utils_bsc.week_plot(dataset_clean, i, column)\n",
        "      # Feature in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
        "      utils_bsc.daily_plot(dataset_clean, i, column)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We print some graphs showing the density distribution of every feature\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_clean.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_clean, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "sJIFPsqkiezx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After looking to the different data graphs i notice there two very different \"time slots\" when the data differs. One is Weekdays between 4:00 and 19:30. The other is Weekdays bewteen 19:30 and 4:00 and Weekends."
      ],
      "metadata": {
        "id": "cWFCmrIH5oA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create two extra data sets, one with the weekdays between 4:00 and 18:30 and one with the rest.\n",
        "dataset_clean_time = pd.to_datetime(dataset_clean['time'])\n",
        "\n",
        "day_mask = dataset_clean_time.dt.day_name()\n",
        "\n",
        "time_mask = (dataset_clean_time.dt.hour >= 4) & ((dataset_clean_time.dt.hour < 19) | ((dataset_clean_time.dt.hour == 19) & (dataset_clean_time.dt.minute <= 30))) & ((day_mask == ('Monday')) | (day_mask == ('Tuesday')) | (day_mask == ('Wednesday')) | (day_mask == ('Thursday')) | (day_mask == ('Friday')))\n",
        "\n",
        "dataset_weekdays = dataset_clean[time_mask]\n",
        "\n",
        "for i in range(len(time_mask)):\n",
        "  if time_mask[i] == False:\n",
        "    time_mask[i] = True\n",
        "  elif time_mask[i] == True:\n",
        "    time_mask[i] = False\n",
        "\n",
        "dataset_weekend = dataset_clean[time_mask]\n",
        "\n",
        "print(f'Weekdays dataset size: {len(dataset_weekdays)}')\n",
        "print(f'Weekend dataset size: {len(dataset_weekend)}')"
      ],
      "metadata": {
        "id": "hVOHl2YDmFV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d210fb-b91d-44c1-f966-aea63543d4d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weekdays dataset size: 29792\n",
            "Weekend dataset size: 33568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekdays.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekdays, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "jYbGTF6mSz5v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekend.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekend, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "hqupNsJw6bzH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this time we have three different datasets:\n",
        "\n",
        "* dataset_clean (Whole dataset)\n",
        "* dataset_weekdays (Entries from weekdays from 4:00 to 19:30)\n",
        "* dataset_weekend (Entries from Weekends and from weekdays from 19:30 to 4:00)\n",
        "\n"
      ],
      "metadata": {
        "id": "mgEydMmqTHtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset normalisation\n",
        "\n",
        "The scale of the data of the different features is very dofferent. Its better to have all of the features in the same scale. Therefore we perform a data normalisation. We choose to do a mean/stddev normalisation. We substract from every value the mean value of the feature and divide the result value by the std dev of this specific feature to have feature values with mean 0 and stddev of 1."
      ],
      "metadata": {
        "id": "B6iRPxmuJzVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the mean / stddev scaling in Pandas using the .mean() and .std() methods\n",
        "def normalize_mean_std_dataset(df):\n",
        "    # copy the dataframe\n",
        "    df_norm = df.copy()\n",
        "    # apply mean / stddev scaling\n",
        "    for column in tqdm(df_norm.columns):\n",
        "      if column != 'time':\n",
        "        df_norm[column] = (df_norm[column] - df_norm[column].mean()) / df_norm[column].std()\n",
        "    return df_norm"
      ],
      "metadata": {
        "id": "HBGfdNkAxxbN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the data normalisation in the whole dataset. We can print the distribution of the data if we want.\n",
        "dataset_norm = normalize_mean_std_dataset(dataset_clean)\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_norm.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_norm, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "1VhzsSn37b_0",
        "outputId": "1617c463-1c59-4f17-e71e-0687b63c2971",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 500.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the data normalisation in the weekdays dataset. We can print the distribution of the data if we want.\n",
        "dataset_weekdays_norm = normalize_mean_std_dataset(dataset_weekdays)\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekdays_norm.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekdays_norm, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "SuS8dhouVCec",
        "outputId": "d0a018d1-1703-45f8-8be6-151dc5241394",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 980.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the data normalisation in the weekdays dataset. We can print the distribution of the data if we want.\n",
        "dataset_weekend_norm = normalize_mean_std_dataset(dataset_weekend)\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekend_norm.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekend_norm, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "MH07VtqpVdez",
        "outputId": "6d988869-6e0e-49ff-e2d6-a2d05a828081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 893.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_norm.head()"
      ],
      "metadata": {
        "id": "FDUnKkascXyI",
        "outputId": "31ce3631-a443-455d-f3f5-6c43936cd87d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "0  2020-06-01 00:00:00 -1.075593 -1.045021 -1.051232  0.063478 -0.098312   \n",
              "1  2020-06-01 00:01:00 -1.074875 -1.045103 -1.048747  0.027004 -0.107515   \n",
              "2  2020-06-01 00:02:00 -1.075615 -0.988316 -1.050631 -0.028760 -0.116055   \n",
              "3  2020-06-01 00:03:00 -1.073661 -0.988798 -1.049922  0.089264 -0.043667   \n",
              "4  2020-06-01 00:04:00 -1.075401 -0.988670 -1.050114  0.031327 -0.071754   \n",
              "\n",
              "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
              "0 -0.618908 -1.868350 -1.835847 -1.500292 -0.345935 -0.817380  0.632551   \n",
              "1 -0.632738 -1.884005 -1.803753 -1.486828 -1.139728  0.678985 -0.849829   \n",
              "2 -0.636846 -1.837041  0.147415 -1.532327 -1.123638 -0.817380 -0.849829   \n",
              "3 -0.556540 -1.643493  0.023152 -1.545327 -0.758922  0.678985 -0.740023   \n",
              "4 -0.608493 -1.882582  0.161405 -1.650254 -0.726741 -0.817380  0.303134   \n",
              "\n",
              "    RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "0  1.075812  0.995360   1.143832       0.694697  0.747095   2.141318  \n",
              "1 -0.918340 -0.792166  -0.630653      -0.822036 -0.777047  -1.175568  \n",
              "2 -0.918340 -0.792166  -0.630653      -0.822036 -0.777047  -1.175568  \n",
              "3 -0.253623 -0.643206  -0.630653      -0.763700 -0.664147  -1.175568  \n",
              "4  1.740530  1.889123   1.950416       0.053002 -0.043201   1.477941  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85ee13db-f1b6-4883-80bb-78f561aa823e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-01 00:00:00</td>\n",
              "      <td>-1.075593</td>\n",
              "      <td>-1.045021</td>\n",
              "      <td>-1.051232</td>\n",
              "      <td>0.063478</td>\n",
              "      <td>-0.098312</td>\n",
              "      <td>-0.618908</td>\n",
              "      <td>-1.868350</td>\n",
              "      <td>-1.835847</td>\n",
              "      <td>-1.500292</td>\n",
              "      <td>-0.345935</td>\n",
              "      <td>-0.817380</td>\n",
              "      <td>0.632551</td>\n",
              "      <td>1.075812</td>\n",
              "      <td>0.995360</td>\n",
              "      <td>1.143832</td>\n",
              "      <td>0.694697</td>\n",
              "      <td>0.747095</td>\n",
              "      <td>2.141318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-01 00:01:00</td>\n",
              "      <td>-1.074875</td>\n",
              "      <td>-1.045103</td>\n",
              "      <td>-1.048747</td>\n",
              "      <td>0.027004</td>\n",
              "      <td>-0.107515</td>\n",
              "      <td>-0.632738</td>\n",
              "      <td>-1.884005</td>\n",
              "      <td>-1.803753</td>\n",
              "      <td>-1.486828</td>\n",
              "      <td>-1.139728</td>\n",
              "      <td>0.678985</td>\n",
              "      <td>-0.849829</td>\n",
              "      <td>-0.918340</td>\n",
              "      <td>-0.792166</td>\n",
              "      <td>-0.630653</td>\n",
              "      <td>-0.822036</td>\n",
              "      <td>-0.777047</td>\n",
              "      <td>-1.175568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-01 00:02:00</td>\n",
              "      <td>-1.075615</td>\n",
              "      <td>-0.988316</td>\n",
              "      <td>-1.050631</td>\n",
              "      <td>-0.028760</td>\n",
              "      <td>-0.116055</td>\n",
              "      <td>-0.636846</td>\n",
              "      <td>-1.837041</td>\n",
              "      <td>0.147415</td>\n",
              "      <td>-1.532327</td>\n",
              "      <td>-1.123638</td>\n",
              "      <td>-0.817380</td>\n",
              "      <td>-0.849829</td>\n",
              "      <td>-0.918340</td>\n",
              "      <td>-0.792166</td>\n",
              "      <td>-0.630653</td>\n",
              "      <td>-0.822036</td>\n",
              "      <td>-0.777047</td>\n",
              "      <td>-1.175568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-01 00:03:00</td>\n",
              "      <td>-1.073661</td>\n",
              "      <td>-0.988798</td>\n",
              "      <td>-1.049922</td>\n",
              "      <td>0.089264</td>\n",
              "      <td>-0.043667</td>\n",
              "      <td>-0.556540</td>\n",
              "      <td>-1.643493</td>\n",
              "      <td>0.023152</td>\n",
              "      <td>-1.545327</td>\n",
              "      <td>-0.758922</td>\n",
              "      <td>0.678985</td>\n",
              "      <td>-0.740023</td>\n",
              "      <td>-0.253623</td>\n",
              "      <td>-0.643206</td>\n",
              "      <td>-0.630653</td>\n",
              "      <td>-0.763700</td>\n",
              "      <td>-0.664147</td>\n",
              "      <td>-1.175568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-01 00:04:00</td>\n",
              "      <td>-1.075401</td>\n",
              "      <td>-0.988670</td>\n",
              "      <td>-1.050114</td>\n",
              "      <td>0.031327</td>\n",
              "      <td>-0.071754</td>\n",
              "      <td>-0.608493</td>\n",
              "      <td>-1.882582</td>\n",
              "      <td>0.161405</td>\n",
              "      <td>-1.650254</td>\n",
              "      <td>-0.726741</td>\n",
              "      <td>-0.817380</td>\n",
              "      <td>0.303134</td>\n",
              "      <td>1.740530</td>\n",
              "      <td>1.889123</td>\n",
              "      <td>1.950416</td>\n",
              "      <td>0.053002</td>\n",
              "      <td>-0.043201</td>\n",
              "      <td>1.477941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85ee13db-f1b6-4883-80bb-78f561aa823e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85ee13db-f1b6-4883-80bb-78f561aa823e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85ee13db-f1b6-4883-80bb-78f561aa823e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_weekdays_norm.head()"
      ],
      "metadata": {
        "id": "mQo9ewweclhz",
        "outputId": "a8d75130-4f13-427b-b7c9-e85705a87178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "240  2020-06-01 04:00:00 -3.844526 -2.815111 -3.811858  1.679619  1.570822   \n",
              "241  2020-06-01 04:01:00 -3.846186 -3.787824 -3.823188  1.763631  1.696076   \n",
              "242  2020-06-01 04:02:00 -3.839272 -1.875102 -2.712874  1.852445  1.730759   \n",
              "243  2020-06-01 04:03:00 -3.842709 -3.088604 -3.827000  1.832063  1.744944   \n",
              "244  2020-06-01 04:04:00 -3.844287 -2.842539 -3.450520  1.753998  1.623568   \n",
              "\n",
              "         ULL3  COS_PHI1  COS_PHI2   COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
              "240  1.782563 -1.458455 -0.043591 -11.695581 -0.570289 -0.884008 -3.224201   \n",
              "241  1.843617 -1.467086 -2.835547 -11.782866  0.903443  2.133621 -3.224201   \n",
              "242  1.917486 -1.557711  0.058113  -1.543490  0.445873  0.624807 -1.273229   \n",
              "243  1.905749 -1.475716 -0.716154 -12.237347 -0.219683  0.624807 -1.923553   \n",
              "244  1.808403 -1.527502 -0.430725  -5.973931 -0.611886 -0.884008 -1.842262   \n",
              "\n",
              "      RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "240 -1.568103 -1.701045  -1.466370      -3.271799 -2.865462  -1.695805  \n",
              "241 -1.568103 -1.701045  -1.466370      -3.357651 -2.939190  -1.695805  \n",
              "242 -0.765503 -1.118658  -0.885575      -1.211362 -0.948518  -0.928865  \n",
              "243 -1.568103 -1.312787  -1.272772      -2.069878 -1.538347  -0.928865  \n",
              "244 -0.765503 -1.312787  -1.272772      -2.069878 -1.464618  -0.928865  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00916ea5-502e-41d4-b8b0-21fdd25f5677\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>2020-06-01 04:00:00</td>\n",
              "      <td>-3.844526</td>\n",
              "      <td>-2.815111</td>\n",
              "      <td>-3.811858</td>\n",
              "      <td>1.679619</td>\n",
              "      <td>1.570822</td>\n",
              "      <td>1.782563</td>\n",
              "      <td>-1.458455</td>\n",
              "      <td>-0.043591</td>\n",
              "      <td>-11.695581</td>\n",
              "      <td>-0.570289</td>\n",
              "      <td>-0.884008</td>\n",
              "      <td>-3.224201</td>\n",
              "      <td>-1.568103</td>\n",
              "      <td>-1.701045</td>\n",
              "      <td>-1.466370</td>\n",
              "      <td>-3.271799</td>\n",
              "      <td>-2.865462</td>\n",
              "      <td>-1.695805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>2020-06-01 04:01:00</td>\n",
              "      <td>-3.846186</td>\n",
              "      <td>-3.787824</td>\n",
              "      <td>-3.823188</td>\n",
              "      <td>1.763631</td>\n",
              "      <td>1.696076</td>\n",
              "      <td>1.843617</td>\n",
              "      <td>-1.467086</td>\n",
              "      <td>-2.835547</td>\n",
              "      <td>-11.782866</td>\n",
              "      <td>0.903443</td>\n",
              "      <td>2.133621</td>\n",
              "      <td>-3.224201</td>\n",
              "      <td>-1.568103</td>\n",
              "      <td>-1.701045</td>\n",
              "      <td>-1.466370</td>\n",
              "      <td>-3.357651</td>\n",
              "      <td>-2.939190</td>\n",
              "      <td>-1.695805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>2020-06-01 04:02:00</td>\n",
              "      <td>-3.839272</td>\n",
              "      <td>-1.875102</td>\n",
              "      <td>-2.712874</td>\n",
              "      <td>1.852445</td>\n",
              "      <td>1.730759</td>\n",
              "      <td>1.917486</td>\n",
              "      <td>-1.557711</td>\n",
              "      <td>0.058113</td>\n",
              "      <td>-1.543490</td>\n",
              "      <td>0.445873</td>\n",
              "      <td>0.624807</td>\n",
              "      <td>-1.273229</td>\n",
              "      <td>-0.765503</td>\n",
              "      <td>-1.118658</td>\n",
              "      <td>-0.885575</td>\n",
              "      <td>-1.211362</td>\n",
              "      <td>-0.948518</td>\n",
              "      <td>-0.928865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>2020-06-01 04:03:00</td>\n",
              "      <td>-3.842709</td>\n",
              "      <td>-3.088604</td>\n",
              "      <td>-3.827000</td>\n",
              "      <td>1.832063</td>\n",
              "      <td>1.744944</td>\n",
              "      <td>1.905749</td>\n",
              "      <td>-1.475716</td>\n",
              "      <td>-0.716154</td>\n",
              "      <td>-12.237347</td>\n",
              "      <td>-0.219683</td>\n",
              "      <td>0.624807</td>\n",
              "      <td>-1.923553</td>\n",
              "      <td>-1.568103</td>\n",
              "      <td>-1.312787</td>\n",
              "      <td>-1.272772</td>\n",
              "      <td>-2.069878</td>\n",
              "      <td>-1.538347</td>\n",
              "      <td>-0.928865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>2020-06-01 04:04:00</td>\n",
              "      <td>-3.844287</td>\n",
              "      <td>-2.842539</td>\n",
              "      <td>-3.450520</td>\n",
              "      <td>1.753998</td>\n",
              "      <td>1.623568</td>\n",
              "      <td>1.808403</td>\n",
              "      <td>-1.527502</td>\n",
              "      <td>-0.430725</td>\n",
              "      <td>-5.973931</td>\n",
              "      <td>-0.611886</td>\n",
              "      <td>-0.884008</td>\n",
              "      <td>-1.842262</td>\n",
              "      <td>-0.765503</td>\n",
              "      <td>-1.312787</td>\n",
              "      <td>-1.272772</td>\n",
              "      <td>-2.069878</td>\n",
              "      <td>-1.464618</td>\n",
              "      <td>-0.928865</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00916ea5-502e-41d4-b8b0-21fdd25f5677')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00916ea5-502e-41d4-b8b0-21fdd25f5677 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00916ea5-502e-41d4-b8b0-21fdd25f5677');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_weekend_norm.head()"
      ],
      "metadata": {
        "id": "TBgx07hRcodl",
        "outputId": "e9ca9909-58a4-4750-cf0c-af1643a1538c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "0  2020-06-01 00:00:00 -0.520051 -0.469417 -0.491179 -0.852017 -1.003068   \n",
              "1  2020-06-01 00:01:00 -0.518390 -0.469592 -0.485656 -0.905465 -1.016009   \n",
              "2  2020-06-01 00:02:00 -0.520102 -0.348132 -0.489844 -0.987181 -1.028018   \n",
              "3  2020-06-01 00:03:00 -0.515582 -0.349161 -0.488267 -0.814230 -0.926227   \n",
              "4  2020-06-01 00:04:00 -0.519607 -0.348889 -0.488696 -0.899130 -0.965723   \n",
              "\n",
              "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
              "0 -1.783292 -1.338808 -1.189834 -0.885658 -0.479759 -0.761410  1.276387   \n",
              "1 -1.803094 -1.356629 -1.159350 -0.870606 -1.233069  0.728477 -0.330467   \n",
              "2 -1.808977 -1.303165  0.693881 -0.921471 -1.217799 -0.761410 -0.330467   \n",
              "3 -1.693993 -1.082826  0.575856 -0.936003 -0.871684  0.728477 -0.211441   \n",
              "4 -1.768380 -1.355009  0.707168 -1.053303 -0.841144 -0.761410  0.919308   \n",
              "\n",
              "    RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "0  1.388355  1.509262   1.555410       1.427389  1.381491   2.307679  \n",
              "1 -0.570467 -0.350376  -0.254028      -0.283821 -0.298828  -0.881879  \n",
              "2 -0.570467 -0.350376  -0.254028      -0.283821 -0.298828  -0.881879  \n",
              "3  0.082473 -0.195407  -0.254028      -0.218005 -0.174360  -0.881879  \n",
              "4  2.041296  2.439081   2.377882       0.703416  0.510214   1.669767  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2522c233-05ab-4406-9b95-40e8ec1ec852\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-01 00:00:00</td>\n",
              "      <td>-0.520051</td>\n",
              "      <td>-0.469417</td>\n",
              "      <td>-0.491179</td>\n",
              "      <td>-0.852017</td>\n",
              "      <td>-1.003068</td>\n",
              "      <td>-1.783292</td>\n",
              "      <td>-1.338808</td>\n",
              "      <td>-1.189834</td>\n",
              "      <td>-0.885658</td>\n",
              "      <td>-0.479759</td>\n",
              "      <td>-0.761410</td>\n",
              "      <td>1.276387</td>\n",
              "      <td>1.388355</td>\n",
              "      <td>1.509262</td>\n",
              "      <td>1.555410</td>\n",
              "      <td>1.427389</td>\n",
              "      <td>1.381491</td>\n",
              "      <td>2.307679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-01 00:01:00</td>\n",
              "      <td>-0.518390</td>\n",
              "      <td>-0.469592</td>\n",
              "      <td>-0.485656</td>\n",
              "      <td>-0.905465</td>\n",
              "      <td>-1.016009</td>\n",
              "      <td>-1.803094</td>\n",
              "      <td>-1.356629</td>\n",
              "      <td>-1.159350</td>\n",
              "      <td>-0.870606</td>\n",
              "      <td>-1.233069</td>\n",
              "      <td>0.728477</td>\n",
              "      <td>-0.330467</td>\n",
              "      <td>-0.570467</td>\n",
              "      <td>-0.350376</td>\n",
              "      <td>-0.254028</td>\n",
              "      <td>-0.283821</td>\n",
              "      <td>-0.298828</td>\n",
              "      <td>-0.881879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-01 00:02:00</td>\n",
              "      <td>-0.520102</td>\n",
              "      <td>-0.348132</td>\n",
              "      <td>-0.489844</td>\n",
              "      <td>-0.987181</td>\n",
              "      <td>-1.028018</td>\n",
              "      <td>-1.808977</td>\n",
              "      <td>-1.303165</td>\n",
              "      <td>0.693881</td>\n",
              "      <td>-0.921471</td>\n",
              "      <td>-1.217799</td>\n",
              "      <td>-0.761410</td>\n",
              "      <td>-0.330467</td>\n",
              "      <td>-0.570467</td>\n",
              "      <td>-0.350376</td>\n",
              "      <td>-0.254028</td>\n",
              "      <td>-0.283821</td>\n",
              "      <td>-0.298828</td>\n",
              "      <td>-0.881879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-01 00:03:00</td>\n",
              "      <td>-0.515582</td>\n",
              "      <td>-0.349161</td>\n",
              "      <td>-0.488267</td>\n",
              "      <td>-0.814230</td>\n",
              "      <td>-0.926227</td>\n",
              "      <td>-1.693993</td>\n",
              "      <td>-1.082826</td>\n",
              "      <td>0.575856</td>\n",
              "      <td>-0.936003</td>\n",
              "      <td>-0.871684</td>\n",
              "      <td>0.728477</td>\n",
              "      <td>-0.211441</td>\n",
              "      <td>0.082473</td>\n",
              "      <td>-0.195407</td>\n",
              "      <td>-0.254028</td>\n",
              "      <td>-0.218005</td>\n",
              "      <td>-0.174360</td>\n",
              "      <td>-0.881879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-01 00:04:00</td>\n",
              "      <td>-0.519607</td>\n",
              "      <td>-0.348889</td>\n",
              "      <td>-0.488696</td>\n",
              "      <td>-0.899130</td>\n",
              "      <td>-0.965723</td>\n",
              "      <td>-1.768380</td>\n",
              "      <td>-1.355009</td>\n",
              "      <td>0.707168</td>\n",
              "      <td>-1.053303</td>\n",
              "      <td>-0.841144</td>\n",
              "      <td>-0.761410</td>\n",
              "      <td>0.919308</td>\n",
              "      <td>2.041296</td>\n",
              "      <td>2.439081</td>\n",
              "      <td>2.377882</td>\n",
              "      <td>0.703416</td>\n",
              "      <td>0.510214</td>\n",
              "      <td>1.669767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2522c233-05ab-4406-9b95-40e8ec1ec852')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2522c233-05ab-4406-9b95-40e8ec1ec852 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2522c233-05ab-4406-9b95-40e8ec1ec852');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this moment we have six different datasets to use:\n",
        "* dataset_clean (Whole dataset)\n",
        "* dataset_weekdays (Entries from weekdays from 4:00 to 19:30)\n",
        "* dataset_weekend (Entries from Weekends and from weekdays from 19:30 to 4:00)\n",
        "* dataset_norm (Whole dataset, mean/stddev normalised)\n",
        "* dataset_weekdays_norm (Entries from weekdays from 4:00 to 19:30, mean/stddev normalised)\n",
        "* dataset_weekend_norm (Entries from Weekends and from weekdays from 19:30 to 4:00, mean/stddev normalised)"
      ],
      "metadata": {
        "id": "hnu9AcwDW8ZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Covariance matrix of all features"
      ],
      "metadata": {
        "id": "AqX61PrGpaxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "set_ = dataset_norm.iloc[:,1:].values\n",
        "\n",
        "print(set_.shape)\n",
        "print(type(set_[0][0]))\n",
        "\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
        "cov_matrix = np.cov(set_.T)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "# Adds subplot on position 1\n",
        "ax = fig.add_subplot(121)\n",
        "ax.matshow(cov_matrix)\n",
        "plt.show()\n",
        "\n",
        "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "\n",
        "print(eigenvalues)\n",
        "\n",
        "explained_variance = []\n",
        "\n",
        "for i in eigenvalues:\n",
        "    explained_variance.append(i/sum(eigenvalues))\n",
        "\n",
        "print(explained_variance)"
      ],
      "metadata": {
        "id": "wRWPIDDnpWhW",
        "outputId": "37c043ba-5abe-4078-ebb4-cb75b4d37c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(63360, 18)\n",
            "<class 'numpy.float64'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAGfCAYAAABvILSqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZ4ElEQVR4nO3de4ydB33m8eeZi8eeiS9xHHKxvcS0uTREZEMnbFpUdiEUhRYI2l2piUobtqwsEW6NomUDpeWfioaCKJUoqbzgJtpGYdk0LVG3BCJIG20VEkwg97QhQBKbBDt24vg+l/PbP+ZkZSYznuM5v/M7Z46/H8nyzDmvnvc35/ac95z3vMcRIQAAqgx0ewAAwImF4gEAlKJ4AAClKB4AQCmKBwBQiuIBAJTqueKxfZntf7H9Q9vXdXueudjeaPsu24/afsT2R7o907HYHrT9fdt/3+1ZjsX2Gtu32n7c9mO2f6XbM83F9jXN6/1h27fYXt7tmV5me6vtnbYfPuq0tbbvtP1E8/+Tuzljc6a55vxM87p/0Pbf2l7TzRmbM71izqPOu9Z22F7XjdlmzTLnnLY/1LxMH7H9p92ab7aeKh7bg5L+QtLbJZ0v6Urb53d3qjlNSbo2Is6XdImkD/TonC/7iKTHuj1EC/5c0h0RcZ6kC9WDM9teL+nDksYj4gJJg5Ku6O5UP+dGSZfNOu06Sd+KiLMlfav5e7fdqFfOeaekCyLidZL+VdLHqoeaw4165ZyyvVHS2yQ9XT3QPG7UrDltv1nS5ZIujIjXSvpsF+aaU08Vj6Q3SPphRPwoIiYkfUUzF1xPiYhnI+L+5s/7NPMAub67U83N9gZJvynpS92e5Vhsr5b0JklflqSImIiIF7s71byGJK2wPSRpVNJPuzzP/xcRd0vaM+vkyyXd1Pz5JknvLh1qDnPNGRHfjIip5q/fkbShfLBZ5rk8JenPJH1UUk98An+eOd8v6fqIONJcZmf5YPPoteJZL+mZo37frh59QH+Z7bMkXSTp3u5OMq/Pa+YO0uj2IAvYJGmXpL9qviz4Jdtj3R5qtojYoZlnjk9LelbS3oj4ZnenWtBpEfFs8+fnJJ3WzWFa9HuSvt7tIeZi+3JJOyLigW7PsoBzJP2a7Xtt/5Pti7s90Mt6rXiWFNsnSfobSb8fES91e57ZbL9D0s6I+F63Z2nBkKTXS7ohIi6SdEC98ZLQz2m+P3K5ZoryTEljtt/T3alaFzPHyOqJZ+nzsf0Hmnk5++ZuzzKb7VFJH5f0R92epQVDktZq5u2A/ybpq7bd3ZFm9Frx7JC08ajfNzRP6zm2hzVTOjdHxG3dnmceb5T0Lts/0czLlm+x/dfdHWle2yVtj4iXtxxv1UwR9Zq3SvpxROyKiElJt0n61S7PtJCf2T5Dkpr/98xLLrPZfq+kd0j67ejNA0n+gmaedDzQvF9tkHS/7dO7OtXctku6LWbcp5lXPbq+I4TUe8XzXUln295ke5lm3rS9vcszvULzWcOXJT0WEZ/r9jzziYiPRcSGiDhLM5fltyOiJ5+dR8Rzkp6xfW7zpEslPdrFkebztKRLbI82bweXqgd3gpjldklXNX++StLXujjLvGxfppmXhd8VEQe7Pc9cIuKhiHhVRJzVvF9tl/T65u231/ydpDdLku1zJC2T9HxXJ2rqqeJpvrH4QUnf0Myd+asR8Uh3p5rTGyX9jma2IH7Q/Pcb3R6qD3xI0s22H5T0byV9qsvzvEJzi+xWSfdLekgz96EtXR3qKLZvkXSPpHNtb7f9PknXS/p1209oZovt+m7OKM075xckrZR0Z/M+9ZddHVLzztlz5plzq6TXNHex/oqkq3plK9I9MgcA4ATRU1s8AID+R/EAAEpRPACAUhQPAKAUxQMAKNWzxWN7c7dnaAVz5loqc0pLZ1bmzLVU5pR6d9aeLR5JPXmBzYE5cy2VOaWlMytz5loqc0o9OmsvFw8AoA+VfoB03drBOGvjcEvL7to9rVNPGVxwuekuH3R59+6GTjll4f5+8sGTOjNAi8f8m4zDGm75+8rybxNnXnCgpeVe3N3QmhYuT0naN72inZHmNDZwpOVl9+6Z0uq1Qwsut/25zhweq7GsteWmDxzQ4FhrB/pes7q16+l47J1o7XY3/dJBDa4abWnZkaGphRc6TpONhR9vJGlq70ENrW5tztXDh9oZaV6T0dqsh184ouUnj7S07L4jud9nOLnrRU2/dGDOB6iF7zWJzto4rPu+sXHhBY/D3kb+FTuo/AO4/qcNl6RnSpKHW3z0OR6RX+Z/ePt96Zl37c//7r03jD6ZnvnxT//X9ExJ2r8h/3b6znfek555x1O/lJ65ae1cX5HTnl0H87+F421nPp6eKUnPHVmVnnnXk+ek5m3/+A3znsdLbQCAUhQPAKAUxQMAKEXxAABKUTwAgFJtFY/ty2z/i+0f2r4uaygAQP9adPHYHpT0F5LeLul8SVfazt+/FQDQV9rZ4nmDpB9GxI8iYkIzX616ec5YAIB+1U7xrJf0zFG/b2+e9nNsb7a9zfa2Xbun21gdAKAfdHzngojYEhHjETHeyiFwAAD9rZ3i2SHp6OPfbGieBgDAvNopnu9KOtv2JtvLJF0h6facsQAA/WrRBwmNiCnbH5T0DUmDkrZGxCNpkwEA+lJbR6eOiH+Q9A9JswAATgAcuQAAUIriAQCUongAAKUoHgBAqdKvvp5WI/2rqlcPrEjNk6Tnp/O/d94jrX3v+XHnDnXgKoxIj3yx0dp31B+P0YGJ9MxJ5X/IOZbQ07tG5H+ddnQgc2I6/3qabuRfUZMNPjQ/lyV0lwAA9AOKBwBQiuIBAJSieAAApSgeAEApigcAUIriAQCUongAAKUoHgBAKYoHAFCK4gEAlKJ4AAClKB4AQCmKBwBQiuIBAJSieAAApSgeAEApigcAUIriAQCUongAAKWGqlc4KKfmPT99IDVPktYNjqVnqhH5mZ3SaHR7gpYcbCxLz1w5cDg9U0voql8qBpx/oS6VzH7AFg8AoBTFAwAoRfEAAEpRPACAUhQPAKAUxQMAKEXxAABKLbp4bG+0fZftR20/YvsjmYMBAPpTOx8gnZJ0bUTcb3ulpO/ZvjMiHk2aDQDQhxa9xRMRz0bE/c2f90l6TNL6rMEAAP0p5T0e22dJukjSvRl5AID+1Xbx2D5J0t9I+v2IeGmO8zfb3mZ72+7dS+MYYACAzmmreGwPa6Z0bo6I2+ZaJiK2RMR4RIyfcgo70QHAia6dvdos6cuSHouIz+WNBADoZ+1sgrxR0u9IeovtHzT//UbSXACAPrXo3akj4v9KyV+uAwDoe7zpAgAoRfEAAEpRPACAUhQPAKCUI6JsZau8Nv6dL03N9MhIap4kqZF/mdzx1H3pmZ2yv3E4PfO3Ln53embjlDXpmQMvvOIz0G17/Np/k54pSct35T9vXH/3wfTMg6fn30eX755Mz5waHUzPHNlzJD1TkqbGhtMzD63LzXz4G5/X/j3PzLkDGls8AIBSFA8AoBTFAwAoRfEAAEpRPACAUhQPAKAUxQMAKEXxAABKUTwAgFIUDwCgFMUDAChF8QAASlE8AIBSFA8AoBTFAwAoRfEAAEpRPACAUhQPAKAUxQMAKEXxAABKUTwAgFJDpWuz5eFluZFDtX/CiWCgE89HRnKvd0nSUAfmHM6/PbmRHtkxMeD80A5ELpk5Bzvz3D4GOzBsIbZ4AAClKB4AQCmKBwBQiuIBAJSieAAApSgeAECptovH9qDt79v++4yBAAD9LWOL5yOSHkvIAQCcANoqHtsbJP2mpC/ljAMA6HftbvF8XtJHJS2hz2YDALpp0cVj+x2SdkbE9xZYbrPtbba3Tcbhxa4OANAn2tnieaOkd9n+iaSvSHqL7b+evVBEbImI8YgYH/byNlYHAOgHiy6eiPhYRGyIiLMkXSHp2xHxnrTJAAB9ic/xAABKpRwDPiL+UdI/ZmQBAPobWzwAgFIUDwCgFMUDAChF8QAASlE8AIBSKXu1tS6kSD66TkRuniQ18o8AtL/RmaM2DHTgucPowLL0TNnpkTHE86ZsbuTfnwamOpA5MZ2e2RjOv416ujNHE/N0Bx73sv/8Y+RxzwUAlKJ4AAClKB4AQCmKBwBQiuIBAJSieAAApSgeAEApigcAUIriAQCUongAAKUoHgBAKYoHAFCK4gEAlKJ4AAClKB4AQCmKBwBQiuIBAJSieAAApSgeAEApigcAUGqocmVnXnBAf3j7famZLzZGU/M65bcufndngkeW5Wfa6ZH/55+/lp75x8+fl575iyM/S8/8zOeuSM+UpINn5Gee9Cc70jOffHpDeubaNQfTM/cfGknPvPDM/MtTkl48siI988fPnJaaN3lPzHseWzwAgFIUDwCgFMUDAChF8QAASlE8AIBSFA8AoBTFAwAo1Vbx2F5j+1bbj9t+zPavZA0GAOhP7X6A9M8l3RER/9n2MklL49OcAICuWXTx2F4t6U2S3itJETEhaSJnLABAv2rnpbZNknZJ+ivb37f9Jdtjsxeyvdn2NtvbXtzdaGN1AIB+0E7xDEl6vaQbIuIiSQckXTd7oYjYEhHjETG+5hT2ZQCAE107TbBd0vaIuLf5+62aKSIAAOa16OKJiOckPWP73OZJl0p6NGUqAEDfanevtg9Jurm5R9uPJP2X9kcCAPSztoonIn4gaTxpFgDACYB3+wEApSgeAEApigcAUIriAQCUanevtuOyb3qF7tp/fmrm6ED+UXoONpalZzZOWZOeKUkayn/uEB3I/OPnz0vP/MS6x9MzP7377PTMxrDTMyVJkR/57IFV6ZmNicH0zP2HRtIzJyfyHw637+vM/f7QZP6sMZl8vz/G7ZMtHgBAKYoHAFCK4gEAlKJ4AAClKB4AQCmKBwBQiuIBAJSieAAApSgeAEApigcAUIriAQCUongAAKUoHgBAKYoHAFCK4gEAlKJ4AAClKB4AQCmKBwBQiuIBAJSieAAApYYqVzY2cERvGH0yNXNSg6l5krRy4HB65j0vvCY9U5I0XHoVLtovjvwsPfPTu89Oz/zvpzyRnvm/pt6anilJMeD0zFNHD6Rn7hpZlZ65cjT/PrrfI+mZp4+9lJ4pSfsmlqdnvjC0MjfwGDdPtngAAKUoHgBAKYoHAFCK4gEAlKJ4AAClKB4AQCmKBwBQqq3isX2N7UdsP2z7Ftv5O5cDAPrKoovH9npJH5Y0HhEXSBqUdEXWYACA/tTuS21DklbYHpI0Kumn7Y8EAOhniy6eiNgh6bOSnpb0rKS9EfHNrMEAAP2pnZfaTpZ0uaRNks6UNGb7PXMst9n2Ntvb9u6ZWvykAIC+0M5LbW+V9OOI2BURk5Juk/SrsxeKiC0RMR4R46vXLo0DWgIAOqed4nla0iW2R21b0qWSHssZCwDQr9p5j+deSbdKul/SQ82sLUlzAQD6VFuvfUXEJyV9MmkWAMAJgCMXAABKUTwAgFIUDwCgFMUDACjliChb2eipG+O8/3hNamZ0ojo7cJG8eF5nLmc3OhKbbvUTTs9sDOdneir/err/j25Iz5Sk137h6vTMZS+lR2p6JD+zE7f7xmB+5tDh/ExJivybvqZX5Ob96KbP6dCzz8w5KVs8AIBSFA8AoBTFAwAoRfEAAEpRPACAUhQPAKAUxQMAKEXxAABKUTwAgFIUDwCgFMUDAChF8QAASlE8AIBSFA8AoBTFAwAoRfEAAEpRPACAUhQPAKAUxQMAKEXxAABKUTwAgFJDlStrLJP2b3DlKnvG8l0n5t/9soNndCA0OhA5kH89vfYLV6dnStIjH/xieub5N+TPOnQgPVLRgbvTwFR+5uG1+ZmS5A7c9of3JwceY0a2eAAApSgeAEApigcAUIriAQCUongAAKUoHgBAqQWLx/ZW2zttP3zUaWtt32n7ieb/J3d2TABAv2hli+dGSZfNOu06Sd+KiLMlfav5OwAAC1qweCLibkl7Zp18uaSbmj/fJOndyXMBAPrUYt/jOS0inm3+/Jyk05LmAQD0ubZ3LoiI0DEOjmB7s+1ttrdNH+jAsTMAAEvKYovnZ7bPkKTm/zvnWzAitkTEeESMD46NLXJ1AIB+sdjiuV3SVc2fr5L0tZxxAAD9rpXdqW+RdI+kc21vt/0+SddL+nXbT0h6a/N3AAAWtODXIkTElfOcdWnyLACAEwBHLgAAlKJ4AAClKB4AQCmKBwBQiuIBAJRacK+2TGtWH9A733lPamYjnJrXKQ99+HUdyY2B/L/fjXkPRLFoJ/3JjvTMZw+sSs88dTT/6BrP/O/XpGdK0vk3XJ2e+ej7v5ieefWOS9IzX718d3rm3qkV6ZmfOu3B9ExJmozp9MxP7Pzl1Lz/ecf89yW2eAAApSgeAEApigcAUIriAQCUongAAKUoHgBAKYoHAFCK4gEAlKJ4AAClKB4AQCmKBwBQiuIBAJSieAAApSgeAEApigcAUIriAQCUongAAKUoHgBAKYoHAFCK4gEAlBqqXNneieW646lfSs2McGpep6w5faQzwR348wemIj3zyac3pGc2JgbTM3eNrErPHO3QVT90ID/z6h2XpGd+cf130jN3Tnfgj++A333q7R3J3T+Zf6P6wPpvp+Z9beDgvOexxQMAKEXxAABKUTwAgFIUDwCgFMUDAChF8QAASi1YPLa32t5p++GjTvuM7cdtP2j7b22v6eyYAIB+0coWz42SLpt12p2SLoiI10n6V0kfS54LANCnFiyeiLhb0p5Zp30zIqaav35HUv6nAwEAfSnjPZ7fk/T1hBwAwAmgreKx/QeSpiTdfIxlNtveZnvb9EvzH0IBAHBiWHTx2H6vpHdI+u2ImPfgXhGxJSLGI2J8cNXoYlcHAOgTizpIqO3LJH1U0r+PCDZjAAAta2V36lsk3SPpXNvbbb9P0hckrZR0p+0f2P7LDs8JAOgTC27xRMSVc5z85Q7MAgA4AXDkAgBAKYoHAFCK4gEAlKJ4AAClKB4AQKlFfY5nsUaGprRp7Z6FFzwOE9ODqXmSNOB5Pw+7aBO7R9IzJSkGnJ45MDGdnrl2Tf7HvfYfyr9MV44eTs880liRnilJkX/V69XLd6dn7pw+kJ75qsGx9MzpaKRnbhrNvzwlaffESemZKwdyb/uDx3gcZYsHAFCK4gEAlKJ4AAClKB4AQCmKBwBQiuIBAJSieAAApSgeAEApigcAUIriAQCUongAAKUoHgBAKYoHAFCK4gEAlKJ4AAClKB4AQCmKBwBQiuIBAJSieAAApSgeAECpocqVTTYGtevgWGrmdCO/Owcc6ZnLRwfTMyVJzo9sDOeH7j80kp45OZF/893v/DkHO3TVD0zlZ+6dWpEf2gHT0UjPHHT+Y0mnLs8D08vSM5cp9zK15n8cZYsHAFCK4gEAlKJ4AAClKB4AQCmKBwBQiuIBAJSieAAApRYsHttbbe+0/fAc511rO2yv68x4AIB+08oWz42SLpt9ou2Nkt4m6enkmQAAfWzB4omIuyXtmeOsP5P0UekYH08FAGCWRb3HY/tySTsi4oEWlt1se5vtbVN7Dy5mdQCAPnLcB7uyPSrp45p5mW1BEbFF0hZJGjvnDLaOAOAEt5gtnl+QtEnSA7Z/ImmDpPttn545GACgPx33Fk9EPCTpVS//3iyf8Yh4PnEuAECfamV36lsk3SPpXNvbbb+v82MBAPrVgls8EXHlAueflTYNAKDvceQCAEApigcAUIriAQCUongAAKWOe3fqdqwePqS3nfl4auZkYzA1T5IGnP851+/uuSg9U5JiMP+5g6cb6ZkXnrkjPXP7vjXpmaePvZSe+eThVemZknR4bX7mp057MD3zd596e3rmptHd6Zl7p1akZ37+jG3pmZI0GdPpmdf89E2pec9PfX3e89jiAQCUongAAKUoHgBAKYoHAFCK4gEAlKJ4AAClKB4AQCmKBwBQiuIBAJSieAAApSgeAEApigcAUIriAQCUongAAKUoHgBAKYoHAFCK4gEAlKJ4AAClKB4AQCmKBwBQiuIBAJQaqlzZZAzquSOrKlfZM6bGhjuSG4NOz/R0pGe+eGRFeuahyfyb776J5emZkX8VSZKcfzVpMqbTM/dPjqRn7p44KT3zwPSy9MxOXJ6SNOzB9Mwjjdz7U+MYN3y2eAAApSgeAEApigcAUIriAQCUongAAKUoHgBAqQWLx/ZW2zttPzzr9A/Zftz2I7b/tHMjAgD6SStbPDdKuuzoE2y/WdLlki6MiNdK+mz+aACAfrRg8UTE3ZL2zDr5/ZKuj4gjzWV2dmA2AEAfWux7POdI+jXb99r+J9sXZw4FAOhfiz1GwpCktZIukXSxpK/afk1EvOIgHrY3S9osSSedPrbYOQEAfWKxWzzbJd0WM+6T1JC0bq4FI2JLRIxHxPjyk/OP2QQAWFoWWzx/J+nNkmT7HEnLJD2fNRQAoH8t+FKb7Vsk/QdJ62xvl/RJSVslbW3uYj0h6aq5XmYDAGC2BYsnIq6c56z3JM8CADgBcOQCAEApigcAUIriAQCUongAAKUoHgBAqcUeuWBR9h1ZrruePKdylT1j3brhbo/QOudH/viZ09IzYzL/edMLQyvTM8dWpEdKkob352d+Yucvp2d+YP230zNXDhxOz1ymRnrmNT99U3qmJB1p5D90/4+N/5ya98Cy+W+gbPEAAEpRPACAUhQPAKAUxQMAKEXxAABKUTwAgFIUDwCgFMUDAChF8QAASlE8AIBSFA8AoBTFAwAoRfEAAEpRPACAUhQPAKAUxQMAKEXxAABKUTwAgFIUDwCgFMUDACjliKhbmb1L0lMtLr5O0vMdHCcLc+ZaKnNKS2dW5sy1VOaUujvrqyPi1LnOKC2e42F7W0SMd3uOhTBnrqUyp7R0ZmXOXEtlTql3Z+WlNgBAKYoHAFCql4tnS7cHaBFz5loqc0pLZ1bmzLVU5pR6dNaefY8HANCfenmLBwDQhygeAEApigcAUIriAQCUongAAKX+H869rNC8y8JKAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.572 2.940 1.352 0.989 0.970 0.891 0.405 0.251 0.230 0.177 0.072 0.052\n",
            " 0.039 0.031 0.012 0.004 0.004 0.007]\n",
            "[0.5317647804810274, 0.16335739298653476, 0.07511546472382995, 0.054921627068028424, 0.05390616867076577, 0.04952232661739343, 0.022486349463995598, 0.013932731902136385, 0.012792662672300325, 0.009829012007199104, 0.004024926426955747, 0.002893959610103366, 0.002163271201445878, 0.001741116222641519, 0.0006928432299862775, 0.00021826337426103455, 0.00023351820917083064, 0.0004035851322244031]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation between features"
      ],
      "metadata": {
        "id": "NmsxwI9r9qM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlations = []\n",
        "matrix = []\n",
        "\n",
        "for i in dataset_norm.columns[1:]:\n",
        "  feature = []\n",
        "  for j in dataset_norm.columns[1:]:\n",
        "    print(f'Correlation between {i} and {j}')\n",
        "    correlation = np.corrcoef(dataset_norm[i], dataset_norm[j])\n",
        "    if i != j:\n",
        "      correlations.append(abs(correlation[0][1]))\n",
        "      feature.append(abs(correlation[0][1]))\n",
        "      print(correlation[0][1])\n",
        "  print(f'Mean of {i} correlations: {np.mean(feature)}')\n",
        "  print('')\n",
        "  matrix.append(feature)\n",
        "\n",
        "print(f'Mean of all correlations: {np.mean(correlations)}')"
      ],
      "metadata": {
        "id": "-5qjvKw79pJ0",
        "outputId": "b38aecda-3d1d-4086-fc15-c17677070147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between PLN1 and PLN1\n",
            "Correlation between PLN1 and PLN2\n",
            "0.9530638927686161\n",
            "Correlation between PLN1 and PLN3\n",
            "0.9606664987977857\n",
            "Correlation between PLN1 and ULL1\n",
            "-0.7274016376341783\n",
            "Correlation between PLN1 and ULL2\n",
            "-0.6955282277514698\n",
            "Correlation between PLN1 and ULL3\n",
            "-0.7030835410050382\n",
            "Correlation between PLN1 and COS_PHI1\n",
            "0.8410401295195357\n",
            "Correlation between PLN1 and COS_PHI2\n",
            "0.6731338062873107\n",
            "Correlation between PLN1 and COS_PHI3\n",
            "0.8122370309192153\n",
            "Correlation between PLN1 and FREQ\n",
            "-0.1545159794969928\n",
            "Correlation between PLN1 and RC_DC\n",
            "0.041447902380906114\n",
            "Correlation between PLN1 and RC_AC\n",
            "0.6311099014117805\n",
            "Correlation between PLN1 and RC_50Hz\n",
            "0.3688113546135114\n",
            "Correlation between PLN1 and RC_150Hz\n",
            "0.5078743784519385\n",
            "Correlation between PLN1 and RC_<100Hz\n",
            "0.4309325330867657\n",
            "Correlation between PLN1 and RC_100Hz-1kHz\n",
            "0.6585953463453892\n",
            "Correlation between PLN1 and RC_>1kHz\n",
            "0.5928797475823842\n",
            "Correlation between PLN1 and RC_>10kHz\n",
            "0.31619183414655355\n",
            "Mean of PLN1 correlations: 0.5922655142470219\n",
            "\n",
            "Correlation between PLN2 and PLN1\n",
            "0.9530638927686161\n",
            "Correlation between PLN2 and PLN2\n",
            "Correlation between PLN2 and PLN3\n",
            "0.9452605980705139\n",
            "Correlation between PLN2 and ULL1\n",
            "-0.6920070109902812\n",
            "Correlation between PLN2 and ULL2\n",
            "-0.6704566233203503\n",
            "Correlation between PLN2 and ULL3\n",
            "-0.6734582119423186\n",
            "Correlation between PLN2 and COS_PHI1\n",
            "0.7986365971843635\n",
            "Correlation between PLN2 and COS_PHI2\n",
            "0.7023352006830498\n",
            "Correlation between PLN2 and COS_PHI3\n",
            "0.8038123821731546\n",
            "Correlation between PLN2 and FREQ\n",
            "-0.14213527867385364\n",
            "Correlation between PLN2 and RC_DC\n",
            "0.039207762733898144\n",
            "Correlation between PLN2 and RC_AC\n",
            "0.6232451337648502\n",
            "Correlation between PLN2 and RC_50Hz\n",
            "0.35899547217519356\n",
            "Correlation between PLN2 and RC_150Hz\n",
            "0.4908468912124751\n",
            "Correlation between PLN2 and RC_<100Hz\n",
            "0.4172313931163452\n",
            "Correlation between PLN2 and RC_100Hz-1kHz\n",
            "0.6488235868701706\n",
            "Correlation between PLN2 and RC_>1kHz\n",
            "0.5891663952522229\n",
            "Correlation between PLN2 and RC_>10kHz\n",
            "0.31188438312240335\n",
            "Mean of PLN2 correlations: 0.5800333420031801\n",
            "\n",
            "Correlation between PLN3 and PLN1\n",
            "0.9606664987977857\n",
            "Correlation between PLN3 and PLN2\n",
            "0.9452605980705139\n",
            "Correlation between PLN3 and PLN3\n",
            "Correlation between PLN3 and ULL1\n",
            "-0.7002177438968478\n",
            "Correlation between PLN3 and ULL2\n",
            "-0.6722798995076359\n",
            "Correlation between PLN3 and ULL3\n",
            "-0.6821156558367119\n",
            "Correlation between PLN3 and COS_PHI1\n",
            "0.8022338627218534\n",
            "Correlation between PLN3 and COS_PHI2\n",
            "0.6694582338358985\n",
            "Correlation between PLN3 and COS_PHI3\n",
            "0.831379706888533\n",
            "Correlation between PLN3 and FREQ\n",
            "-0.14967487104652202\n",
            "Correlation between PLN3 and RC_DC\n",
            "0.04088450891644734\n",
            "Correlation between PLN3 and RC_AC\n",
            "0.6281657734892854\n",
            "Correlation between PLN3 and RC_50Hz\n",
            "0.36563522876627164\n",
            "Correlation between PLN3 and RC_150Hz\n",
            "0.4989635979541192\n",
            "Correlation between PLN3 and RC_<100Hz\n",
            "0.423953449978989\n",
            "Correlation between PLN3 and RC_100Hz-1kHz\n",
            "0.653923668551288\n",
            "Correlation between PLN3 and RC_>1kHz\n",
            "0.5911138593179586\n",
            "Correlation between PLN3 and RC_>10kHz\n",
            "0.31781241506277835\n",
            "Mean of PLN3 correlations: 0.5843376219199671\n",
            "\n",
            "Correlation between ULL1 and PLN1\n",
            "-0.7274016376341783\n",
            "Correlation between ULL1 and PLN2\n",
            "-0.6920070109902812\n",
            "Correlation between ULL1 and PLN3\n",
            "-0.7002177438968478\n",
            "Correlation between ULL1 and ULL1\n",
            "Correlation between ULL1 and ULL2\n",
            "0.9939941350683594\n",
            "Correlation between ULL1 and ULL3\n",
            "0.9618955396414088\n",
            "Correlation between ULL1 and COS_PHI1\n",
            "-0.6035602236966966\n",
            "Correlation between ULL1 and COS_PHI2\n",
            "-0.4998011468511354\n",
            "Correlation between ULL1 and COS_PHI3\n",
            "-0.5935572901249871\n",
            "Correlation between ULL1 and FREQ\n",
            "0.13197327822064744\n",
            "Correlation between ULL1 and RC_DC\n",
            "-0.019422769445639664\n",
            "Correlation between ULL1 and RC_AC\n",
            "-0.4224120693563289\n",
            "Correlation between ULL1 and RC_50Hz\n",
            "-0.27779168346606625\n",
            "Correlation between ULL1 and RC_150Hz\n",
            "-0.39202737581282215\n",
            "Correlation between ULL1 and RC_<100Hz\n",
            "-0.32940535648076114\n",
            "Correlation between ULL1 and RC_100Hz-1kHz\n",
            "-0.43980057374684045\n",
            "Correlation between ULL1 and RC_>1kHz\n",
            "-0.37447740688167575\n",
            "Correlation between ULL1 and RC_>10kHz\n",
            "-0.25420475464234854\n",
            "Mean of ULL1 correlations: 0.49493823505629564\n",
            "\n",
            "Correlation between ULL2 and PLN1\n",
            "-0.6955282277514698\n",
            "Correlation between ULL2 and PLN2\n",
            "-0.6704566233203503\n",
            "Correlation between ULL2 and PLN3\n",
            "-0.6722798995076359\n",
            "Correlation between ULL2 and ULL1\n",
            "0.9939941350683594\n",
            "Correlation between ULL2 and ULL2\n",
            "Correlation between ULL2 and ULL3\n",
            "0.9679344064619085\n",
            "Correlation between ULL2 and COS_PHI1\n",
            "-0.5720923780407858\n",
            "Correlation between ULL2 and COS_PHI2\n",
            "-0.47937831082658844\n",
            "Correlation between ULL2 and COS_PHI3\n",
            "-0.567700112669604\n",
            "Correlation between ULL2 and FREQ\n",
            "0.12234449713473242\n",
            "Correlation between ULL2 and RC_DC\n",
            "-0.015685463412389872\n",
            "Correlation between ULL2 and RC_AC\n",
            "-0.40423600542104837\n",
            "Correlation between ULL2 and RC_50Hz\n",
            "-0.27269488072813736\n",
            "Correlation between ULL2 and RC_150Hz\n",
            "-0.3823625567194393\n",
            "Correlation between ULL2 and RC_<100Hz\n",
            "-0.32256670279212446\n",
            "Correlation between ULL2 and RC_100Hz-1kHz\n",
            "-0.4200868940113775\n",
            "Correlation between ULL2 and RC_>1kHz\n",
            "-0.35767437058385176\n",
            "Correlation between ULL2 and RC_>10kHz\n",
            "-0.24924688411542353\n",
            "Mean of ULL2 correlations: 0.48036837344501343\n",
            "\n",
            "Correlation between ULL3 and PLN1\n",
            "-0.7030835410050382\n",
            "Correlation between ULL3 and PLN2\n",
            "-0.6734582119423186\n",
            "Correlation between ULL3 and PLN3\n",
            "-0.6821156558367119\n",
            "Correlation between ULL3 and ULL1\n",
            "0.9618955396414088\n",
            "Correlation between ULL3 and ULL2\n",
            "0.9679344064619085\n",
            "Correlation between ULL3 and ULL3\n",
            "Correlation between ULL3 and COS_PHI1\n",
            "-0.5631552795349817\n",
            "Correlation between ULL3 and COS_PHI2\n",
            "-0.4605683549411026\n",
            "Correlation between ULL3 and COS_PHI3\n",
            "-0.5678746499327133\n",
            "Correlation between ULL3 and FREQ\n",
            "0.11732253505588489\n",
            "Correlation between ULL3 and RC_DC\n",
            "-0.018546293523528313\n",
            "Correlation between ULL3 and RC_AC\n",
            "-0.42374208804827185\n",
            "Correlation between ULL3 and RC_50Hz\n",
            "-0.2972458537127213\n",
            "Correlation between ULL3 and RC_150Hz\n",
            "-0.4149620582027394\n",
            "Correlation between ULL3 and RC_<100Hz\n",
            "-0.35093038054779213\n",
            "Correlation between ULL3 and RC_100Hz-1kHz\n",
            "-0.44085919789991956\n",
            "Correlation between ULL3 and RC_>1kHz\n",
            "-0.3748521278843218\n",
            "Correlation between ULL3 and RC_>10kHz\n",
            "-0.2427669277249782\n",
            "Mean of ULL3 correlations: 0.48595959422919655\n",
            "\n",
            "Correlation between COS_PHI1 and PLN1\n",
            "0.8410401295195357\n",
            "Correlation between COS_PHI1 and PLN2\n",
            "0.7986365971843635\n",
            "Correlation between COS_PHI1 and PLN3\n",
            "0.8022338627218534\n",
            "Correlation between COS_PHI1 and ULL1\n",
            "-0.6035602236966966\n",
            "Correlation between COS_PHI1 and ULL2\n",
            "-0.5720923780407858\n",
            "Correlation between COS_PHI1 and ULL3\n",
            "-0.5631552795349817\n",
            "Correlation between COS_PHI1 and COS_PHI1\n",
            "Correlation between COS_PHI1 and COS_PHI2\n",
            "0.6721486971436302\n",
            "Correlation between COS_PHI1 and COS_PHI3\n",
            "0.7679288479423111\n",
            "Correlation between COS_PHI1 and FREQ\n",
            "-0.147035147167703\n",
            "Correlation between COS_PHI1 and RC_DC\n",
            "0.02856080648274264\n",
            "Correlation between COS_PHI1 and RC_AC\n",
            "0.5224505954850469\n",
            "Correlation between COS_PHI1 and RC_50Hz\n",
            "0.28598483106508726\n",
            "Correlation between COS_PHI1 and RC_150Hz\n",
            "0.4069034148899058\n",
            "Correlation between COS_PHI1 and RC_<100Hz\n",
            "0.3450622542196257\n",
            "Correlation between COS_PHI1 and RC_100Hz-1kHz\n",
            "0.5443587853537228\n",
            "Correlation between COS_PHI1 and RC_>1kHz\n",
            "0.4936793319894297\n",
            "Correlation between COS_PHI1 and RC_>10kHz\n",
            "0.2703843372754415\n",
            "Mean of COS_PHI1 correlations: 0.5097185599831096\n",
            "\n",
            "Correlation between COS_PHI2 and PLN1\n",
            "0.6731338062873107\n",
            "Correlation between COS_PHI2 and PLN2\n",
            "0.7023352006830498\n",
            "Correlation between COS_PHI2 and PLN3\n",
            "0.6694582338358985\n",
            "Correlation between COS_PHI2 and ULL1\n",
            "-0.4998011468511354\n",
            "Correlation between COS_PHI2 and ULL2\n",
            "-0.47937831082658844\n",
            "Correlation between COS_PHI2 and ULL3\n",
            "-0.4605683549411026\n",
            "Correlation between COS_PHI2 and COS_PHI1\n",
            "0.6721486971436302\n",
            "Correlation between COS_PHI2 and COS_PHI2\n",
            "Correlation between COS_PHI2 and COS_PHI3\n",
            "0.6853907893926222\n",
            "Correlation between COS_PHI2 and FREQ\n",
            "-0.11239331571367385\n",
            "Correlation between COS_PHI2 and RC_DC\n",
            "0.024512304278753623\n",
            "Correlation between COS_PHI2 and RC_AC\n",
            "0.4295743933735341\n",
            "Correlation between COS_PHI2 and RC_50Hz\n",
            "0.25029130339434186\n",
            "Correlation between COS_PHI2 and RC_150Hz\n",
            "0.34492310440673435\n",
            "Correlation between COS_PHI2 and RC_<100Hz\n",
            "0.29451321192232705\n",
            "Correlation between COS_PHI2 and RC_100Hz-1kHz\n",
            "0.4465840329092465\n",
            "Correlation between COS_PHI2 and RC_>1kHz\n",
            "0.40542889130635923\n",
            "Correlation between COS_PHI2 and RC_>10kHz\n",
            "0.23200703950807844\n",
            "Mean of COS_PHI2 correlations: 0.4342613021631992\n",
            "\n",
            "Correlation between COS_PHI3 and PLN1\n",
            "0.8122370309192153\n",
            "Correlation between COS_PHI3 and PLN2\n",
            "0.8038123821731546\n",
            "Correlation between COS_PHI3 and PLN3\n",
            "0.831379706888533\n",
            "Correlation between COS_PHI3 and ULL1\n",
            "-0.5935572901249871\n",
            "Correlation between COS_PHI3 and ULL2\n",
            "-0.567700112669604\n",
            "Correlation between COS_PHI3 and ULL3\n",
            "-0.5678746499327133\n",
            "Correlation between COS_PHI3 and COS_PHI1\n",
            "0.7679288479423111\n",
            "Correlation between COS_PHI3 and COS_PHI2\n",
            "0.6853907893926222\n",
            "Correlation between COS_PHI3 and COS_PHI3\n",
            "Correlation between COS_PHI3 and FREQ\n",
            "-0.13593458098321448\n",
            "Correlation between COS_PHI3 and RC_DC\n",
            "0.03770701540947717\n",
            "Correlation between COS_PHI3 and RC_AC\n",
            "0.5128776647152186\n",
            "Correlation between COS_PHI3 and RC_50Hz\n",
            "0.2954004112175192\n",
            "Correlation between COS_PHI3 and RC_150Hz\n",
            "0.4161431739321745\n",
            "Correlation between COS_PHI3 and RC_<100Hz\n",
            "0.3510288668281722\n",
            "Correlation between COS_PHI3 and RC_100Hz-1kHz\n",
            "0.5325198797906967\n",
            "Correlation between COS_PHI3 and RC_>1kHz\n",
            "0.4825962763757615\n",
            "Correlation between COS_PHI3 and RC_>10kHz\n",
            "0.2591023016571135\n",
            "Mean of COS_PHI3 correlations: 0.5090112341736759\n",
            "\n",
            "Correlation between FREQ and PLN1\n",
            "-0.1545159794969928\n",
            "Correlation between FREQ and PLN2\n",
            "-0.14213527867385364\n",
            "Correlation between FREQ and PLN3\n",
            "-0.14967487104652202\n",
            "Correlation between FREQ and ULL1\n",
            "0.13197327822064744\n",
            "Correlation between FREQ and ULL2\n",
            "0.12234449713473242\n",
            "Correlation between FREQ and ULL3\n",
            "0.11732253505588489\n",
            "Correlation between FREQ and COS_PHI1\n",
            "-0.147035147167703\n",
            "Correlation between FREQ and COS_PHI2\n",
            "-0.11239331571367385\n",
            "Correlation between FREQ and COS_PHI3\n",
            "-0.13593458098321448\n",
            "Correlation between FREQ and FREQ\n",
            "Correlation between FREQ and RC_DC\n",
            "-0.01080999936710587\n",
            "Correlation between FREQ and RC_AC\n",
            "-0.1076867560857399\n",
            "Correlation between FREQ and RC_50Hz\n",
            "-0.0599540617400453\n",
            "Correlation between FREQ and RC_150Hz\n",
            "-0.0746200724726473\n",
            "Correlation between FREQ and RC_<100Hz\n",
            "-0.05897914444129208\n",
            "Correlation between FREQ and RC_100Hz-1kHz\n",
            "-0.11163642547386085\n",
            "Correlation between FREQ and RC_>1kHz\n",
            "-0.10135632693877397\n",
            "Correlation between FREQ and RC_>10kHz\n",
            "-0.04416443889960932\n",
            "Mean of FREQ correlations: 0.1048551005242529\n",
            "\n",
            "Correlation between RC_DC and PLN1\n",
            "0.041447902380906114\n",
            "Correlation between RC_DC and PLN2\n",
            "0.039207762733898144\n",
            "Correlation between RC_DC and PLN3\n",
            "0.04088450891644734\n",
            "Correlation between RC_DC and ULL1\n",
            "-0.019422769445639664\n",
            "Correlation between RC_DC and ULL2\n",
            "-0.015685463412389872\n",
            "Correlation between RC_DC and ULL3\n",
            "-0.018546293523528313\n",
            "Correlation between RC_DC and COS_PHI1\n",
            "0.02856080648274264\n",
            "Correlation between RC_DC and COS_PHI2\n",
            "0.024512304278753623\n",
            "Correlation between RC_DC and COS_PHI3\n",
            "0.03770701540947717\n",
            "Correlation between RC_DC and FREQ\n",
            "-0.01080999936710587\n",
            "Correlation between RC_DC and RC_DC\n",
            "Correlation between RC_DC and RC_AC\n",
            "0.009408275400609279\n",
            "Correlation between RC_DC and RC_50Hz\n",
            "-0.06680533222156979\n",
            "Correlation between RC_DC and RC_150Hz\n",
            "-0.06653181935938085\n",
            "Correlation between RC_DC and RC_<100Hz\n",
            "-0.08081309086755864\n",
            "Correlation between RC_DC and RC_100Hz-1kHz\n",
            "0.01573317644502217\n",
            "Correlation between RC_DC and RC_>1kHz\n",
            "0.011862953683483864\n",
            "Correlation between RC_DC and RC_>10kHz\n",
            "-0.07707048019590787\n",
            "Mean of RC_DC correlations: 0.03558882083084831\n",
            "\n",
            "Correlation between RC_AC and PLN1\n",
            "0.6311099014117805\n",
            "Correlation between RC_AC and PLN2\n",
            "0.6232451337648502\n",
            "Correlation between RC_AC and PLN3\n",
            "0.6281657734892854\n",
            "Correlation between RC_AC and ULL1\n",
            "-0.4224120693563289\n",
            "Correlation between RC_AC and ULL2\n",
            "-0.40423600542104837\n",
            "Correlation between RC_AC and ULL3\n",
            "-0.42374208804827185\n",
            "Correlation between RC_AC and COS_PHI1\n",
            "0.5224505954850469\n",
            "Correlation between RC_AC and COS_PHI2\n",
            "0.4295743933735341\n",
            "Correlation between RC_AC and COS_PHI3\n",
            "0.5128776647152186\n",
            "Correlation between RC_AC and FREQ\n",
            "-0.1076867560857399\n",
            "Correlation between RC_AC and RC_DC\n",
            "0.009408275400609279\n",
            "Correlation between RC_AC and RC_AC\n",
            "Correlation between RC_AC and RC_50Hz\n",
            "0.5988353180559405\n",
            "Correlation between RC_AC and RC_150Hz\n",
            "0.6870800166525872\n",
            "Correlation between RC_AC and RC_<100Hz\n",
            "0.6478497540541008\n",
            "Correlation between RC_AC and RC_100Hz-1kHz\n",
            "0.9937633088247765\n",
            "Correlation between RC_AC and RC_>1kHz\n",
            "0.9856775813519929\n",
            "Correlation between RC_AC and RC_>10kHz\n",
            "0.6405906580239059\n",
            "Mean of RC_AC correlations: 0.5452179584420599\n",
            "\n",
            "Correlation between RC_50Hz and PLN1\n",
            "0.3688113546135114\n",
            "Correlation between RC_50Hz and PLN2\n",
            "0.35899547217519356\n",
            "Correlation between RC_50Hz and PLN3\n",
            "0.36563522876627164\n",
            "Correlation between RC_50Hz and ULL1\n",
            "-0.27779168346606625\n",
            "Correlation between RC_50Hz and ULL2\n",
            "-0.27269488072813736\n",
            "Correlation between RC_50Hz and ULL3\n",
            "-0.2972458537127213\n",
            "Correlation between RC_50Hz and COS_PHI1\n",
            "0.28598483106508726\n",
            "Correlation between RC_50Hz and COS_PHI2\n",
            "0.25029130339434186\n",
            "Correlation between RC_50Hz and COS_PHI3\n",
            "0.2954004112175192\n",
            "Correlation between RC_50Hz and FREQ\n",
            "-0.0599540617400453\n",
            "Correlation between RC_50Hz and RC_DC\n",
            "-0.06680533222156979\n",
            "Correlation between RC_50Hz and RC_AC\n",
            "0.5988353180559405\n",
            "Correlation between RC_50Hz and RC_50Hz\n",
            "Correlation between RC_50Hz and RC_150Hz\n",
            "0.9325844626970944\n",
            "Correlation between RC_50Hz and RC_<100Hz\n",
            "0.9378468651085988\n",
            "Correlation between RC_50Hz and RC_100Hz-1kHz\n",
            "0.5680814090699112\n",
            "Correlation between RC_50Hz and RC_>1kHz\n",
            "0.5226845889912008\n",
            "Correlation between RC_50Hz and RC_>10kHz\n",
            "0.8215943251700436\n",
            "Mean of RC_50Hz correlations: 0.4283080813054856\n",
            "\n",
            "Correlation between RC_150Hz and PLN1\n",
            "0.5078743784519385\n",
            "Correlation between RC_150Hz and PLN2\n",
            "0.4908468912124751\n",
            "Correlation between RC_150Hz and PLN3\n",
            "0.4989635979541192\n",
            "Correlation between RC_150Hz and ULL1\n",
            "-0.39202737581282215\n",
            "Correlation between RC_150Hz and ULL2\n",
            "-0.3823625567194393\n",
            "Correlation between RC_150Hz and ULL3\n",
            "-0.4149620582027394\n",
            "Correlation between RC_150Hz and COS_PHI1\n",
            "0.4069034148899058\n",
            "Correlation between RC_150Hz and COS_PHI2\n",
            "0.34492310440673435\n",
            "Correlation between RC_150Hz and COS_PHI3\n",
            "0.4161431739321745\n",
            "Correlation between RC_150Hz and FREQ\n",
            "-0.0746200724726473\n",
            "Correlation between RC_150Hz and RC_DC\n",
            "-0.06653181935938085\n",
            "Correlation between RC_150Hz and RC_AC\n",
            "0.6870800166525872\n",
            "Correlation between RC_150Hz and RC_50Hz\n",
            "0.9325844626970944\n",
            "Correlation between RC_150Hz and RC_150Hz\n",
            "Correlation between RC_150Hz and RC_<100Hz\n",
            "0.9869431585782875\n",
            "Correlation between RC_150Hz and RC_100Hz-1kHz\n",
            "0.6594755799243152\n",
            "Correlation between RC_150Hz and RC_>1kHz\n",
            "0.6031328223115229\n",
            "Correlation between RC_150Hz and RC_>10kHz\n",
            "0.8525990801808159\n",
            "Mean of RC_150Hz correlations: 0.5128219743387646\n",
            "\n",
            "Correlation between RC_<100Hz and PLN1\n",
            "0.4309325330867657\n",
            "Correlation between RC_<100Hz and PLN2\n",
            "0.4172313931163452\n",
            "Correlation between RC_<100Hz and PLN3\n",
            "0.423953449978989\n",
            "Correlation between RC_<100Hz and ULL1\n",
            "-0.32940535648076114\n",
            "Correlation between RC_<100Hz and ULL2\n",
            "-0.32256670279212446\n",
            "Correlation between RC_<100Hz and ULL3\n",
            "-0.35093038054779213\n",
            "Correlation between RC_<100Hz and COS_PHI1\n",
            "0.3450622542196257\n",
            "Correlation between RC_<100Hz and COS_PHI2\n",
            "0.29451321192232705\n",
            "Correlation between RC_<100Hz and COS_PHI3\n",
            "0.3510288668281722\n",
            "Correlation between RC_<100Hz and FREQ\n",
            "-0.05897914444129208\n",
            "Correlation between RC_<100Hz and RC_DC\n",
            "-0.08081309086755864\n",
            "Correlation between RC_<100Hz and RC_AC\n",
            "0.6478497540541008\n",
            "Correlation between RC_<100Hz and RC_50Hz\n",
            "0.9378468651085988\n",
            "Correlation between RC_<100Hz and RC_150Hz\n",
            "0.9869431585782875\n",
            "Correlation between RC_<100Hz and RC_<100Hz\n",
            "Correlation between RC_<100Hz and RC_100Hz-1kHz\n",
            "0.6163156439742198\n",
            "Correlation between RC_<100Hz and RC_>1kHz\n",
            "0.5681934410881461\n",
            "Correlation between RC_<100Hz and RC_>10kHz\n",
            "0.8697462185366136\n",
            "Mean of RC_<100Hz correlations: 0.47248890974245406\n",
            "\n",
            "Correlation between RC_100Hz-1kHz and PLN1\n",
            "0.6585953463453892\n",
            "Correlation between RC_100Hz-1kHz and PLN2\n",
            "0.6488235868701706\n",
            "Correlation between RC_100Hz-1kHz and PLN3\n",
            "0.653923668551288\n",
            "Correlation between RC_100Hz-1kHz and ULL1\n",
            "-0.43980057374684045\n",
            "Correlation between RC_100Hz-1kHz and ULL2\n",
            "-0.4200868940113775\n",
            "Correlation between RC_100Hz-1kHz and ULL3\n",
            "-0.44085919789991956\n",
            "Correlation between RC_100Hz-1kHz and COS_PHI1\n",
            "0.5443587853537228\n",
            "Correlation between RC_100Hz-1kHz and COS_PHI2\n",
            "0.4465840329092465\n",
            "Correlation between RC_100Hz-1kHz and COS_PHI3\n",
            "0.5325198797906967\n",
            "Correlation between RC_100Hz-1kHz and FREQ\n",
            "-0.11163642547386085\n",
            "Correlation between RC_100Hz-1kHz and RC_DC\n",
            "0.01573317644502217\n",
            "Correlation between RC_100Hz-1kHz and RC_AC\n",
            "0.9937633088247765\n",
            "Correlation between RC_100Hz-1kHz and RC_50Hz\n",
            "0.5680814090699112\n",
            "Correlation between RC_100Hz-1kHz and RC_150Hz\n",
            "0.6594755799243152\n",
            "Correlation between RC_100Hz-1kHz and RC_<100Hz\n",
            "0.6163156439742198\n",
            "Correlation between RC_100Hz-1kHz and RC_100Hz-1kHz\n",
            "Correlation between RC_100Hz-1kHz and RC_>1kHz\n",
            "0.9842987879976385\n",
            "Correlation between RC_100Hz-1kHz and RC_>10kHz\n",
            "0.6079125821841566\n",
            "Mean of RC_100Hz-1kHz correlations: 0.5495746399630912\n",
            "\n",
            "Correlation between RC_>1kHz and PLN1\n",
            "0.5928797475823842\n",
            "Correlation between RC_>1kHz and PLN2\n",
            "0.5891663952522229\n",
            "Correlation between RC_>1kHz and PLN3\n",
            "0.5911138593179586\n",
            "Correlation between RC_>1kHz and ULL1\n",
            "-0.37447740688167575\n",
            "Correlation between RC_>1kHz and ULL2\n",
            "-0.35767437058385176\n",
            "Correlation between RC_>1kHz and ULL3\n",
            "-0.3748521278843218\n",
            "Correlation between RC_>1kHz and COS_PHI1\n",
            "0.4936793319894297\n",
            "Correlation between RC_>1kHz and COS_PHI2\n",
            "0.40542889130635923\n",
            "Correlation between RC_>1kHz and COS_PHI3\n",
            "0.4825962763757615\n",
            "Correlation between RC_>1kHz and FREQ\n",
            "-0.10135632693877397\n",
            "Correlation between RC_>1kHz and RC_DC\n",
            "0.011862953683483864\n",
            "Correlation between RC_>1kHz and RC_AC\n",
            "0.9856775813519929\n",
            "Correlation between RC_>1kHz and RC_50Hz\n",
            "0.5226845889912008\n",
            "Correlation between RC_>1kHz and RC_150Hz\n",
            "0.6031328223115229\n",
            "Correlation between RC_>1kHz and RC_<100Hz\n",
            "0.5681934410881461\n",
            "Correlation between RC_>1kHz and RC_100Hz-1kHz\n",
            "0.9842987879976385\n",
            "Correlation between RC_>1kHz and RC_>1kHz\n",
            "Correlation between RC_>1kHz and RC_>10kHz\n",
            "0.5866515939691284\n",
            "Mean of RC_>1kHz correlations: 0.507395676676815\n",
            "\n",
            "Correlation between RC_>10kHz and PLN1\n",
            "0.31619183414655355\n",
            "Correlation between RC_>10kHz and PLN2\n",
            "0.31188438312240335\n",
            "Correlation between RC_>10kHz and PLN3\n",
            "0.31781241506277835\n",
            "Correlation between RC_>10kHz and ULL1\n",
            "-0.25420475464234854\n",
            "Correlation between RC_>10kHz and ULL2\n",
            "-0.24924688411542353\n",
            "Correlation between RC_>10kHz and ULL3\n",
            "-0.2427669277249782\n",
            "Correlation between RC_>10kHz and COS_PHI1\n",
            "0.2703843372754415\n",
            "Correlation between RC_>10kHz and COS_PHI2\n",
            "0.23200703950807844\n",
            "Correlation between RC_>10kHz and COS_PHI3\n",
            "0.2591023016571135\n",
            "Correlation between RC_>10kHz and FREQ\n",
            "-0.04416443889960932\n",
            "Correlation between RC_>10kHz and RC_DC\n",
            "-0.07707048019590787\n",
            "Correlation between RC_>10kHz and RC_AC\n",
            "0.6405906580239059\n",
            "Correlation between RC_>10kHz and RC_50Hz\n",
            "0.8215943251700436\n",
            "Correlation between RC_>10kHz and RC_150Hz\n",
            "0.8525990801808159\n",
            "Correlation between RC_>10kHz and RC_<100Hz\n",
            "0.8697462185366136\n",
            "Correlation between RC_>10kHz and RC_100Hz-1kHz\n",
            "0.6079125821841566\n",
            "Correlation between RC_>10kHz and RC_>1kHz\n",
            "0.5866515939691284\n",
            "Correlation between RC_>10kHz and RC_>10kHz\n",
            "Mean of RC_>10kHz correlations: 0.4090547208479588\n",
            "\n",
            "Mean of all correlations: 0.45756664777179945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(matrix)):\n",
        "  print(matrix[i])"
      ],
      "metadata": {
        "id": "-nsjlNPvC5k5",
        "outputId": "1154ff1d-1ab5-4e23-8bae-d065cfeaa115",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9530638927686161, 0.9606664987977857, 0.7274016376341783, 0.6955282277514698, 0.7030835410050382, 0.8410401295195357, 0.6731338062873107, 0.8122370309192153, 0.1545159794969928, 0.041447902380906114, 0.6311099014117805, 0.3688113546135114, 0.5078743784519385, 0.4309325330867657, 0.6585953463453892, 0.5928797475823842, 0.31619183414655355]\n",
            "[0.9530638927686161, 0.9452605980705139, 0.6920070109902812, 0.6704566233203503, 0.6734582119423186, 0.7986365971843635, 0.7023352006830498, 0.8038123821731546, 0.14213527867385364, 0.039207762733898144, 0.6232451337648502, 0.35899547217519356, 0.4908468912124751, 0.4172313931163452, 0.6488235868701706, 0.5891663952522229, 0.31188438312240335]\n",
            "[0.9606664987977857, 0.9452605980705139, 0.7002177438968478, 0.6722798995076359, 0.6821156558367119, 0.8022338627218534, 0.6694582338358985, 0.831379706888533, 0.14967487104652202, 0.04088450891644734, 0.6281657734892854, 0.36563522876627164, 0.4989635979541192, 0.423953449978989, 0.653923668551288, 0.5911138593179586, 0.31781241506277835]\n",
            "[0.7274016376341783, 0.6920070109902812, 0.7002177438968478, 0.9939941350683594, 0.9618955396414088, 0.6035602236966966, 0.4998011468511354, 0.5935572901249871, 0.13197327822064744, 0.019422769445639664, 0.4224120693563289, 0.27779168346606625, 0.39202737581282215, 0.32940535648076114, 0.43980057374684045, 0.37447740688167575, 0.25420475464234854]\n",
            "[0.6955282277514698, 0.6704566233203503, 0.6722798995076359, 0.9939941350683594, 0.9679344064619085, 0.5720923780407858, 0.47937831082658844, 0.567700112669604, 0.12234449713473242, 0.015685463412389872, 0.40423600542104837, 0.27269488072813736, 0.3823625567194393, 0.32256670279212446, 0.4200868940113775, 0.35767437058385176, 0.24924688411542353]\n",
            "[0.7030835410050382, 0.6734582119423186, 0.6821156558367119, 0.9618955396414088, 0.9679344064619085, 0.5631552795349817, 0.4605683549411026, 0.5678746499327133, 0.11732253505588489, 0.018546293523528313, 0.42374208804827185, 0.2972458537127213, 0.4149620582027394, 0.35093038054779213, 0.44085919789991956, 0.3748521278843218, 0.2427669277249782]\n",
            "[0.8410401295195357, 0.7986365971843635, 0.8022338627218534, 0.6035602236966966, 0.5720923780407858, 0.5631552795349817, 0.6721486971436302, 0.7679288479423111, 0.147035147167703, 0.02856080648274264, 0.5224505954850469, 0.28598483106508726, 0.4069034148899058, 0.3450622542196257, 0.5443587853537228, 0.4936793319894297, 0.2703843372754415]\n",
            "[0.6731338062873107, 0.7023352006830498, 0.6694582338358985, 0.4998011468511354, 0.47937831082658844, 0.4605683549411026, 0.6721486971436302, 0.6853907893926222, 0.11239331571367385, 0.024512304278753623, 0.4295743933735341, 0.25029130339434186, 0.34492310440673435, 0.29451321192232705, 0.4465840329092465, 0.40542889130635923, 0.23200703950807844]\n",
            "[0.8122370309192153, 0.8038123821731546, 0.831379706888533, 0.5935572901249871, 0.567700112669604, 0.5678746499327133, 0.7679288479423111, 0.6853907893926222, 0.13593458098321448, 0.03770701540947717, 0.5128776647152186, 0.2954004112175192, 0.4161431739321745, 0.3510288668281722, 0.5325198797906967, 0.4825962763757615, 0.2591023016571135]\n",
            "[0.1545159794969928, 0.14213527867385364, 0.14967487104652202, 0.13197327822064744, 0.12234449713473242, 0.11732253505588489, 0.147035147167703, 0.11239331571367385, 0.13593458098321448, 0.01080999936710587, 0.1076867560857399, 0.0599540617400453, 0.0746200724726473, 0.05897914444129208, 0.11163642547386085, 0.10135632693877397, 0.04416443889960932]\n",
            "[0.041447902380906114, 0.039207762733898144, 0.04088450891644734, 0.019422769445639664, 0.015685463412389872, 0.018546293523528313, 0.02856080648274264, 0.024512304278753623, 0.03770701540947717, 0.01080999936710587, 0.009408275400609279, 0.06680533222156979, 0.06653181935938085, 0.08081309086755864, 0.01573317644502217, 0.011862953683483864, 0.07707048019590787]\n",
            "[0.6311099014117805, 0.6232451337648502, 0.6281657734892854, 0.4224120693563289, 0.40423600542104837, 0.42374208804827185, 0.5224505954850469, 0.4295743933735341, 0.5128776647152186, 0.1076867560857399, 0.009408275400609279, 0.5988353180559405, 0.6870800166525872, 0.6478497540541008, 0.9937633088247765, 0.9856775813519929, 0.6405906580239059]\n",
            "[0.3688113546135114, 0.35899547217519356, 0.36563522876627164, 0.27779168346606625, 0.27269488072813736, 0.2972458537127213, 0.28598483106508726, 0.25029130339434186, 0.2954004112175192, 0.0599540617400453, 0.06680533222156979, 0.5988353180559405, 0.9325844626970944, 0.9378468651085988, 0.5680814090699112, 0.5226845889912008, 0.8215943251700436]\n",
            "[0.5078743784519385, 0.4908468912124751, 0.4989635979541192, 0.39202737581282215, 0.3823625567194393, 0.4149620582027394, 0.4069034148899058, 0.34492310440673435, 0.4161431739321745, 0.0746200724726473, 0.06653181935938085, 0.6870800166525872, 0.9325844626970944, 0.9869431585782875, 0.6594755799243152, 0.6031328223115229, 0.8525990801808159]\n",
            "[0.4309325330867657, 0.4172313931163452, 0.423953449978989, 0.32940535648076114, 0.32256670279212446, 0.35093038054779213, 0.3450622542196257, 0.29451321192232705, 0.3510288668281722, 0.05897914444129208, 0.08081309086755864, 0.6478497540541008, 0.9378468651085988, 0.9869431585782875, 0.6163156439742198, 0.5681934410881461, 0.8697462185366136]\n",
            "[0.6585953463453892, 0.6488235868701706, 0.653923668551288, 0.43980057374684045, 0.4200868940113775, 0.44085919789991956, 0.5443587853537228, 0.4465840329092465, 0.5325198797906967, 0.11163642547386085, 0.01573317644502217, 0.9937633088247765, 0.5680814090699112, 0.6594755799243152, 0.6163156439742198, 0.9842987879976385, 0.6079125821841566]\n",
            "[0.5928797475823842, 0.5891663952522229, 0.5911138593179586, 0.37447740688167575, 0.35767437058385176, 0.3748521278843218, 0.4936793319894297, 0.40542889130635923, 0.4825962763757615, 0.10135632693877397, 0.011862953683483864, 0.9856775813519929, 0.5226845889912008, 0.6031328223115229, 0.5681934410881461, 0.9842987879976385, 0.5866515939691284]\n",
            "[0.31619183414655355, 0.31188438312240335, 0.31781241506277835, 0.25420475464234854, 0.24924688411542353, 0.2427669277249782, 0.2703843372754415, 0.23200703950807844, 0.2591023016571135, 0.04416443889960932, 0.07707048019590787, 0.6405906580239059, 0.8215943251700436, 0.8525990801808159, 0.8697462185366136, 0.6079125821841566, 0.5866515939691284]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJeKUzS0jDhq"
      },
      "source": [
        "# Preparation Training and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvocvIBA292-"
      },
      "source": [
        "Once the dataset is prepared, make batches of data,put them togheter in an array and split them into train and test sets.\n",
        "After looking through the dataset and the features, i decided to takeonly the values with a timestap of a weekday between 4:00 and 19:30. In many of the features in the interval outside those timestamps there i only noise, which can be a sign that the machine is off in that time interval."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloaders(dataset_norm):\n",
        "\n",
        "  # Create a dataset with pairs data / Target (in this case data is one measure (18 features) and target is the next measure (18 features))\n",
        "  # When you plug in one measure, the model should out the next measure\n",
        "\n",
        "  pair_set = []\n",
        "\n",
        "  for i in tqdm(range(len(dataset_norm) -1)):\n",
        "    data = np.array([j for j in dataset_norm.iloc[i, 1:]])\n",
        "    target = np.array([j for j in dataset_norm.iloc[i+1, 1:]])\n",
        "    \n",
        "    pair_set.append((data, target))\n",
        "\n",
        "  dataset_pairs = np.array(pair_set)\n",
        "\n",
        "  training_data_pairs, testing_data_pairs = train_test_split(dataset_pairs, test_size=0.1, random_state=25)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in training_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  training_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  training_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in testing_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  test_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  test_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  print(f'length of training set (whole dataset): {training_data.shape[0]}')\n",
        "  print(f'length of test set (whole dataset): {test_data.shape[0]}')\n",
        "  print('\\n')\n",
        "\n",
        "  # Create data loader to feed the FFN in mini batches\n",
        "\n",
        "  loader_train = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(training_data, training_target),\n",
        "      batch_size=64,\n",
        "      shuffle=True\n",
        "  )\n",
        "\n",
        "  # Create data loader for testing the model\n",
        "  loader_test = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(test_data, test_target),\n",
        "      batch_size=64,\n",
        "      shuffle=True\n",
        "  )\n",
        "\n",
        "  return loader_train, loader_test"
      ],
      "metadata": {
        "id": "eI6P8KvabrMO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_train, loader_test = create_dataloaders(dataset_norm)"
      ],
      "metadata": {
        "id": "kgHc7L9_cfN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a199e100-776e-4513-d4a2-36339144a965"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63359/63359 [00:35<00:00, 1781.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set (whole dataset): 57023\n",
            "length of test set (whole dataset): 6336\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequece_dataloaders(dataset_norm):\n",
        "\n",
        "  # Create a dataset with pairs data / Target (in this case data is one sequence of 30 measures (18 features) and target are the next sequence of 30 \n",
        "  # measures (18 features)). When you plug in one measure, the model should out the next measure\n",
        "\n",
        "  pair_set = []\n",
        "\n",
        "  for i in tqdm(range(len(dataset_norm) - 60)):\n",
        "    data = np.array(dataset_norm.iloc[i:i+30, 1:])\n",
        "    target = np.array(dataset_norm.iloc[i+30:i+60, 1:])\n",
        "    \n",
        "    pair_set.append((data, target))\n",
        "\n",
        "  dataset_pairs = np.array(pair_set)\n",
        "\n",
        "  training_data_pairs, testing_data_pairs = train_test_split(dataset_pairs, test_size=0.1, random_state=25)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in training_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  training_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  training_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in testing_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  test_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  test_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  print(f'length of training set (whole dataset): {training_data.shape[0]}')\n",
        "  print(f'length of test set (whole dataset): {test_data.shape[0]}')\n",
        "  print('\\n')\n",
        "\n",
        "  # Create data loader to feed the FFN in mini batches\n",
        "\n",
        "  loader_train = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(training_data, training_target),\n",
        "      batch_size=30,\n",
        "      shuffle=False\n",
        "  )\n",
        "\n",
        "  # Create data loader for testing the model\n",
        "  loader_test = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(test_data, test_target),\n",
        "      batch_size=30,\n",
        "      shuffle=False\n",
        "  )\n",
        "\n",
        "  return loader_train, loader_test, training_data, training_target"
      ],
      "metadata": {
        "id": "eGr5DfpAQ25U"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_train, loader_test, training_data, training_target = create_sequece_dataloaders(dataset_norm)"
      ],
      "metadata": {
        "id": "sQbJaAtaRBUM",
        "outputId": "fd46301c-f169-4ca3-f77a-da5703eaf2a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63300/63300 [00:34<00:00, 1859.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set (whole dataset): 56970\n",
            "length of test set (whole dataset): 6330\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Baseline Model\n",
        "\n",
        "I am taking the Last step as prediction of all features to create a baselinemodel. I will use this baseline model to compare the results of the actual model with it. Everything that works better than this baseline model could be an improvement."
      ],
      "metadata": {
        "id": "VazanvM-f9cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "\n",
        "losses_train = []\n",
        "\n",
        "for i in loader_train:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_train.append(loss.item())\n",
        "\n",
        "losses_test = []\n",
        "\n",
        "for i in loader_test:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_test.append(loss.item())\n",
        "\n",
        "print(\"Training set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_train))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_train))\n",
        "print('\\n')\n",
        "print(\"Test set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_test))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_test))\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeZYKAbqkvUY",
        "outputId": "08d6b279-e66a-4838-d6cd-44a9f0528530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set\n",
            "Mean Loss of baselinemodel:  0.7443867036312615\n",
            "Standard deviation Loss of baselinemodel:  0.11228539154408188\n",
            "\n",
            "\n",
            "Test set\n",
            "Mean Loss of baselinemodel:  0.750549325445817\n",
            "Standard deviation Loss of baselinemodel:  0.10785673408274579\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "\n",
        "losses_train = []\n",
        "\n",
        "for i in loader_train:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_train.append(loss.item())\n",
        "\n",
        "losses_test = []\n",
        "\n",
        "for i in loader_test:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_test.append(loss.item())\n",
        "\n",
        "print(\"Training set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_train))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_train))\n",
        "print('\\n')\n",
        "print(\"Test set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_test))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_test))\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me_JXHtgZyuE",
        "outputId": "9ee3c059-21a5-40fa-bfa2-2b9f953ce4ef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set\n",
            "Mean Loss of baselinemodel:  0.47378769557082695\n",
            "Standard deviation Loss of baselinemodel:  0.09206421629210913\n",
            "\n",
            "\n",
            "Test set\n",
            "Mean Loss of baselinemodel:  0.4659305714597606\n",
            "Standard deviation Loss of baselinemodel:  0.09029201465539803\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a simple Feed Forward Neural Network as a baseline model\n",
        "\n",
        "I trained a simple FFN Network to have a second baseline model. The final model training should have also a better performance than this FFN."
      ],
      "metadata": {
        "id": "aX-B-7HMqFeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN_relu(nn.Module):\n",
        "\n",
        "    def __init__(self, D_in, D_out):\n",
        "        super(ANN_relu, self).__init__()\n",
        "        self.linear1 = nn.Linear(D_in, 180)\n",
        "        self.linear2 = nn.Linear(180, 360)\n",
        "        self.linear3 = nn.Linear(360, 360)\n",
        "        self.linear4 = nn.Linear(360, 180)\n",
        "        self.linear5 = nn.Linear(180, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.linear1(x))\n",
        "        x = torch.relu(self.linear2(x))\n",
        "        x = torch.relu(self.linear3(x))\n",
        "        x = torch.relu(self.linear4(x))\n",
        "        return self.linear5(x)\n",
        "\n",
        "# This function trains the model for one epoch\n",
        "def train(model, criterion, optimizer, train_loader, test_loader, n_epochs):\n",
        "\n",
        "    epoch_loss_train = []\n",
        "    epoch_loss_test = []\n",
        "\n",
        "    for e in range(1, n_epochs +1):\n",
        "      print(f'\\nEpoch {e}:')\n",
        "\n",
        "      print('Train')\n",
        "      model.train()\n",
        "\n",
        "      for i in tqdm(train_loader):\n",
        "\n",
        "        data, target = i[0], i[1]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward Pass\n",
        "        output = model(data)\n",
        "\n",
        "        #Compute loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        #Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        #Optimization\n",
        "        optimizer.step()\n",
        "\n",
        "      losses = []\n",
        "\n",
        "      print('\\nTest with training set')\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for i in tqdm(train_loader):\n",
        "\n",
        "          data, target = i[0], i[1]\n",
        "\n",
        "          output = model(data)\n",
        "              \n",
        "          losses.append (float(criterion(output, target).item()))\n",
        "\n",
        "      print('\\nCurrent Mean loss Train: ', np.mean(losses))\n",
        "      epoch_loss_train.append(losses)\n",
        "\n",
        "      losses = []\n",
        "\n",
        "      print('\\nTest with test set')\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for i in tqdm(test_loader):\n",
        "\n",
        "          data, target = i[0], i[1]\n",
        "\n",
        "          output = model(data)\n",
        "            \n",
        "          losses.append (float(criterion(output, target).item()))\n",
        "\n",
        "\n",
        "      print('\\nCurrent Mean loss: ', np.mean(losses))\n",
        "      epoch_loss_test.append(losses)\n",
        "\n",
        "    return model, epoch_loss_train, epoch_loss_test"
      ],
      "metadata": {
        "id": "n9961Y_qY190"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 50\n",
        "lr=0.01\n",
        "\n",
        "# Create model FFN instance\n",
        "model_FFN_whole = ANN_relu(18, 18).to(device)\n",
        "print(model_FFN_whole)\n",
        "\n",
        "# Define Loss\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer_whole = torch.optim.SGD(model_FFN_whole.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "train_FFN = True\n",
        "\n",
        "params_not_trained_whole = model_FFN_whole.parameters()\n",
        "\n",
        "if train_FFN is True:\n",
        "  trained_model_FFN_whole , train_losses_whole, test_losses_whole = train(model_FFN_whole, criterion, optimizer_whole, loader_train, loader_test, n_epochs)\n"
      ],
      "metadata": {
        "id": "XXhL658rVs8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e386cb-1d43-4c32-87d3-99b718cf6eb3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN_relu(\n",
            "  (linear1): Linear(in_features=18, out_features=180, bias=True)\n",
            "  (linear2): Linear(in_features=180, out_features=360, bias=True)\n",
            "  (linear3): Linear(in_features=360, out_features=360, bias=True)\n",
            "  (linear4): Linear(in_features=360, out_features=180, bias=True)\n",
            "  (linear5): Linear(in_features=180, out_features=18, bias=True)\n",
            ")\n",
            "\n",
            "Epoch 1:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 476.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1071.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.5097212433547417\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1050.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.5027254865025029\n",
            "\n",
            "Epoch 2:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 470.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1075.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.46381044795885096\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1027.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.4563189067623832\n",
            "\n",
            "Epoch 3:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 474.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1063.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.4002476057620964\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1044.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.3919443024529351\n",
            "\n",
            "Epoch 4:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 481.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1077.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.37340163380141744\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1076.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.36472289580287354\n",
            "\n",
            "Epoch 5:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 472.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1066.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.35329580873953376\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1137.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.3451222816501001\n",
            "\n",
            "Epoch 6:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 479.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1061.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.3360691056508408\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1103.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.3282900451108663\n",
            "\n",
            "Epoch 7:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 476.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1063.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.3280548208657606\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1044.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.3205748551120662\n",
            "\n",
            "Epoch 8:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 477.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1094.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.322844048474908\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1090.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.3147340847386254\n",
            "\n",
            "Epoch 9:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 478.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1051.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.318796088532299\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1043.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.3106810294016443\n",
            "\n",
            "Epoch 10:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 480.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1066.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.3157388216384198\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1064.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.3082388233054768\n",
            "\n",
            "Epoch 11:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 476.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1066.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.3128166458790016\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1057.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.30447752593141614\n",
            "\n",
            "Epoch 12:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 480.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1079.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.30962475625888\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1010.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.30186890878460626\n",
            "\n",
            "Epoch 13:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 478.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1090.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.30707048501831913\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1104.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2992845857986296\n",
            "\n",
            "Epoch 14:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 473.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1070.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.3052975786254061\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1004.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2972883907231418\n",
            "\n",
            "Epoch 15:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 481.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1070.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.3039533212262506\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1056.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2960375321633888\n",
            "\n",
            "Epoch 16:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 480.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1060.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.3031520856885129\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1018.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2953660965266854\n",
            "\n",
            "Epoch 17:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:02<00:00, 382.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1081.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.30239952023650124\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1046.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.29462333986855516\n",
            "\n",
            "Epoch 18:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 481.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1056.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.30225402914514443\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1044.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2949678741320215\n",
            "\n",
            "Epoch 19:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 480.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1063.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.3016637214506515\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1067.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.29426558692045884\n",
            "\n",
            "Epoch 20:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 477.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1069.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.3015522497270244\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1073.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2934877496175092\n",
            "\n",
            "Epoch 21:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 480.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1072.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.3009156596279305\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1037.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2934832234274257\n",
            "\n",
            "Epoch 22:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 482.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1066.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.300779468868049\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1010.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.29296539513149644\n",
            "\n",
            "Epoch 23:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 481.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1080.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.3004381092710527\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1113.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2926924645599693\n",
            "\n",
            "Epoch 24:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 479.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1079.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.29986459209126926\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1047.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.29223661666566675\n",
            "\n",
            "Epoch 25:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 478.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1079.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.300595039169395\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1060.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.29381419116198415\n",
            "\n",
            "Epoch 26:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 480.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1090.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.299306157411951\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1056.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2919168673982524\n",
            "\n",
            "Epoch 27:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 475.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1062.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.2990910644851015\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1059.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.291987426654257\n",
            "\n",
            "Epoch 28:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 479.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1083.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.29883235990666646\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1106.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.29135957044182403\n",
            "\n",
            "Epoch 29:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 482.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1079.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.29869173411969785\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1041.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2910831728667924\n",
            "\n",
            "Epoch 30:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 486.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1089.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.29860981484387994\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1023.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2912283262821159\n",
            "\n",
            "Epoch 31:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 479.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1078.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.2979646367423328\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1052.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.29073459000298474\n",
            "\n",
            "Epoch 32:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 482.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1080.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.2998597105812411\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1044.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2936275094145476\n",
            "\n",
            "Epoch 33:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 477.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 869.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.29798583371938947\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1080.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.29059371141472246\n",
            "\n",
            "Epoch 34:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:02<00:00, 320.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 871.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.29732521752984703\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 848.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2899624469003292\n",
            "\n",
            "Epoch 35:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:02<00:00, 305.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 839.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.2972362733181612\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1044.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2898214646060057\n",
            "\n",
            "Epoch 36:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 482.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1074.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.2968422966506479\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1099.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.28967668371971206\n",
            "\n",
            "Epoch 37:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 478.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1055.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.29657976655446316\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1038.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.28957110793903623\n",
            "\n",
            "Epoch 38:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 478.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1081.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.29699043404440556\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 995.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2905073081604158\n",
            "\n",
            "Epoch 39:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 482.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1067.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.2965417397778176\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1029.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.28980136775609217\n",
            "\n",
            "Epoch 40:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 475.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1078.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.29627179545920035\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1030.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.28902708942239935\n",
            "\n",
            "Epoch 41:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 483.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1071.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.2962206123453198\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1038.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.28961186065818323\n",
            "\n",
            "Epoch 42:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 482.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1066.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.2957473053909445\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1007.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.28898243380315375\n",
            "\n",
            "Epoch 43:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 482.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1071.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.296443072416298\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1043.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2901417739463575\n",
            "\n",
            "Epoch 44:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 483.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1088.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.2958578077028898\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1083.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.28890554561759485\n",
            "\n",
            "Epoch 45:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 469.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1090.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.29551050767687165\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1092.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.28859967399727215\n",
            "\n",
            "Epoch 46:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 482.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1072.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.2952081206036203\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1061.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.288750989569558\n",
            "\n",
            "Epoch 47:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 486.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1084.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.29524155084867404\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1006.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2888100099081945\n",
            "\n",
            "Epoch 48:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 482.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1076.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.29579451924355077\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1005.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2883897065514266\n",
            "\n",
            "Epoch 49:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:01<00:00, 447.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 894.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.2952685659682309\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 965.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.28842079142729443\n",
            "\n",
            "Epoch 50:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:02<00:00, 386.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 891/891 [00:00<00:00, 1063.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train:  0.2946895166780009\n",
            "\n",
            "Test with test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [00:00<00:00, 1058.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss:  0.2880734015594829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_FFN_whole)"
      ],
      "metadata": {
        "id": "JyA95BxnEMnz",
        "outputId": "ebfdb304-7b6c-4fac-afe2-669a06481e47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN_relu(\n",
            "  (linear1): Linear(in_features=18, out_features=180, bias=True)\n",
            "  (linear2): Linear(in_features=180, out_features=360, bias=True)\n",
            "  (linear3): Linear(in_features=360, out_features=360, bias=True)\n",
            "  (linear4): Linear(in_features=360, out_features=180, bias=True)\n",
            "  (linear5): Linear(in_features=180, out_features=18, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if train_FFN is True:\n",
        "\n",
        "  # Show results of the loss function whole\n",
        "\n",
        "  fig = plt.figure(figsize = (10,10))\n",
        "\n",
        "  ax = fig.add_subplot(111)\n",
        "  plt.ion()\n",
        "\n",
        "  fig.show()\n",
        "  fig.canvas.draw()\n",
        "\n",
        "  baseline = [np.mean(losses_train) for i in range(len(train_losses_whole))]\n",
        "\n",
        "  ax.plot(baseline, label='Baseline')\n",
        "  ax.plot([np.mean(i) for i in train_losses_whole], label= 'Train_loss')\n",
        "  ax.plot([np.mean(i) for i in test_losses_whole], label= 'Test_loss')\n",
        "  ax.set_title(\"Full Forward Neural Network (Whole dataset)\")\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.set_ylabel('Mean Squared Error')\n",
        "  ax.legend()\n",
        "  fig.canvas.draw()"
      ],
      "metadata": {
        "id": "7kSeRG2ILQ65",
        "outputId": "c5e89084-6193-4c08-f22d-4cb137bb9b52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = torch.Tensor(1, 30, 18).to(device)\n",
        "with torch.no_grad():\n",
        "  trained_model_FFN_whole.train()\n",
        "  count = 0\n",
        "  for i in tqdm(training_data):\n",
        "    batch_result = torch.Tensor(1, 18).to(device)\n",
        "    new = i[0].unsqueeze(0)\n",
        "\n",
        "    for j in range(30):\n",
        "      output = trained_model_FFN_whole(new)\n",
        "      new = output\n",
        "      if j == 0:\n",
        "        batch_result = output\n",
        "      else:\n",
        "        batch_result = torch.cat((batch_result, output), 0)\n",
        "\n",
        "    if count == 0:\n",
        "      results = batch_result.unsqueeze(0)\n",
        "    else:\n",
        "      results = torch.cat((results, batch_result.unsqueeze(0)), 0)\n",
        "    \n",
        "    count += 1\n"
      ],
      "metadata": {
        "id": "7NOTrAuI0rdu",
        "outputId": "a3615b3c-cdba-4f10-8d0d-35ef96789929",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56970/56970 [10:49<00:00, 87.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results.shape)\n",
        "print(training_target.shape)\n"
      ],
      "metadata": {
        "id": "W4lfV8Z93JZn",
        "outputId": "7d30267b-9084-4251-f65e-cefb2148f8fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([56970, 30, 18])\n",
            "torch.Size([56970, 30, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "\n",
        "losses_train = []\n",
        "\n",
        "for i in range(len(results)):\n",
        "  output = results[i]\n",
        "  target = training_target[i]\n",
        "  loss = criterion(output, target)\n",
        "  losses_train.append(loss.item())\n",
        "\n",
        "print(\"Training set\")\n",
        "print(\"Mean Loss of FFN baselinemodel: \", np.mean(losses_train))\n",
        "print(\"Standard deviation Loss of FFN baselinemodel: \", np.std(losses_train))\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "F5cAjYN7Arhx",
        "outputId": "80884406-ffd2-40af-c6a1-8b245824429b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set\n",
            "Mean Loss of baselinemodel:  0.5558841310121081\n",
            "Standard deviation Loss of baselinemodel:  0.33891258801545227\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions FFN\n",
        "\n",
        "Training this small, easy FFN have an improvement to the base model in the case that we don't take a sequence of samples but we compare each sample individually."
      ],
      "metadata": {
        "id": "nzJPbmTPOleH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Model\n",
        "\n",
        "We train before a standard RNN and see which results we can expected with a small and easy solution.\n",
        "I am using this template (https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb) and make changes using it as a base.\n",
        "\n",
        "1) torch.nn.RNN (https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)\n",
        "\n",
        "Parameters\n",
        "* input_size – The number of expected features in the input x\n",
        "* hidden_size – The number of features in the hidden state h\n",
        "* num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1\n",
        "* nonlinearity – The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'\n",
        "* bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
        "* batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: False\n",
        "* dropout – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
        "* bidirectional – If True, becomes a bidirectional RNN. Default: False\n",
        "\n",
        "2) torch.nn.Linear (https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
        "\n",
        "Parameters\n",
        "* in_features – size of each input sample\n",
        "* out_features – size of each output sample\n",
        "* bias – If set to False, the layer will not learn an additive bias. Default: True\n"
      ],
      "metadata": {
        "id": "wLCXaTbSsHRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers, seq_length, device, batch_first = True, dropout = 0):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.device = device\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_size = hidden_dim, num_layers = n_layers, batch_first = batch_first, nonlinearity='relu', dropout = dropout)   \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim*seq_length, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        h0 = torch.zeros(self.n_layers, x.size(0), self.hidden_dim).to(device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out.reshape(out.shape[0], -1)\n",
        "        out = self.fc(out)\n",
        "      \n",
        "        return out\n"
      ],
      "metadata": {
        "id": "VOL1v_mjsEDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_RNN(model, criterion, optimizer, train_loader, test_loader, n_epochs):\n",
        "\n",
        "  epoch_loss_train = []\n",
        "  epoch_loss_test = []\n",
        "\n",
        "  # Training Run\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "    print('\\nTraining:')\n",
        "    print(f'Epoch {epoch}')\n",
        "\n",
        "    for batch in tqdm(train_loader):\n",
        "\n",
        "      data = batch[0]\n",
        "      targets = batch[1]\n",
        "\n",
        "      print(data.size())\n",
        "\n",
        "      data = data.to(device).squeeze(1)\n",
        "      print(data.size())\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      output = model(data)\n",
        "      loss = criterion (output, targets)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(train_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        output, hidden = model(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_train.append (float(criterion(output, target).item()))\n",
        "\n",
        "    print('\\nTest with test set')\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(test_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        output, hidden = model(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_test.append (float(criterion(output, target).item()))\n",
        "\n",
        "\n",
        "    print('\\nCurrent Mean loss Train Set: ', np.mean(losses_train))\n",
        "    epoch_loss_train.append(np.mean(losses_train))\n",
        "\n",
        "    print('\\nCurrent Mean loss Test Set: ', np.mean(losses_test))\n",
        "    epoch_loss_test.append(np.mean(losses_test))\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "  return epoch_loss_train, epoch_loss_test, model"
      ],
      "metadata": {
        "id": "IzAT4IPPwfZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model with hyperparameters\n",
        "model_rnn = RNN(input_size = 18,\n",
        "                output_size = 18,\n",
        "                seq_length= 30,\n",
        "                hidden_dim = 64,\n",
        "                n_layers = 1,\n",
        "                batch_first = True,\n",
        "                dropout = 0,\n",
        "                device = device)\n",
        "\n",
        "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
        "model_rnn = model_rnn.to(device)\n",
        "\n",
        "# Define hyperparameters\n",
        "n_epochs = 50\n",
        "lr=0.01\n",
        "\n",
        "# Define Loss, Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model_rnn.parameters(), lr=lr)\n",
        "\n",
        "train_RNN = True\n",
        "\n",
        "if train_RNN is True:\n",
        "  train_losses, test_losses, trained_model_RNN = training_RNN(model_rnn, criterion, optimizer, loader_train, loader_test, n_epochs)"
      ],
      "metadata": {
        "id": "kZQzvqz0aU5r",
        "outputId": "91e6b262-fec9-414d-de69-1811bf924821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training:\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1899 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([30, 30, 18])) that is different to the input size (torch.Size([30, 18])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "  2%|▏         | 33/1899 [00:00<00:05, 324.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 66/1899 [00:00<00:05, 326.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 99/1899 [00:00<00:05, 320.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▊         | 166/1899 [00:00<00:05, 318.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 232/1899 [00:00<00:05, 316.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 298/1899 [00:00<00:04, 321.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 364/1899 [00:01<00:04, 318.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 431/1899 [00:01<00:04, 327.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 498/1899 [00:01<00:04, 325.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 564/1899 [00:01<00:04, 322.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 630/1899 [00:01<00:03, 323.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 695/1899 [00:02<00:03, 319.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 760/1899 [00:02<00:03, 319.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▎     | 828/1899 [00:02<00:03, 326.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 894/1899 [00:02<00:03, 320.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 961/1899 [00:02<00:02, 323.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 970/1899 [00:03<00:02, 320.17it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-f178a6bdfa75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain_RNN\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_model_RNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_RNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-3eb0a780d534>\u001b[0m in \u001b[0;36mtraining_RNN\u001b[0;34m(model, criterion, optimizer, train_loader, test_loader, n_epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if train_RNN is True:\n",
        "\n",
        "  # Show results of the loss function\n",
        "\n",
        "  fig = plt.figure()\n",
        "\n",
        "  ax = fig.add_subplot(111)\n",
        "  plt.ion()\n",
        "\n",
        "  fig.show()\n",
        "  fig.canvas.draw()\n",
        "\n",
        "  baseline = [np.mean(losses_train) for i in range(len(train_losses))]\n",
        "\n",
        "  ax.plot(baseline)\n",
        "  ax.plot([np.mean(i) for i in train_losses])\n",
        "  ax.plot([np.mean(i) for i in test_losses])\n",
        "  ax.set_title(\"Mean Squared Error RNN\")\n",
        "  fig.canvas.draw()"
      ],
      "metadata": {
        "id": "989Pq-hNLX7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last basemodel i am going to use is a simple RNN. The final model should also have a better performance than this RNN."
      ],
      "metadata": {
        "id": "Y93gczvmqiT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequece_dataloaders(dataset_norm):\n",
        "\n",
        "  # Create a dataset with pairs data / Target (in this case data is one sequence of 30 measures (18 features) and target are the next sequence of 30 \n",
        "  # measures (18 features)). When you plug in one measure, the model should out the next measure\n",
        "\n",
        "  pair_set = []\n",
        "\n",
        "  for i in tqdm(range(len(dataset_norm) - 60)):\n",
        "    data = np.array(dataset_norm.iloc[i:i+30, 1:])\n",
        "    target = np.array(dataset_norm.iloc[i+30:i+60, 1:])\n",
        "    \n",
        "    pair_set.append((data, target))\n",
        "\n",
        "  dataset_pairs = np.array(pair_set)\n",
        "\n",
        "  training_data_pairs, testing_data_pairs = train_test_split(dataset_pairs, test_size=0.1, random_state=25)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in training_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  training_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  training_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in testing_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  test_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  test_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  print(f'length of training set (whole dataset): {training_data.shape[0]}')\n",
        "  print(f'length of test set (whole dataset): {test_data.shape[0]}')\n",
        "  print('\\n')\n",
        "\n",
        "  # Create data loader to feed the FFN in mini batches\n",
        "\n",
        "  loader_train = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(training_data, training_target),\n",
        "      batch_size=15,\n",
        "      shuffle=False\n",
        "  )\n",
        "\n",
        "  # Create data loader for testing the model\n",
        "  loader_test = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(test_data, test_target),\n",
        "      batch_size=15,\n",
        "      shuffle=False\n",
        "  )\n",
        "\n",
        "  return loader_train, loader_test"
      ],
      "metadata": {
        "id": "6E3nOOEDkOCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_train, loader_test = create_sequece_dataloaders(dataset_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loolRFt_jhgV",
        "outputId": "2c69208b-ce75-4371-998c-0925a7d2e5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63300/63300 [00:19<00:00, 3205.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set (whole dataset): 56970\n",
            "length of test set (whole dataset): 6330\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXX8lu3jjDhr"
      },
      "source": [
        "# Transformer Model settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dUCsWWo292_"
      },
      "source": [
        "Now, we define a class with the transformer model that we are going to use:\n",
        "\n",
        "Using the already written pytorch library for Transformers:\n",
        "\n",
        "1) torch.nn.TransformerEncoderLayer (https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html)\n",
        "\n",
        "*   d_model –> the number of expected features in the input (required).\n",
        "*   nhead –> the number of heads in the multiheadattention models (required).\n",
        "*   dropout –> the dropout value (default=0.1).\n",
        "*   activation –> the activation function of the intermediate layer, can be a string (“relu” or “gelu”) or a unary callable. (default: relu)\n",
        "*   layer_norm_eps –> the eps value in layer normalization components (default=1e-5).\n",
        "*   batch_first –> If True, then the input and output tensors are provided as (batch, seq, feature). (default: False)\n",
        "*   norm_first –> if True, layer norm is done prior to attention and feedforward operations, respectivaly. Otherwise it’s done after. (default: False (after))\n",
        "\n",
        "2) torch.nn.TransformerDecoderLayer\n",
        "\n",
        "* d_model –> the number of expected features in the input (required).\n",
        "* nhead –> the number of heads in the multiheadattention models (required).\n",
        "* dim_feedforward –> the dimension of the feedforward network model (default=2048).\n",
        "* dropout –> the dropout value (default=0.1).\n",
        "* activation –> the activation function of the intermediate layer, can be a string (“relu” or “gelu”) or a unary callable. Default: relu\n",
        "* layer_norm_eps –> the eps value in layer normalization components (default=1e-5).\n",
        "* batch_first –> If True, then the input and output tensors are provided as (batch, seq, feature). Default: False.\n",
        "* norm_first –> if True, layer norm is done prior to self attention, multihead attention and feedforward operations, respectivaly. Otherwise it’s done after. Default: False (after).\n",
        "\n",
        "3) torch.nn.TransformerEncoder\n",
        "\n",
        "* encoder_layer –> an instance of the TransformerEncoderLayer() class (required).\n",
        "* num_layers –> the number of sub-encoder-layers in the encoder (required).\n",
        "* norm –> the layer normalization component (optional).\n",
        "\n",
        "\n",
        "4) torch.nn.TransformerDecoder\n",
        "\n",
        "* decoder_layer – an instance of the TransformerDecoderLayer() class (required).\n",
        "* num_layers – the number of sub-decoder-layers in the decoder (required).\n",
        "* norm – the layer normalization component (optional).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCC_Bava293A",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def positional_encoding(seq_len: int, dim_model: int, device):\n",
        "    \n",
        "    # Tensor with the positions of every sequence element (0 to seq_len)\n",
        "    pos = torch.arange(seq_len, dtype=float32, device=device).reshape(1, -1, 1)\n",
        "    \n",
        "    # Tensor with the positions of every feature in the sequence (0 to dim_model)\n",
        "    dim = torch.arange(dim_model, dtype=float32, device=device).reshape(1, 1, -1)\n",
        "\n",
        "    phase = pos / (1e4 ** (torch.div(dim, dim_model, rounding_mode='floor')))\n",
        "\n",
        "    position_encoding = torch.where(dim.long() % 2 == 0, sin(phase), cos(phase))\n",
        "\n",
        "    return position_encoding.to(device)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, feature_size, output_size, num_encoder_layers, num_heads, num_decoder_layers, device, dropout: float =0.1, batch_first: bool = False):\n",
        "        super(Transformer, self).__init__()\n",
        "        \n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model= feature_size, nhead= num_heads, dropout=dropout, device=device, batch_first=batch_first)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model= feature_size, nhead= num_heads, dropout=dropout, device=device, batch_first=batch_first)\n",
        "        \n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers= num_encoder_layers)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers= num_decoder_layers)\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.device = device\n",
        "\n",
        "    def generate_square_mask(self, dim):\n",
        "        return torch.triu(torch.ones(dim, dim) * float('-inf'), diagonal=1).to(self.device)\n",
        "        \n",
        "    def forward (self, src):\n",
        "        \n",
        "        mask = self.generate_square_mask(len(src))\n",
        "\n",
        "        #src_pos = src + positional_encoding(src.shape[1], src.shape[2], self.device)\n",
        "\n",
        "        output = self.encoder (src, mask)\n",
        "        \n",
        "        output = self.decoder (src, output, mask)\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should define an optimizer too.\n",
        "For this, we use the pytorch library:\n",
        "\n",
        "* SGD –> Stochastic gradient descent.\n",
        "\n",
        "1) torch.optim.SDG (https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)\n",
        "\n",
        "* params (iterable) – iterable of parameters to optimize or dicts defining parameter groups\n",
        "* lr (float) – learning rate\n",
        "* momentum (float, optional) – momentum factor (default: 0)\n",
        "* weight_decay (float, optional) – weight decay (L2 penalty) (default: 0)\n",
        "* dampening (float, optional) – dampening for momentum (default: 0)\n",
        "* nesterov (bool, optional) – enables Nesterov momentum (default: False)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8EANo5UFE15A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_transformer(model, optimizer, criterion, train_loader, test_loader, n_epochs):\n",
        "  epoch_loss_train = []\n",
        "  epoch_loss_test = []\n",
        "\n",
        "  for e in range(1, n_epochs + 1):\n",
        "\n",
        "    print(f'Epoch: {e} of {n_epochs}')\n",
        "\n",
        "    print('Training:')\n",
        "    model.train()\n",
        "\n",
        "    for i in tqdm(train_loader):\n",
        "\n",
        "      # Initialize optimizer gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      input = i[0]\n",
        "\n",
        "      target = i[1]\n",
        "\n",
        "      net_out = model.forward(input)\n",
        "\n",
        "      #Compute loss\n",
        "      loss = criterion(net_out, target)\n",
        "\n",
        "      #Backpropagation\n",
        "      loss.backward()\n",
        "\n",
        "      #Optimization\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    losses_train = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(train_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        net_out = model.forward(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_train.append (float(criterion(net_out, target).item()))\n",
        "\n",
        "    \n",
        "    print('\\nCurrent Mean loss Train Set: ', np.mean(losses_train))\n",
        "    epoch_loss_train.append(losses_train)\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    losses_test = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(test_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        net_out = model.forward(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_test.append (float(criterion(net_out, target).item()))\n",
        "\n",
        "    print('\\nCurrent Mean loss Test Set: ', np.mean(losses_test))\n",
        "    epoch_loss_test.append(losses_test)\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "  return model, epoch_loss_train, epoch_loss_test"
      ],
      "metadata": {
        "id": "SZ8UZSHPQLT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup model Ok\n",
            "Setup optimizer Ok\n",
            "Epoch: 1 of 50\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 1408/3798 [00:24<00:42, 56.59it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-26ed60183b8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain_transformer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mtrained_model_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-efe2077d6e12>\u001b[0m in \u001b[0;36mtraining_transformer\u001b[0;34m(model, optimizer, criterion, train_loader, test_loader, n_epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mnet_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;31m#Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-041dc401cab4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#src_pos = src + positional_encoding(src.shape[1], src.shape[2], self.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Initialize Transformer Model and Optimizer\n",
        "\n",
        "model_transformer = Transformer (num_encoder_layers=3,\n",
        "                     num_decoder_layers=3,\n",
        "                     feature_size=18,\n",
        "                     output_size=18,\n",
        "                     num_heads=3,\n",
        "                     device = device,\n",
        "                     batch_first=False)\n",
        "\n",
        "n_epochs = 50\n",
        "\n",
        "print('Setup model Ok')\n",
        "\n",
        "optimizer = torch.optim.Adam(model_transformer.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print('Setup optimizer Ok')\n",
        "\n",
        "\n",
        "train_transformer = True\n",
        "\n",
        "if train_transformer is True:\n",
        "  trained_model_transformer, train_losses, test_losses = training_transformer(model_transformer, optimizer, criterion, loader_train, loader_test, n_epochs)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Muhz9Q2qjDhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "9d058b42-71ef-4bd1-9923-57a4b1776042"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgrbFBLS293A",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if train_transformer is True:\n",
        "\n",
        "  # Show results of the loss function\n",
        "\n",
        "  fig = plt.figure()\n",
        "\n",
        "  ax = fig.add_subplot(111)\n",
        "  plt.ion()\n",
        "\n",
        "  fig.show()\n",
        "  fig.canvas.draw()\n",
        "\n",
        "  baseline = [np.mean(losses_train) for i in range(len(train_losses))]\n",
        "\n",
        "  ax.plot(baseline)\n",
        "  ax.plot([np.mean(i) for i in train_losses])\n",
        "  ax.plot([np.mean(i) for i in test_losses])\n",
        "  ax.set_title(\"Mean Squared Error RNN\")\n",
        "  fig.canvas.draw()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequece_pairs(dataset_norm):\n",
        "\n",
        "  # Create a dataset with pairs data / Target (in this case data is one sequence of 30 measures (18 features) and target are the next sequence of 30 \n",
        "  # measures (18 features)). When you plug in one measure, the model should out the next measure\n",
        "\n",
        "  pair_set = []\n",
        "\n",
        "  for i in tqdm(range(len(dataset_norm) - 60)):\n",
        "    data = np.array(dataset_norm.iloc[i:i+30, 1:])\n",
        "    target = np.array(dataset_norm.iloc[i+30:i+60, 1:])\n",
        "    \n",
        "    pair_set.append((data, target))\n",
        "\n",
        "  dataset_pairs = np.array(pair_set)\n",
        "\n",
        "  training_data_pairs, testing_data_pairs = train_test_split(dataset_pairs, test_size=0.1, random_state=25)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in training_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  training_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  training_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in testing_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  test_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  test_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  return (training_data, training_target), (test_data, test_target)"
      ],
      "metadata": {
        "id": "cEOlIPX4EcA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pairs, test_pairs = create_sequece_pairs(dataset_norm)"
      ],
      "metadata": {
        "id": "0NyICzR4EpUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_pairs))\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "losses_train = []\n",
        "\n",
        "for i in train_pairs:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_train.append(loss.item())\n",
        "\n",
        "losses_test = []\n",
        "\n",
        "for i in test_pairs:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_test.append(loss.item())\n",
        "\n",
        "print(\"Training set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_train))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_train))\n",
        "print('\\n')\n",
        "print(\"Test set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_test))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_test))\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "a5-laMb6Dngn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_transformer(model, optimizer, criterion, train_loader, test_loader, n_epochs):\n",
        "  epoch_loss_train = []\n",
        "  epoch_loss_test = []\n",
        "\n",
        "  for e in range(1, n_epochs + 1):\n",
        "\n",
        "    print(f'Epoch: {e} of {n_epochs}')\n",
        "\n",
        "    print('Training:')\n",
        "    model.train()\n",
        "\n",
        "    for i in tqdm(train_loader):\n",
        "\n",
        "      # Initialize optimizer gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      input = i[0]\n",
        "\n",
        "      target = i[1]\n",
        "\n",
        "      net_out = model.forward(input)\n",
        "\n",
        "      #Compute loss\n",
        "      loss = criterion(net_out, target)\n",
        "\n",
        "      #Backpropagation\n",
        "      loss.backward()\n",
        "\n",
        "      #Optimization\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    losses_train = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(train_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        net_out = model.forward(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_train.append (float(criterion(net_out, target).item()))\n",
        "\n",
        "    \n",
        "    print('\\nCurrent Mean loss Train Set: ', np.mean(losses_train))\n",
        "    epoch_loss_train.append(losses_train)\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    losses_test = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(test_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        net_out = model.forward(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_test.append (float(criterion(net_out, target).item()))\n",
        "\n",
        "    print('\\nCurrent Mean loss Test Set: ', np.mean(losses_test))\n",
        "    epoch_loss_test.append(losses_test)\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "  return model, epoch_loss_train, epoch_loss_test"
      ],
      "metadata": {
        "id": "ZrzzO5EECjJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Transformer Model and Optimizer\n",
        "\n",
        "model_transformer = Transformer (num_encoder_layers=3,\n",
        "                     num_decoder_layers=3,\n",
        "                     feature_size=18,\n",
        "                     output_size=18,\n",
        "                     num_heads=3,\n",
        "                     device = device,\n",
        "                     batch_first=False)\n",
        "\n",
        "\n",
        "print('Setup model Ok')\n",
        "\n",
        "n_epochs = 50\n",
        "optimizer = torch.optim.Adam(model_transformer.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print('Setup optimizer Ok')\n",
        "\n",
        "print(train_pairs[0].shape)\n",
        "\n",
        "train_transformer = True\n",
        "\n",
        "if train_transformer is True:\n",
        "  trained_model_transformer, train_losses, test_losses = training_transformer(model_transformer, optimizer, criterion, train_pairs, test_pairs, n_epochs)"
      ],
      "metadata": {
        "id": "m2Vy5m7GCqvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS8DcLC-293B"
      },
      "source": [
        "Ideas, things to remember, to search, etc...\n",
        "\n",
        "reconstruction, vergelich mit base line model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "bsc_arbeit.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python392jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}