{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0esqvQHT2922"
      },
      "source": [
        "# First: load imports needed for the project and preparation of the project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is necessary to use this notebook in google colab\n",
        "# If you are running this notebook in colab, please change colab to True\n",
        "\n",
        "import os\n",
        "\n",
        "colab = True\n",
        "cwd = os.getcwd()\n",
        "\n",
        "if colab is True and cwd != \"/content/Bsc_Thesis\":\n",
        "  ! git clone https://github.com/SergioTallo/Bsc_Thesis.git\n",
        "  % cd Bsc_Thesis\n",
        "\n",
        "print(cwd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adt0VN_ojbV1",
        "outputId": "4ce0739c-efe7-4a52-ee40-d637c8ef34a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Bsc_Thesis'...\n",
            "remote: Enumerating objects: 167, done.\u001b[K\n",
            "remote: Counting objects: 100% (167/167), done.\u001b[K\n",
            "remote: Compressing objects: 100% (155/155), done.\u001b[K\n",
            "remote: Total 167 (delta 103), reused 26 (delta 12), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (167/167), 3.69 MiB | 5.87 MiB/s, done.\n",
            "Resolving deltas: 100% (103/103), done.\n",
            "/content/Bsc_Thesis\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VCwEuYFk2923",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2cc50ff-3c1f-46f3-caec-4ed642cfc755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: GPU = Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "from torch import Tensor, float32, sin, cos\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import utils_bsc\n",
        "import datetime\n",
        "import statistics\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "  print('Device: GPU =', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print('Device: CPU')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQPvc4I-4LY5",
        "outputId": "c5a4387a-4cbd-465f-d59a-22ec59422a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "versions of packages:\n",
            "Python: 3.7.13\n",
            "Pandas: 1.3.5\n",
            "Numpy: 1.21.5\n",
            "PyTorch: 1.10.0+cu111\n",
            "Sklearn: 1.0.2\n",
            "seaborn: 0.11.2\n"
          ]
        }
      ],
      "source": [
        "utils_bsc.print_versions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICcfWNfajDhn"
      },
      "source": [
        "# Data loading and preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "bjUFrMX32925"
      },
      "source": [
        "Now, we should create a dataset with all the data stored in the .csv file\n",
        "\n",
        "Description of the data:\n",
        "\n",
        "*   time: Timestamp (YYYY-MM-DD HH:MM:SS)\n",
        "*   PLN1: Power in the phase 1 (W)\n",
        "*   PLN2: Power in the phase 2 (W)\n",
        "*   PLN3: Power in the phase 3 (W)\n",
        "*   ULL1: Current Voltage between 2 phases (V)\n",
        "*   ULL2: Current Voltage between 2 phases (V)\n",
        "*   ULL3: Current Voltage between 2 phases (V)\n",
        "*   COS_PHI1: Phase shift (Cos)\n",
        "*   COS_PHI2: Phase shift (Cos)\n",
        "*   COS_PHI3: Phase shift (Cos)\n",
        "*   FREQ: Electricity Frequency (Hz)\n",
        "*   RC_DC: Fault currents\n",
        "*   RC_AC: Fault currents\n",
        "*   RC_50Hz: Fault currents\n",
        "*   RC_150Hz: Fault currents\n",
        "*   RC_<100Hz: Fault currents\n",
        "*   RC_100Hz-1kHz: Fault currents\n",
        "*   RC_>10kHz: Fault currents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "qIhc9bwK2926",
        "outputId": "64517b44-e2d3-4393-c9f5-a2c71844db05",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  time       PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "0  2020-06-01 00:00:00  1141.0819  519.5034  482.9381  398.8613  400.1982   \n",
              "1  2020-06-01 00:01:00  1145.1162  519.1807  491.4436  398.6934  400.1579   \n",
              "2  2020-06-01 00:02:00  1140.9558  743.3837  484.9942  398.4367  400.1205   \n",
              "3  2020-06-01 00:03:00  1151.9409  741.4836  487.4224  398.9800  400.4375   \n",
              "4  2020-06-01 00:04:00  1142.1594  741.9858  486.7629  398.7133  400.3145   \n",
              "\n",
              "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3     FREQ  RC_DC  RC_AC  RC_50Hz  \\\n",
              "0  395.6010    0.8091    0.6864    0.4875  49.9927    4.0   91.0     10.0   \n",
              "1  395.5431    0.8080    0.6903    0.4904  49.9779    5.0   64.0      7.0   \n",
              "2  395.5259    0.8113    0.9274    0.4806  49.9782    4.0   64.0      7.0   \n",
              "3  395.8621    0.8249    0.9123    0.4778  49.9850    5.0   66.0      8.0   \n",
              "4  395.6446    0.8081    0.9291    0.4552  49.9856    4.0   85.0     11.0   \n",
              "\n",
              "   RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "0      39.0       36.0           86.0      82.0        7.0  \n",
              "1      27.0       25.0           60.0      55.0        2.0  \n",
              "2      27.0       25.0           60.0      55.0        2.0  \n",
              "3      28.0       25.0           61.0      57.0        2.0  \n",
              "4      45.0       41.0           75.0      68.0        6.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32792e82-a2af-466a-b50b-d60c7f06c07f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-01 00:00:00</td>\n",
              "      <td>1141.0819</td>\n",
              "      <td>519.5034</td>\n",
              "      <td>482.9381</td>\n",
              "      <td>398.8613</td>\n",
              "      <td>400.1982</td>\n",
              "      <td>395.6010</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.6864</td>\n",
              "      <td>0.4875</td>\n",
              "      <td>49.9927</td>\n",
              "      <td>4.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-01 00:01:00</td>\n",
              "      <td>1145.1162</td>\n",
              "      <td>519.1807</td>\n",
              "      <td>491.4436</td>\n",
              "      <td>398.6934</td>\n",
              "      <td>400.1579</td>\n",
              "      <td>395.5431</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6903</td>\n",
              "      <td>0.4904</td>\n",
              "      <td>49.9779</td>\n",
              "      <td>5.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-01 00:02:00</td>\n",
              "      <td>1140.9558</td>\n",
              "      <td>743.3837</td>\n",
              "      <td>484.9942</td>\n",
              "      <td>398.4367</td>\n",
              "      <td>400.1205</td>\n",
              "      <td>395.5259</td>\n",
              "      <td>0.8113</td>\n",
              "      <td>0.9274</td>\n",
              "      <td>0.4806</td>\n",
              "      <td>49.9782</td>\n",
              "      <td>4.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-01 00:03:00</td>\n",
              "      <td>1151.9409</td>\n",
              "      <td>741.4836</td>\n",
              "      <td>487.4224</td>\n",
              "      <td>398.9800</td>\n",
              "      <td>400.4375</td>\n",
              "      <td>395.8621</td>\n",
              "      <td>0.8249</td>\n",
              "      <td>0.9123</td>\n",
              "      <td>0.4778</td>\n",
              "      <td>49.9850</td>\n",
              "      <td>5.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-01 00:04:00</td>\n",
              "      <td>1142.1594</td>\n",
              "      <td>741.9858</td>\n",
              "      <td>486.7629</td>\n",
              "      <td>398.7133</td>\n",
              "      <td>400.3145</td>\n",
              "      <td>395.6446</td>\n",
              "      <td>0.8081</td>\n",
              "      <td>0.9291</td>\n",
              "      <td>0.4552</td>\n",
              "      <td>49.9856</td>\n",
              "      <td>4.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32792e82-a2af-466a-b50b-d60c7f06c07f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32792e82-a2af-466a-b50b-d60c7f06c07f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32792e82-a2af-466a-b50b-d60c7f06c07f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset = pd.read_csv('data_factory.csv')\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZAyQ-cA2926"
      },
      "source": [
        "Once we have the dataset, we should prepare it. Finding the missing or the NaN values and replace them with suitable values (in this case we use the previous value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNTHq6mO2927",
        "outputId": "bc04a3f4-6c82-4629-ccee-db00ea85ba21",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with NaN values before cleaning: 2546\n",
            "Number of rows with NaN values after cleaning: 0\n",
            "Total number of samples: 63360\n",
            "Number of features: 19\n"
          ]
        }
      ],
      "source": [
        "# Replace all mising values with NaN\n",
        "dataset = dataset.replace(' ', np.nan)\n",
        "# Search for all the rows with NaN values\n",
        "nan_values = dataset[dataset.isna().any(axis=1)]\n",
        "# Print the shape to know how many are there\n",
        "print(f'Number of rows with NaN values before cleaning: {nan_values.shape[0]}') \n",
        "\n",
        "# Fill all NaN values with the previous row value\n",
        "dataset_clean = dataset.fillna(method='ffill')\n",
        "\n",
        "# Check that there isn't any NaN values\n",
        "nan_values = dataset_clean[dataset_clean.isna().any(axis=1)]\n",
        "# Print the shape to know how many are there\n",
        "print(f'Number of rows with NaN values after cleaning: {nan_values.shape[0]}') \n",
        "\n",
        "#Total number of samples\n",
        "print(f'Total number of samples: {dataset_clean.shape[0]}')\n",
        "print(f'Number of features: {dataset_clean.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d44xLGPbjDhp"
      },
      "source": [
        "# Distribution of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6R7YF-T2928"
      },
      "source": [
        "Now we look at the distribution of the different features of the data over different time intervals.\n",
        "First we take a look of the min and max values, mean and median value and the standard deviation of every feature."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_data = False\n",
        "\n",
        "if print_data is True:\n",
        "  for column in dataset_clean.columns:\n",
        "    if column == 'time':\n",
        "      print(column)\n",
        "      print('Min value: ', dataset_clean[column].min())\n",
        "      print('Max value: ', dataset_clean[column].max())\n",
        "      print('')\n",
        "    else:\n",
        "      print(column)\n",
        "      print('Min value: ', dataset_clean[column].min())\n",
        "      print('Max value: ', dataset_clean[column].max())\n",
        "      print('Mean value: ', dataset_clean[column].mean())\n",
        "      print('Median value: ', dataset_clean[column].median())\n",
        "      print('Standard deviation: ', dataset_clean[column].std())\n",
        "      print('')"
      ],
      "metadata": {
        "id": "pseEB_3qChk4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tQ0vhNNv2928",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Set to True to print the graphs\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "\n",
        "  for i, column in enumerate(dataset_clean.columns):\n",
        "    if i > 0:\n",
        "      # Feature in a weekly interval\n",
        "      utils_bsc.week_plot(dataset_clean, i, column)\n",
        "      # Feature in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
        "      utils_bsc.daily_plot(dataset_clean, i, column)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We print some graphs showing the density distribution of every feature\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_clean.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_clean, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "sJIFPsqkiezx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After looking to the different data graphs i notice there two very different \"time slots\" when the data differs. One is Weekdays between 4:00 and 19:30. The other is Weekdays bewteen 19:30 and 4:00 and Weekends."
      ],
      "metadata": {
        "id": "cWFCmrIH5oA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create two extra data sets, one with the weekdays between 4:00 and 18:30 and one with the rest.\n",
        "dataset_clean_time = pd.to_datetime(dataset_clean['time'])\n",
        "\n",
        "day_mask = dataset_clean_time.dt.day_name()\n",
        "\n",
        "time_mask = (dataset_clean_time.dt.hour >= 4) & ((dataset_clean_time.dt.hour < 19) | ((dataset_clean_time.dt.hour == 19) & (dataset_clean_time.dt.minute <= 30))) & ((day_mask == ('Monday')) | (day_mask == ('Tuesday')) | (day_mask == ('Wednesday')) | (day_mask == ('Thursday')) | (day_mask == ('Friday')))\n",
        "\n",
        "dataset_weekdays = dataset_clean[time_mask]\n",
        "\n",
        "for i in range(len(time_mask)):\n",
        "  if time_mask[i] == False:\n",
        "    time_mask[i] = True\n",
        "  elif time_mask[i] == True:\n",
        "    time_mask[i] = False\n",
        "\n",
        "dataset_weekend = dataset_clean[time_mask]\n",
        "\n",
        "print(f'Weekdays dataset size: {len(dataset_weekdays)}')\n",
        "print(f'Weekend dataset size: {len(dataset_weekend)}')"
      ],
      "metadata": {
        "id": "hVOHl2YDmFV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53379c8-eebf-4a25-9905-592abb0f1e93"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weekdays dataset size: 29792\n",
            "Weekend dataset size: 33568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekdays.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekdays, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "jYbGTF6mSz5v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekend.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekend, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "hqupNsJw6bzH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this time we have three different datasets:\n",
        "\n",
        "* dataset_clean (Whole dataset)\n",
        "* dataset_weekdays (Entries from weekdays from 4:00 to 19:30)\n",
        "* dataset_weekend (Entries from Weekends and from weekdays from 19:30 to 4:00)\n",
        "\n"
      ],
      "metadata": {
        "id": "mgEydMmqTHtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset normalisation\n",
        "\n",
        "The scale of the data of the different features is very dofferent. Its better to have all of the features in the same scale. Therefore we perform a data normalisation. We choose to do a mean/stddev normalisation. We substract from every value the mean value of the feature and divide the result value by the std dev of this specific feature to have feature values with mean 0 and stddev of 1."
      ],
      "metadata": {
        "id": "B6iRPxmuJzVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the mean / stddev scaling in Pandas using the .mean() and .std() methods\n",
        "def normalize_mean_std_dataset(df):\n",
        "    # copy the dataframe\n",
        "    df_scaled = df.copy()\n",
        "    df_norm = df.copy()\n",
        "    # apply mean / stddev scaling\n",
        "    for column in tqdm(df_scaled.columns):\n",
        "      if column != 'time':\n",
        "        df_norm[column] = (df_norm[column] - df_norm[column].mean()) / df_norm[column].std()\n",
        "    return df_norm"
      ],
      "metadata": {
        "id": "HBGfdNkAxxbN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the data normalisation in the whole dataset. We can print the distribution of the data if we want.\n",
        "dataset_norm = normalize_mean_std_dataset(dataset_clean)\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_norm.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_norm, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "1VhzsSn37b_0",
        "outputId": "9e47cbe4-2f8c-46d7-90cb-51d5e02fd41a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 819.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the data normalisation in the weekdays dataset. We can print the distribution of the data if we want.\n",
        "dataset_weekdays_norm = normalize_mean_std_dataset(dataset_weekdays)\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekdays_norm.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekdays_norm, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "SuS8dhouVCec",
        "outputId": "2438c61a-c16e-4fb4-e20c-780bf3440906",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 1189.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the data normalisation in the weekdays dataset. We can print the distribution of the data if we want.\n",
        "dataset_weekend_norm = normalize_mean_std_dataset(dataset_weekend)\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekend_norm.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekend_norm, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "MH07VtqpVdez",
        "outputId": "7c4d3293-81f7-493c-8b3b-a9d34088902d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 1071.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_norm.head()"
      ],
      "metadata": {
        "id": "FDUnKkascXyI",
        "outputId": "688ad763-42a7-4d8d-8010-23b2a2554f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "0  2020-06-01 00:00:00 -1.075593 -1.045021 -1.051232  0.063478 -0.098312   \n",
              "1  2020-06-01 00:01:00 -1.074875 -1.045103 -1.048747  0.027004 -0.107515   \n",
              "2  2020-06-01 00:02:00 -1.075615 -0.988316 -1.050631 -0.028760 -0.116055   \n",
              "3  2020-06-01 00:03:00 -1.073661 -0.988798 -1.049922  0.089264 -0.043667   \n",
              "4  2020-06-01 00:04:00 -1.075401 -0.988670 -1.050114  0.031327 -0.071754   \n",
              "\n",
              "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
              "0 -0.618908 -1.868350 -1.835847 -1.500292 -0.345935 -0.817380  0.632551   \n",
              "1 -0.632738 -1.884005 -1.803753 -1.486828 -1.139728  0.678985 -0.849829   \n",
              "2 -0.636846 -1.837041  0.147415 -1.532327 -1.123638 -0.817380 -0.849829   \n",
              "3 -0.556540 -1.643493  0.023152 -1.545327 -0.758922  0.678985 -0.740023   \n",
              "4 -0.608493 -1.882582  0.161405 -1.650254 -0.726741 -0.817380  0.303134   \n",
              "\n",
              "    RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "0  1.075812  0.995360   1.143832       0.694697  0.747095   2.141318  \n",
              "1 -0.918340 -0.792166  -0.630653      -0.822036 -0.777047  -1.175568  \n",
              "2 -0.918340 -0.792166  -0.630653      -0.822036 -0.777047  -1.175568  \n",
              "3 -0.253623 -0.643206  -0.630653      -0.763700 -0.664147  -1.175568  \n",
              "4  1.740530  1.889123   1.950416       0.053002 -0.043201   1.477941  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55316161-2c8c-47a8-87e9-b546c2952796\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-01 00:00:00</td>\n",
              "      <td>-1.075593</td>\n",
              "      <td>-1.045021</td>\n",
              "      <td>-1.051232</td>\n",
              "      <td>0.063478</td>\n",
              "      <td>-0.098312</td>\n",
              "      <td>-0.618908</td>\n",
              "      <td>-1.868350</td>\n",
              "      <td>-1.835847</td>\n",
              "      <td>-1.500292</td>\n",
              "      <td>-0.345935</td>\n",
              "      <td>-0.817380</td>\n",
              "      <td>0.632551</td>\n",
              "      <td>1.075812</td>\n",
              "      <td>0.995360</td>\n",
              "      <td>1.143832</td>\n",
              "      <td>0.694697</td>\n",
              "      <td>0.747095</td>\n",
              "      <td>2.141318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-01 00:01:00</td>\n",
              "      <td>-1.074875</td>\n",
              "      <td>-1.045103</td>\n",
              "      <td>-1.048747</td>\n",
              "      <td>0.027004</td>\n",
              "      <td>-0.107515</td>\n",
              "      <td>-0.632738</td>\n",
              "      <td>-1.884005</td>\n",
              "      <td>-1.803753</td>\n",
              "      <td>-1.486828</td>\n",
              "      <td>-1.139728</td>\n",
              "      <td>0.678985</td>\n",
              "      <td>-0.849829</td>\n",
              "      <td>-0.918340</td>\n",
              "      <td>-0.792166</td>\n",
              "      <td>-0.630653</td>\n",
              "      <td>-0.822036</td>\n",
              "      <td>-0.777047</td>\n",
              "      <td>-1.175568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-01 00:02:00</td>\n",
              "      <td>-1.075615</td>\n",
              "      <td>-0.988316</td>\n",
              "      <td>-1.050631</td>\n",
              "      <td>-0.028760</td>\n",
              "      <td>-0.116055</td>\n",
              "      <td>-0.636846</td>\n",
              "      <td>-1.837041</td>\n",
              "      <td>0.147415</td>\n",
              "      <td>-1.532327</td>\n",
              "      <td>-1.123638</td>\n",
              "      <td>-0.817380</td>\n",
              "      <td>-0.849829</td>\n",
              "      <td>-0.918340</td>\n",
              "      <td>-0.792166</td>\n",
              "      <td>-0.630653</td>\n",
              "      <td>-0.822036</td>\n",
              "      <td>-0.777047</td>\n",
              "      <td>-1.175568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-01 00:03:00</td>\n",
              "      <td>-1.073661</td>\n",
              "      <td>-0.988798</td>\n",
              "      <td>-1.049922</td>\n",
              "      <td>0.089264</td>\n",
              "      <td>-0.043667</td>\n",
              "      <td>-0.556540</td>\n",
              "      <td>-1.643493</td>\n",
              "      <td>0.023152</td>\n",
              "      <td>-1.545327</td>\n",
              "      <td>-0.758922</td>\n",
              "      <td>0.678985</td>\n",
              "      <td>-0.740023</td>\n",
              "      <td>-0.253623</td>\n",
              "      <td>-0.643206</td>\n",
              "      <td>-0.630653</td>\n",
              "      <td>-0.763700</td>\n",
              "      <td>-0.664147</td>\n",
              "      <td>-1.175568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-01 00:04:00</td>\n",
              "      <td>-1.075401</td>\n",
              "      <td>-0.988670</td>\n",
              "      <td>-1.050114</td>\n",
              "      <td>0.031327</td>\n",
              "      <td>-0.071754</td>\n",
              "      <td>-0.608493</td>\n",
              "      <td>-1.882582</td>\n",
              "      <td>0.161405</td>\n",
              "      <td>-1.650254</td>\n",
              "      <td>-0.726741</td>\n",
              "      <td>-0.817380</td>\n",
              "      <td>0.303134</td>\n",
              "      <td>1.740530</td>\n",
              "      <td>1.889123</td>\n",
              "      <td>1.950416</td>\n",
              "      <td>0.053002</td>\n",
              "      <td>-0.043201</td>\n",
              "      <td>1.477941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55316161-2c8c-47a8-87e9-b546c2952796')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55316161-2c8c-47a8-87e9-b546c2952796 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55316161-2c8c-47a8-87e9-b546c2952796');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_weekdays_norm.head()"
      ],
      "metadata": {
        "id": "mQo9ewweclhz",
        "outputId": "1f51d689-1af4-4d7e-af19-0542a92c8a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "240  2020-06-01 04:00:00 -3.844526 -2.815111 -3.811858  1.679619  1.570822   \n",
              "241  2020-06-01 04:01:00 -3.846186 -3.787824 -3.823188  1.763631  1.696076   \n",
              "242  2020-06-01 04:02:00 -3.839272 -1.875102 -2.712874  1.852445  1.730759   \n",
              "243  2020-06-01 04:03:00 -3.842709 -3.088604 -3.827000  1.832063  1.744944   \n",
              "244  2020-06-01 04:04:00 -3.844287 -2.842539 -3.450520  1.753998  1.623568   \n",
              "\n",
              "         ULL3  COS_PHI1  COS_PHI2   COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
              "240  1.782563 -1.458455 -0.043591 -11.695581 -0.570289 -0.884008 -3.224201   \n",
              "241  1.843617 -1.467086 -2.835547 -11.782866  0.903443  2.133621 -3.224201   \n",
              "242  1.917486 -1.557711  0.058113  -1.543490  0.445873  0.624807 -1.273229   \n",
              "243  1.905749 -1.475716 -0.716154 -12.237347 -0.219683  0.624807 -1.923553   \n",
              "244  1.808403 -1.527502 -0.430725  -5.973931 -0.611886 -0.884008 -1.842262   \n",
              "\n",
              "      RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "240 -1.568103 -1.701045  -1.466370      -3.271799 -2.865462  -1.695805  \n",
              "241 -1.568103 -1.701045  -1.466370      -3.357651 -2.939190  -1.695805  \n",
              "242 -0.765503 -1.118658  -0.885575      -1.211362 -0.948518  -0.928865  \n",
              "243 -1.568103 -1.312787  -1.272772      -2.069878 -1.538347  -0.928865  \n",
              "244 -0.765503 -1.312787  -1.272772      -2.069878 -1.464618  -0.928865  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49f38129-b100-422b-8f27-e8153f0acd8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>2020-06-01 04:00:00</td>\n",
              "      <td>-3.844526</td>\n",
              "      <td>-2.815111</td>\n",
              "      <td>-3.811858</td>\n",
              "      <td>1.679619</td>\n",
              "      <td>1.570822</td>\n",
              "      <td>1.782563</td>\n",
              "      <td>-1.458455</td>\n",
              "      <td>-0.043591</td>\n",
              "      <td>-11.695581</td>\n",
              "      <td>-0.570289</td>\n",
              "      <td>-0.884008</td>\n",
              "      <td>-3.224201</td>\n",
              "      <td>-1.568103</td>\n",
              "      <td>-1.701045</td>\n",
              "      <td>-1.466370</td>\n",
              "      <td>-3.271799</td>\n",
              "      <td>-2.865462</td>\n",
              "      <td>-1.695805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>2020-06-01 04:01:00</td>\n",
              "      <td>-3.846186</td>\n",
              "      <td>-3.787824</td>\n",
              "      <td>-3.823188</td>\n",
              "      <td>1.763631</td>\n",
              "      <td>1.696076</td>\n",
              "      <td>1.843617</td>\n",
              "      <td>-1.467086</td>\n",
              "      <td>-2.835547</td>\n",
              "      <td>-11.782866</td>\n",
              "      <td>0.903443</td>\n",
              "      <td>2.133621</td>\n",
              "      <td>-3.224201</td>\n",
              "      <td>-1.568103</td>\n",
              "      <td>-1.701045</td>\n",
              "      <td>-1.466370</td>\n",
              "      <td>-3.357651</td>\n",
              "      <td>-2.939190</td>\n",
              "      <td>-1.695805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>2020-06-01 04:02:00</td>\n",
              "      <td>-3.839272</td>\n",
              "      <td>-1.875102</td>\n",
              "      <td>-2.712874</td>\n",
              "      <td>1.852445</td>\n",
              "      <td>1.730759</td>\n",
              "      <td>1.917486</td>\n",
              "      <td>-1.557711</td>\n",
              "      <td>0.058113</td>\n",
              "      <td>-1.543490</td>\n",
              "      <td>0.445873</td>\n",
              "      <td>0.624807</td>\n",
              "      <td>-1.273229</td>\n",
              "      <td>-0.765503</td>\n",
              "      <td>-1.118658</td>\n",
              "      <td>-0.885575</td>\n",
              "      <td>-1.211362</td>\n",
              "      <td>-0.948518</td>\n",
              "      <td>-0.928865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>2020-06-01 04:03:00</td>\n",
              "      <td>-3.842709</td>\n",
              "      <td>-3.088604</td>\n",
              "      <td>-3.827000</td>\n",
              "      <td>1.832063</td>\n",
              "      <td>1.744944</td>\n",
              "      <td>1.905749</td>\n",
              "      <td>-1.475716</td>\n",
              "      <td>-0.716154</td>\n",
              "      <td>-12.237347</td>\n",
              "      <td>-0.219683</td>\n",
              "      <td>0.624807</td>\n",
              "      <td>-1.923553</td>\n",
              "      <td>-1.568103</td>\n",
              "      <td>-1.312787</td>\n",
              "      <td>-1.272772</td>\n",
              "      <td>-2.069878</td>\n",
              "      <td>-1.538347</td>\n",
              "      <td>-0.928865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>2020-06-01 04:04:00</td>\n",
              "      <td>-3.844287</td>\n",
              "      <td>-2.842539</td>\n",
              "      <td>-3.450520</td>\n",
              "      <td>1.753998</td>\n",
              "      <td>1.623568</td>\n",
              "      <td>1.808403</td>\n",
              "      <td>-1.527502</td>\n",
              "      <td>-0.430725</td>\n",
              "      <td>-5.973931</td>\n",
              "      <td>-0.611886</td>\n",
              "      <td>-0.884008</td>\n",
              "      <td>-1.842262</td>\n",
              "      <td>-0.765503</td>\n",
              "      <td>-1.312787</td>\n",
              "      <td>-1.272772</td>\n",
              "      <td>-2.069878</td>\n",
              "      <td>-1.464618</td>\n",
              "      <td>-0.928865</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49f38129-b100-422b-8f27-e8153f0acd8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49f38129-b100-422b-8f27-e8153f0acd8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49f38129-b100-422b-8f27-e8153f0acd8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_weekend_norm.head()"
      ],
      "metadata": {
        "id": "TBgx07hRcodl",
        "outputId": "94e4d72d-b2ef-4b38-e167-6e5035fac4c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "0  2020-06-01 00:00:00 -0.520051 -0.469417 -0.491179 -0.852017 -1.003068   \n",
              "1  2020-06-01 00:01:00 -0.518390 -0.469592 -0.485656 -0.905465 -1.016009   \n",
              "2  2020-06-01 00:02:00 -0.520102 -0.348132 -0.489844 -0.987181 -1.028018   \n",
              "3  2020-06-01 00:03:00 -0.515582 -0.349161 -0.488267 -0.814230 -0.926227   \n",
              "4  2020-06-01 00:04:00 -0.519607 -0.348889 -0.488696 -0.899130 -0.965723   \n",
              "\n",
              "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
              "0 -1.783292 -1.338808 -1.189834 -0.885658 -0.479759 -0.761410  1.276387   \n",
              "1 -1.803094 -1.356629 -1.159350 -0.870606 -1.233069  0.728477 -0.330467   \n",
              "2 -1.808977 -1.303165  0.693881 -0.921471 -1.217799 -0.761410 -0.330467   \n",
              "3 -1.693993 -1.082826  0.575856 -0.936003 -0.871684  0.728477 -0.211441   \n",
              "4 -1.768380 -1.355009  0.707168 -1.053303 -0.841144 -0.761410  0.919308   \n",
              "\n",
              "    RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "0  1.388355  1.509262   1.555410       1.427389  1.381491   2.307679  \n",
              "1 -0.570467 -0.350376  -0.254028      -0.283821 -0.298828  -0.881879  \n",
              "2 -0.570467 -0.350376  -0.254028      -0.283821 -0.298828  -0.881879  \n",
              "3  0.082473 -0.195407  -0.254028      -0.218005 -0.174360  -0.881879  \n",
              "4  2.041296  2.439081   2.377882       0.703416  0.510214   1.669767  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31b013c6-e5d5-4514-9178-4e1e59ad528c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-01 00:00:00</td>\n",
              "      <td>-0.520051</td>\n",
              "      <td>-0.469417</td>\n",
              "      <td>-0.491179</td>\n",
              "      <td>-0.852017</td>\n",
              "      <td>-1.003068</td>\n",
              "      <td>-1.783292</td>\n",
              "      <td>-1.338808</td>\n",
              "      <td>-1.189834</td>\n",
              "      <td>-0.885658</td>\n",
              "      <td>-0.479759</td>\n",
              "      <td>-0.761410</td>\n",
              "      <td>1.276387</td>\n",
              "      <td>1.388355</td>\n",
              "      <td>1.509262</td>\n",
              "      <td>1.555410</td>\n",
              "      <td>1.427389</td>\n",
              "      <td>1.381491</td>\n",
              "      <td>2.307679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-01 00:01:00</td>\n",
              "      <td>-0.518390</td>\n",
              "      <td>-0.469592</td>\n",
              "      <td>-0.485656</td>\n",
              "      <td>-0.905465</td>\n",
              "      <td>-1.016009</td>\n",
              "      <td>-1.803094</td>\n",
              "      <td>-1.356629</td>\n",
              "      <td>-1.159350</td>\n",
              "      <td>-0.870606</td>\n",
              "      <td>-1.233069</td>\n",
              "      <td>0.728477</td>\n",
              "      <td>-0.330467</td>\n",
              "      <td>-0.570467</td>\n",
              "      <td>-0.350376</td>\n",
              "      <td>-0.254028</td>\n",
              "      <td>-0.283821</td>\n",
              "      <td>-0.298828</td>\n",
              "      <td>-0.881879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-01 00:02:00</td>\n",
              "      <td>-0.520102</td>\n",
              "      <td>-0.348132</td>\n",
              "      <td>-0.489844</td>\n",
              "      <td>-0.987181</td>\n",
              "      <td>-1.028018</td>\n",
              "      <td>-1.808977</td>\n",
              "      <td>-1.303165</td>\n",
              "      <td>0.693881</td>\n",
              "      <td>-0.921471</td>\n",
              "      <td>-1.217799</td>\n",
              "      <td>-0.761410</td>\n",
              "      <td>-0.330467</td>\n",
              "      <td>-0.570467</td>\n",
              "      <td>-0.350376</td>\n",
              "      <td>-0.254028</td>\n",
              "      <td>-0.283821</td>\n",
              "      <td>-0.298828</td>\n",
              "      <td>-0.881879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-01 00:03:00</td>\n",
              "      <td>-0.515582</td>\n",
              "      <td>-0.349161</td>\n",
              "      <td>-0.488267</td>\n",
              "      <td>-0.814230</td>\n",
              "      <td>-0.926227</td>\n",
              "      <td>-1.693993</td>\n",
              "      <td>-1.082826</td>\n",
              "      <td>0.575856</td>\n",
              "      <td>-0.936003</td>\n",
              "      <td>-0.871684</td>\n",
              "      <td>0.728477</td>\n",
              "      <td>-0.211441</td>\n",
              "      <td>0.082473</td>\n",
              "      <td>-0.195407</td>\n",
              "      <td>-0.254028</td>\n",
              "      <td>-0.218005</td>\n",
              "      <td>-0.174360</td>\n",
              "      <td>-0.881879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-01 00:04:00</td>\n",
              "      <td>-0.519607</td>\n",
              "      <td>-0.348889</td>\n",
              "      <td>-0.488696</td>\n",
              "      <td>-0.899130</td>\n",
              "      <td>-0.965723</td>\n",
              "      <td>-1.768380</td>\n",
              "      <td>-1.355009</td>\n",
              "      <td>0.707168</td>\n",
              "      <td>-1.053303</td>\n",
              "      <td>-0.841144</td>\n",
              "      <td>-0.761410</td>\n",
              "      <td>0.919308</td>\n",
              "      <td>2.041296</td>\n",
              "      <td>2.439081</td>\n",
              "      <td>2.377882</td>\n",
              "      <td>0.703416</td>\n",
              "      <td>0.510214</td>\n",
              "      <td>1.669767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31b013c6-e5d5-4514-9178-4e1e59ad528c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31b013c6-e5d5-4514-9178-4e1e59ad528c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31b013c6-e5d5-4514-9178-4e1e59ad528c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this moment we have six different datasets to use:\n",
        "* dataset_clean (Whole dataset)\n",
        "* dataset_weekdays (Entries from weekdays from 4:00 to 19:30)\n",
        "* dataset_weekend (Entries from Weekends and from weekdays from 19:30 to 4:00)\n",
        "* dataset_norm (Whole dataset, mean/stddev normalised)\n",
        "* dataset_weekdays_norm (Entries from weekdays from 4:00 to 19:30, mean/stddev normalised)\n",
        "* dataset_weekend_norm (Entries from Weekends and from weekdays from 19:30 to 4:00, mean/stddev normalised)"
      ],
      "metadata": {
        "id": "hnu9AcwDW8ZH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJeKUzS0jDhq"
      },
      "source": [
        "# Preparation Training and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvocvIBA292-"
      },
      "source": [
        "Once the dataset is prepared, make batches of data,put them togheter in an array and split them into train and test sets.\n",
        "After looking through the dataset and the features, i decided to takeonly the values with a timestap of a weekday between 4:00 and 19:30. In many of the features in the interval outside those timestamps there i only noise, which can be a sign that the machine is off in that time interval."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches_whole = utils_bsc.create_batches(dataset_clean, 30)\n",
        "batches_whole_norm = utils_bsc.create_batches(dataset_norm, 30)\n",
        "\n",
        "print(f'\\nWhole dataset: {len(batches_whole)} pairs of sequences of longitud {batches_whole[0].shape[1]} with {batches_whole[0].shape[2]} features')\n",
        "print(f'Whole dataset Normalised: {len(batches_whole_norm)} pairs of sequences of longitud {batches_whole_norm[0].shape[1]} with {batches_whole_norm[0].shape[2]} features')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYHPFPjUfpsK",
        "outputId": "566e8e7d-b466-4579-be2e-39e5eafad190"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63330/63330 [00:10<00:00, 5801.17it/s]\n",
            "100%|██████████| 63330/63330 [00:10<00:00, 6049.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(63329, 2, 30, 18)\n",
            "\n",
            "Whole dataset: 63329 pairs of sequences of longitud 30 with 18 features\n",
            "Whole dataset Normalised: 63329 pairs of sequences of longitud 30 with 18 features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(batches_whole_norm.shape)\n",
        "print(type(batches_whole_norm))\n",
        "print(type(batches_whole_norm[0]))\n",
        "print(type(batches_whole_norm[0][0][0]))\n",
        "for i in batches_whole_norm[0][0][0]:\n",
        "  print(type(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afy4nD2MB81L",
        "outputId": "578162dd-2580-469d-f3db-a8a3f3dbb86c"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(63329, 2, 30, 18)\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.float64'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting into train and test sets and convert into pytorch tensors with the normalised data\n",
        "\n",
        "\n",
        "training_data_whole_norm, testing_data_whole_norm = train_test_split(batches_whole_norm, test_size=0.1, random_state=25)\n",
        "\n",
        "print(type(training_data_whole_norm))\n",
        "print(training_data_whole_norm.shape)\n",
        "print(type(training_data_whole_norm[0]))\n",
        "print(training_data_whole_norm[0].shape)\n",
        "print(type(training_data_whole_norm[0][0]))\n",
        "print(training_data_whole_norm[0][0].shape)\n",
        "print(type(training_data_whole_norm[0][0][0]))\n",
        "print(training_data_whole_norm[0][0][0].shape)\n",
        "print(training_data_whole_norm[0][0][0])\n",
        "\n",
        "training_data_whole_norm = torch.from_numpy(training_data_whole_norm).float().to(device)\n",
        "testing_data_whole_norm = torch.from_numpy(testing_data_whole_norm).float().to(device)\n",
        "\n",
        "print(f'length of training set (whole dataset): {training_data_whole.shape[0]}')\n",
        "print(f'length of test set (whole dataset): {testing_data_whole.shape[0]}')\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "QH7L9G-M_PTw",
        "outputId": "c6b5016c-5014-48b1-df91-8bd74be50515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(56996, 2, 30, 18)\n",
            "<class 'numpy.ndarray'>\n",
            "(2, 30, 18)\n",
            "<class 'numpy.ndarray'>\n",
            "(30, 18)\n",
            "<class 'numpy.ndarray'>\n",
            "(18,)\n",
            "[ 0.93692739  0.66488652  0.73407013 -1.02309578 -0.94027917 -1.06852472\n",
            "  0.84702147  0.65598575  0.80809456  1.20410812  0.67898539 -0.08118725\n",
            " -0.25362287 -0.3452846  -0.46933621  0.05300223 -0.15610002 -0.51219082]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-8882736bde2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtesting_data_whole_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_data_whole_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'length of training set (whole dataset): {training_data_whole.shape[0]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'length of test set (whole dataset): {testing_data_whole.shape[0]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_data_whole' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset with pairs data / Target (in this case data is one measure (18 features) and target is the next measure (18 features))\n",
        "# When you plug in one measure, the model should out the next measure\n",
        "\n",
        "pair_set = []\n",
        "\n",
        "for i in tqdm(range(len(dataset_norm) -1)):\n",
        "  data = np.array([j for j in dataset_norm.iloc[i, 1:]])\n",
        "  target = np.array([j for j in dataset_norm.iloc[i+1, 1:]])\n",
        "  \n",
        "  pair_set.append((data, target))\n",
        "\n",
        "dataset_pairs = np.array(pair_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI6P8KvabrMO",
        "outputId": "6088e6b5-2f23-4352-c330-ca8f0b674672"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63359/63359 [00:22<00:00, 2839.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_pairs, testing_data_pairs = train_test_split(dataset_pairs, test_size=0.1, random_state=25)\n",
        "\n",
        "data = []\n",
        "target = []\n",
        "for i in training_data_pairs:\n",
        "  data.append(i[0])\n",
        "  target.append(i[1])\n",
        "\n",
        "training_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "training_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "data = []\n",
        "target = []\n",
        "for i in testing_data_pairs:\n",
        "  data.append(i[0])\n",
        "  target.append(i[1])\n",
        "\n",
        "test_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "test_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "print(f'length of training set (whole dataset): {training_data.shape[0]}')\n",
        "print(f'length of test set (whole dataset): {test_data.shape[0]}')\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "kgHc7L9_cfN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac7b559-f6b5-49de-f07b-c2618bb8b194"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set (whole dataset): 57023\n",
            "length of test set (whole dataset): 6336\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Baseline Model\n",
        "\n",
        "I am taking the Last step as prediction of all features to create a baselinemodel. I will use this baseline model to compare the results of the actual model with it. Everything that works better than this baseline model could be an improvement."
      ],
      "metadata": {
        "id": "VazanvM-f9cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "\n",
        "losses_train = []\n",
        "\n",
        "for i in range(1, len(training_data_whole_norm)):\n",
        "  output = training_data[i]\n",
        "  target = training_target[i]\n",
        "  loss = criterion(output, target)\n",
        "  losses_train.append(loss.item())\n",
        "\n",
        "losses_test = []\n",
        "\n",
        "for i in range(1, len(testing_data_pairs)):\n",
        "  output = test_data[i]\n",
        "  target = test_target[i]\n",
        "  loss = criterion(output, target)\n",
        "  losses_test.append(loss.item())\n",
        "\n",
        "print(\"Training set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_train))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_train))\n",
        "print('\\n')\n",
        "print(\"Test set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_test))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_test))\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "zaWwwy7Igbh3",
        "outputId": "73b691d8-3054-4278-9199-3e67c6543b7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set\n",
            "Mean Loss of baselinemodel:  0.4737651490329326\n",
            "Standard deviation Loss of baselinemodel:  0.7239740402432294\n",
            "\n",
            "\n",
            "Test set\n",
            "Mean Loss of baselinemodel:  0.4659431133047794\n",
            "Standard deviation Loss of baselinemodel:  0.6987633647386906\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a simple Feed Forward Neural Network\n",
        "\n",
        "I trained a simple FFN Network to have a second baseline model. The final model training should have also a better performance than this FFN."
      ],
      "metadata": {
        "id": "aX-B-7HMqFeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loader to feed the FFN in mini batches\n",
        "\n",
        "loader_train = torch.utils.data.DataLoader(\n",
        "    dataset=torch.utils.data.TensorDataset(training_data, training_target),\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Create data loader for testing the model\n",
        "loader_test = torch.utils.data.DataLoader(\n",
        "    dataset=torch.utils.data.TensorDataset(test_data, test_target),\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "GH0JrXGDSLFc"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN_relu(nn.Module):\n",
        "\n",
        "    def __init__(self, D_in, D_out):\n",
        "        super(ANN_relu, self).__init__()\n",
        "        self.linear1 = nn.Linear(D_in, 180)\n",
        "        self.linear2 = nn.Linear(180, 180)\n",
        "        self.linear3 = nn.Linear(20, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.linear1(x))\n",
        "        x = torch.relu(self.linear2(x))\n",
        "        return self.linear3(x)\n",
        "\n",
        "# This function trains the model for one epoch\n",
        "def train(model, device, train_set, optimizer, n_epochs):\n",
        "\n",
        "    epoch_loss = []\n",
        "\n",
        "    for e in range(1, n_epochs +1):\n",
        "      print(f'\\nEpoch {e}:')\n",
        "\n",
        "      losses = []\n",
        "\n",
        "      print('Train')\n",
        "      model.train()\n",
        "      for batch_idx in tqdm(range(len(train_set))):\n",
        "        \n",
        "        batch = train_set[batch_idx]\n",
        "\n",
        "        for i in range(len(batch) - 1):\n",
        "\n",
        "          data, target = batch[i].to(device), batch[i + 1].to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Forward Pass\n",
        "          output = model(data)\n",
        "\n",
        "          #Compute loss\n",
        "          loss = criterion(output, target)\n",
        "\n",
        "          #Backpropagation\n",
        "          loss.backward()\n",
        "\n",
        "          #Optimization\n",
        "          optimizer.step()\n",
        "\n",
        "\n",
        "      print('\\nTest with training set')\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for batch_idx in tqdm(range(len(train_set))):\n",
        "          batch = train_set[batch_idx]\n",
        "\n",
        "          for i in range(len(batch) - 1):\n",
        "\n",
        "            data, target = batch[i].to(device), batch[i + 1].to(device)\n",
        "\n",
        "            output = model(data)\n",
        "              \n",
        "            losses.append (float(criterion(output, target).item()))\n",
        "\n",
        "\n",
        "      print('\\nCurrent Mean loss: ', np.mean(losses))\n",
        "      epoch_loss.append(losses)\n",
        "\n",
        "    return model, epoch_loss\n",
        "\n",
        "n_epochs = 4\n",
        "lr=0.001\n",
        "\n",
        "# Define Loss, Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "train_FFN = True\n",
        "if train_FFN is True:\n",
        "  print('Whole Dataset:')\n",
        "  model_FFN_whole = ANN_relu(18, 18).to(device)\n",
        "  optimizer = torch.optim.SGD(model_FFN_whole.parameters(), lr=lr)\n",
        "  trained_model3 , whole_set_losses = train(model_FFN_whole, device, training_data_whole_norm, optimizer, n_epochs)\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "n9961Y_qY190",
        "outputId": "482811cb-a63f-4602-8bb8-eaf4b594b6be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weekday Dataset:\n",
            "\n",
            "Epoch 1:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25976/25976 [09:29<00:00, 45.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25976/25976 [02:08<00:00, 201.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current loss:  0.30983840211929425\n",
            "\n",
            "Epoch 2:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25976/25976 [09:23<00:00, 46.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25976/25976 [02:10<00:00, 199.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current loss:  0.3087435358885242\n",
            "\n",
            "Epoch 3:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25976/25976 [09:22<00:00, 46.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25976/25976 [02:09<00:00, 200.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current loss:  0.30808435389590766\n",
            "\n",
            "Epoch 4:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25976/25976 [09:22<00:00, 46.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25976/25976 [02:09<00:00, 200.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current loss:  0.3069355035234076\n",
            "\n",
            "\n",
            "Weekend Dataset:\n",
            "\n",
            "Epoch 1:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28294/28294 [10:14<00:00, 46.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28294/28294 [02:21<00:00, 200.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current loss:  0.46093833830883485\n",
            "\n",
            "Epoch 2:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28294/28294 [10:45<00:00, 43.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28294/28294 [02:23<00:00, 197.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current loss:  0.45740237129269457\n",
            "\n",
            "Epoch 3:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28294/28294 [10:15<00:00, 45.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28294/28294 [02:21<00:00, 200.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current loss:  0.455178074687676\n",
            "\n",
            "Epoch 4:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28294/28294 [10:15<00:00, 45.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28294/28294 [02:21<00:00, 199.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current loss:  0.45328326599206925\n",
            "\n",
            "\n",
            "Whole Dataset:\n",
            "\n",
            "Epoch 1:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56997/56997 [20:27<00:00, 46.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56997/56997 [04:42<00:00, 201.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current loss:  0.2979278438075961\n",
            "\n",
            "Epoch 2:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56997/56997 [20:34<00:00, 46.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56997/56997 [04:43<00:00, 200.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current loss:  0.2953299432862701\n",
            "\n",
            "Epoch 3:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56997/56997 [20:36<00:00, 46.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56997/56997 [04:44<00:00, 200.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current loss:  0.2940153248391583\n",
            "\n",
            "Epoch 4:\n",
            "Train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56997/56997 [20:33<00:00, 46.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56997/56997 [04:43<00:00, 200.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current loss:  0.2933188504910381\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This function Test the model with the test set\n",
        "def test(model, test_set):\n",
        "\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  print('\\nTest with Test set')\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch_idx in tqdm(range(len(test_set))):\n",
        "      batch = test_set[batch_idx]\n",
        "\n",
        "      for i in range(len(batch) - 1):\n",
        "\n",
        "        data, target = batch[i].to(device), batch[i + 1].to(device)\n",
        "\n",
        "        output = model(data)\n",
        "          \n",
        "        losses.append (float(criterion(output, target).item()))\n",
        "\n",
        "    print('\\nMean Loss in Test set: ', np.mean(losses))\n",
        "\n",
        "print('Weekday Dataset:')\n",
        "test(trained_model1, testing_data_weekday_norm)\n",
        "print('\\n')\n",
        "\n",
        "print('Weekend Dataset:')\n",
        "test(trained_model2, testing_data_weekend_norm)\n",
        "print('\\n')\n",
        "\n",
        "print('Whole Dataset:')\n",
        "test(trained_model3, testing_data_whole_norm)\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7NxUNJNiHcV",
        "outputId": "b37571e5-043d-454a-e25c-4d425d4b9864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weekday Dataset:\n",
            "\n",
            "Test with Test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2887/2887 [00:14<00:00, 201.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mean Loss in Test set:  0.6996191194919645\n",
            "\n",
            "\n",
            "Weekend Dataset:\n",
            "\n",
            "Test with Test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3144/3144 [00:15<00:00, 200.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mean Loss in Test set:  0.5895734702318555\n",
            "\n",
            "\n",
            "Weekday Dataset:\n",
            "\n",
            "Test with Test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6333/6333 [00:31<00:00, 198.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mean Loss in Test set:  0.4478775834217984\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last basemodel i am going to use is a simple RNN. The final model should also have a better performance than this RNN."
      ],
      "metadata": {
        "id": "Y93gczvmqiT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Model\n",
        "\n",
        "We train before a standard RNN and see which results we can expected with a small and easy solution.\n",
        "I am using this template (https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb) and make changes using it as a base.\n",
        "\n",
        "1) torch.nn.RNN (https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)\n",
        "\n",
        "Parameters\n",
        "* input_size – The number of expected features in the input x\n",
        "* hidden_size – The number of features in the hidden state h\n",
        "* num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1\n",
        "* nonlinearity – The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'\n",
        "* bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
        "* batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: False\n",
        "* dropout – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
        "* bidirectional – If True, becomes a bidirectional RNN. Default: False\n",
        "\n",
        "2) torch.nn.Linear (https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
        "\n",
        "Parameters\n",
        "* in_features – size of each input sample\n",
        "* out_features – size of each output sample\n",
        "* bias – If set to False, the layer will not learn an additive bias. Default: True\n"
      ],
      "metadata": {
        "id": "wLCXaTbSsHRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers, device, batch_first = True, dropout = 0):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.device = device\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size = input_size, hidden_size = hidden_dim, num_layers = n_layers, batch_first = batch_first, dropout = dropout)   \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size).to(self.device)\n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        out = torch.relu(out)\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out = out.contiguous().view(-1, self.hidden_dim)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "VOL1v_mjsEDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_RNN(model, criterion, optimizer, train_set, test_set):\n",
        "\n",
        "  epoch_loss_train = []\n",
        "  epoch_loss_test = []\n",
        "\n",
        "  # Training Run\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "    print(f'Epoch {epoch}')\n",
        "\n",
        "    losses_train = []\n",
        "    losses_test = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
        "\n",
        "    print('\\nTraining:')\n",
        "    for i in tqdm(range(len(train_set))):\n",
        "\n",
        "      input = train_set[i][0]\n",
        "\n",
        "      target = train_set[i][1]\n",
        "\n",
        "      output, hidden = model_rnn(input.unsqueeze(0))\n",
        "\n",
        "      #Compute loss\n",
        "      loss = criterion(output, target)\n",
        "\n",
        "      #Backpropagation\n",
        "      loss.backward()\n",
        "\n",
        "      #Optimization\n",
        "      optimizer.step()\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(range(len(train_set))):\n",
        "        input = train_set[i][0]\n",
        "        target = train_set[i][1]\n",
        "\n",
        "        output, hidden = model(input.unsqueeze(0))\n",
        "\n",
        "        #Compute loss\n",
        "        losses_train.append (float(criterion(output, target).item()))\n",
        "\n",
        "    print('\\nTest with test set')\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(range(len(test_set))):\n",
        "        input = train_set[i][0]\n",
        "        target = train_set[i][1]\n",
        "\n",
        "        output, hidden = model(input.unsqueeze(0))\n",
        "\n",
        "        #Compute loss\n",
        "        losses_test.append (float(criterion(output, target).item()))\n",
        "\n",
        "\n",
        "    print('\\nCurrent Mean loss Train Set: ', np.mean(losses_train))\n",
        "    epoch_loss_train.append(losses_train)\n",
        "\n",
        "    print('\\nCurrent Mean loss Test Set: ', np.mean(losses_test))\n",
        "    epoch_loss_test.append(losses_test)\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "  return epoch_loss_train, epoch_loss_test, model"
      ],
      "metadata": {
        "id": "IzAT4IPPwfZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model with hyperparameters\n",
        "model_rnn = RNN(input_size = 18,\n",
        "                output_size = 18,\n",
        "                hidden_dim = 36,\n",
        "                n_layers = 1,\n",
        "                batch_first = True,\n",
        "                dropout = 0,\n",
        "                device = device)\n",
        "\n",
        "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
        "model_rnn = model_rnn.to(device)\n",
        "\n",
        "# Define hyperparameters\n",
        "n_epochs = 4\n",
        "lr=0.01\n",
        "\n",
        "# Define Loss, Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model_rnn.parameters(), lr=lr)\n",
        "\n",
        "train_set = training_data_pairs\n",
        "test_set = testing_data_pairs"
      ],
      "metadata": {
        "id": "kZQzvqz0aU5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXX8lu3jjDhr"
      },
      "source": [
        "# Transformer Model settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dUCsWWo292_"
      },
      "source": [
        "Now, we define a class with the transformer model that we are going to use:\n",
        "\n",
        "Using the already written pytorch library for Transformers:\n",
        "\n",
        "1) torch.nn.TransformerEncoderLayer (https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html)\n",
        "\n",
        "*   d_model –> the number of expected features in the input (required).\n",
        "*   nhead –> the number of heads in the multiheadattention models (required).\n",
        "*   dropout –> the dropout value (default=0.1).\n",
        "*   activation –> the activation function of the intermediate layer, can be a string (“relu” or “gelu”) or a unary callable. (default: relu)\n",
        "*   layer_norm_eps –> the eps value in layer normalization components (default=1e-5).\n",
        "*   batch_first –> If True, then the input and output tensors are provided as (batch, seq, feature). (default: False)\n",
        "*   norm_first –> if True, layer norm is done prior to attention and feedforward operations, respectivaly. Otherwise it’s done after. (default: False (after))\n",
        "\n",
        "2) torch.nn.TransformerDecoderLayer\n",
        "\n",
        "* d_model –> the number of expected features in the input (required).\n",
        "* nhead –> the number of heads in the multiheadattention models (required).\n",
        "* dim_feedforward –> the dimension of the feedforward network model (default=2048).\n",
        "* dropout –> the dropout value (default=0.1).\n",
        "* activation –> the activation function of the intermediate layer, can be a string (“relu” or “gelu”) or a unary callable. Default: relu\n",
        "* layer_norm_eps –> the eps value in layer normalization components (default=1e-5).\n",
        "* batch_first –> If True, then the input and output tensors are provided as (batch, seq, feature). Default: False.\n",
        "* norm_first –> if True, layer norm is done prior to self attention, multihead attention and feedforward operations, respectivaly. Otherwise it’s done after. Default: False (after).\n",
        "\n",
        "3) torch.nn.TransformerEncoder\n",
        "\n",
        "* encoder_layer –> an instance of the TransformerEncoderLayer() class (required).\n",
        "* num_layers –> the number of sub-encoder-layers in the encoder (required).\n",
        "* norm –> the layer normalization component (optional).\n",
        "\n",
        "\n",
        "4) torch.nn.TransformerDecoder\n",
        "\n",
        "* decoder_layer – an instance of the TransformerDecoderLayer() class (required).\n",
        "* num_layers – the number of sub-decoder-layers in the decoder (required).\n",
        "* norm – the layer normalization component (optional).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCC_Bava293A",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def positional_encoding(seq_len: int, dim_model: int, device):\n",
        "    \n",
        "    # Tensor with the positions of every sequence element (0 to seq_len)\n",
        "    pos = torch.arange(seq_len, dtype=float32, device=device).reshape(1, -1, 1)\n",
        "    \n",
        "    # Tensor with the positions of every feature in the sequence (0 to dim_model)\n",
        "    dim = torch.arange(dim_model, dtype=float32, device=device).reshape(1, 1, -1)\n",
        "\n",
        "    phase = pos / (1e4 ** (torch.div(dim, dim_model, rounding_mode='floor')))\n",
        "\n",
        "    position_encoding = torch.where(dim.long() % 2 == 0, sin(phase), cos(phase))\n",
        "\n",
        "    return position_encoding.to(device)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, feature_size, output_size, num_encoder_layers, num_heads, num_decoder_layers, device, debug: bool = False, dropout: float =0.1, batch_first: bool = False):\n",
        "        super(Transformer, self).__init__()\n",
        "        \n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model= feature_size, nhead= num_heads, dropout=dropout, device=device, batch_first=batch_first)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model= feature_size, nhead= num_heads, dropout=dropout, device=device, batch_first=batch_first)\n",
        "        \n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers= num_encoder_layers)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers= num_decoder_layers)\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.device = device\n",
        "        self.debug = debug\n",
        "\n",
        "    def generate_square_mask(self, dim):\n",
        "        return torch.triu(torch.ones(dim, dim) * float('-inf'), diagonal=1).to(self.device)\n",
        "        \n",
        "    def forward (self, src):\n",
        "        \n",
        "        mask = self.generate_square_mask(len(src))\n",
        "        if self.debug is True:\n",
        "            print('mask creation: ok')\n",
        "\n",
        "        src_pos = src + positional_encoding(src.shape[1], src.shape[2], self.device)\n",
        "        if self.debug is True:\n",
        "            print('Pos encoder (encoder): ok')\n",
        "\n",
        "        output = self.encoder (src, mask)\n",
        "        if self.debug is True:\n",
        "            print('encoder pass: ok')\n",
        "        \n",
        "        output = self.decoder (src_pos, output, mask)\n",
        "        if self.debug is True:\n",
        "            print('decoder pass: ok')\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should define an optimizer too.\n",
        "For this, we use the pytorch library:\n",
        "\n",
        "* SGD –> Stochastic gradient descent.\n",
        "\n",
        "1) torch.optim.SDG (https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)\n",
        "\n",
        "* params (iterable) – iterable of parameters to optimize or dicts defining parameter groups\n",
        "* lr (float) – learning rate\n",
        "* momentum (float, optional) – momentum factor (default: 0)\n",
        "* weight_decay (float, optional) – weight decay (L2 penalty) (default: 0)\n",
        "* dampening (float, optional) – dampening for momentum (default: 0)\n",
        "* nesterov (bool, optional) – enables Nesterov momentum (default: False)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8EANo5UFE15A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup model Ok\n",
            "Setup optimizer Ok\n",
            "Epoch:  1\n",
            "Training:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 56996/56996 [22:57<00:00, 41.39it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 56996/56996 [05:35<00:00, 169.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6333/6333 [00:37<00:00, 169.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current Mean loss Train Set:  17.8081452231113\n",
            "\n",
            "Current Mean loss Test Set:  17.808013503253694\n",
            "\n",
            "\n",
            "Epoch:  2\n",
            "Training:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 56996/56996 [22:41<00:00, 41.87it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 56996/56996 [05:36<00:00, 169.24it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6333/6333 [00:37<00:00, 168.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current Mean loss Train Set:  20.689044967284328\n",
            "\n",
            "Current Mean loss Test Set:  20.689511593533\n",
            "\n",
            "\n",
            "Epoch:  3\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56996/56996 [22:30<00:00, 42.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56996/56996 [05:34<00:00, 170.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6333/6333 [00:36<00:00, 171.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train Set:  17.399096156414856\n",
            "\n",
            "Current Mean loss Test Set:  17.37718508319984\n",
            "\n",
            "\n",
            "Epoch:  4\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56996/56996 [22:27<00:00, 42.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56996/56996 [05:32<00:00, 171.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test with training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6333/6333 [00:36<00:00, 172.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Mean loss Train Set:  9.250140273476477\n",
            "\n",
            "Current Mean loss Test Set:  9.267819709392327\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize Transformer Model and Optimizer\n",
        "\n",
        "model = Transformer (num_encoder_layers=3,\n",
        "                     num_decoder_layers=3,\n",
        "                     feature_size=18,\n",
        "                     output_size=18,\n",
        "                     num_heads=3,\n",
        "                     device = device,\n",
        "                     batch_first=False,\n",
        "                     debug=False)\n",
        "\n",
        "\n",
        "train_set = training_data_pairs\n",
        "test_set = testing_data_pairs\n",
        "\n",
        "print('Setup model Ok')\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print('Setup optimizer Ok')\n",
        "\n",
        "epoch_loss_train = []\n",
        "epoch_loss_test = []\n",
        "\n",
        "train_transformer = True\n",
        "\n",
        "if train_transformer is True:\n",
        "\n",
        "  # Lists to keep track of the losses\n",
        "  loss_list_train = []\n",
        "  loss_list_test = []\n",
        "\n",
        "  n_epochs = 4\n",
        "\n",
        "  for e in range(1, n_epochs + 1):\n",
        "    print('Epoch: ', e)\n",
        "\n",
        "    print('Training:')\n",
        "    model.train()\n",
        "    # Initialize optimizer gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i in tqdm(range(len(train_set))):\n",
        "\n",
        "      input = train_set[i][0]\n",
        "\n",
        "      target = train_set[i][1]\n",
        "\n",
        "      net_out = model.forward(input.unsqueeze(0))\n",
        "\n",
        "      #Compute loss\n",
        "      loss = criterion(net_out, target.unsqueeze(0))\n",
        "\n",
        "      #Backpropagation\n",
        "      loss.backward()\n",
        "\n",
        "      #Optimization\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    losses_train = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(range(len(train_set))):\n",
        "        input = train_set[i][0]\n",
        "        target = train_set[i][1]\n",
        "\n",
        "        net_out = model.forward(input.unsqueeze(0))\n",
        "\n",
        "        #Compute loss\n",
        "        losses_train.append (float(criterion(net_out, target.unsqueeze(0)).item()))\n",
        "\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    losses_test = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(range(len(test_set))):\n",
        "        input = train_set[i][0]\n",
        "        target = train_set[i][1]\n",
        "\n",
        "        net_out = model.forward(input.unsqueeze(0))\n",
        "\n",
        "        #Compute loss\n",
        "        losses_test.append (float(criterion(net_out, target.unsqueeze(0)).item()))\n",
        "\n",
        "    print('\\nCurrent Mean loss Train Set: ', np.mean(losses_train))\n",
        "    epoch_loss_train.append(losses_train)\n",
        "\n",
        "    print('\\nCurrent Mean loss Test Set: ', np.mean(losses_test))\n",
        "    epoch_loss_test.append(losses_test)\n",
        "\n",
        "    print('\\n')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Muhz9Q2qjDhs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2088217a-c6fe-4ee8-bda4-8bf8bb564e11"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgrbFBLS293A",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "282db380-6c1a-42ea-a3dd-9e78cf10daca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Show results of the loss function\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ion()\n",
        "\n",
        "fig.show()\n",
        "fig.canvas.draw()\n",
        "\n",
        "ax.plot([np.mean(i) for i in epoch_loss_train])\n",
        "ax.plot([np.mean(i) for i in epoch_loss_test])\n",
        "ax.set_title(\"Mean Squared Error Transformer\")\n",
        "fig.canvas.draw()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS8DcLC-293B"
      },
      "source": [
        "Ideas, things to remember, to search, etc...\n",
        "\n",
        "reconstruction, vergelich mit base line model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "bsc_arbeit.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python392jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}