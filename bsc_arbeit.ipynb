{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0esqvQHT2922"
      },
      "source": [
        "# First: load imports needed for the project and preparation of the project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is necessary to use this notebook in google colab\n",
        "# If you are running this notebook in colab, please change colab to True\n",
        "\n",
        "import os\n",
        "\n",
        "colab = True\n",
        "cwd = os.getcwd()\n",
        "\n",
        "if colab is True and cwd != \"/content/Bsc_Thesis\":\n",
        "  ! git clone https://github.com/SergioTallo/Bsc_Thesis.git\n",
        "  % cd Bsc_Thesis\n",
        "\n",
        "print(cwd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adt0VN_ojbV1",
        "outputId": "1761559e-bcc6-447e-89da-837d9d61235e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Bsc_Thesis'...\n",
            "remote: Enumerating objects: 209, done.\u001b[K\n",
            "remote: Counting objects: 100% (209/209), done.\u001b[K\n",
            "remote: Compressing objects: 100% (197/197), done.\u001b[K\n",
            "remote: Total 209 (delta 129), reused 26 (delta 12), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (209/209), 3.89 MiB | 8.49 MiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n",
            "/content/Bsc_Thesis\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VCwEuYFk2923",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c092f7-4482-4603-ce3a-65bcbbede5ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: GPU = Tesla P100-PCIE-16GB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "from torch import Tensor, float32, sin, cos\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import utils_bsc\n",
        "import datetime\n",
        "import statistics\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "  print('Device: GPU =', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print('Device: CPU')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQPvc4I-4LY5",
        "outputId": "fea17f87-550a-4d1a-da05-416f41ab2a35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "versions of packages:\n",
            "Python: 3.7.13\n",
            "Pandas: 1.3.5\n",
            "Numpy: 1.21.5\n",
            "PyTorch: 1.10.0+cu111\n",
            "Sklearn: 1.0.2\n",
            "seaborn: 0.11.2\n"
          ]
        }
      ],
      "source": [
        "utils_bsc.print_versions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICcfWNfajDhn"
      },
      "source": [
        "# Data loading and preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "bjUFrMX32925"
      },
      "source": [
        "Now, we should create a dataset with all the data stored in the .csv file\n",
        "\n",
        "Description of the data:\n",
        "\n",
        "*   time: Timestamp (YYYY-MM-DD HH:MM:SS)\n",
        "*   PLN1: Power in the phase 1 (W)\n",
        "*   PLN2: Power in the phase 2 (W)\n",
        "*   PLN3: Power in the phase 3 (W)\n",
        "*   ULL1: Current Voltage between 2 phases (V)\n",
        "*   ULL2: Current Voltage between 2 phases (V)\n",
        "*   ULL3: Current Voltage between 2 phases (V)\n",
        "*   COS_PHI1: Phase shift (Cos)\n",
        "*   COS_PHI2: Phase shift (Cos)\n",
        "*   COS_PHI3: Phase shift (Cos)\n",
        "*   FREQ: Electricity Frequency (Hz)\n",
        "*   RC_DC: Fault currents\n",
        "*   RC_AC: Fault currents\n",
        "*   RC_50Hz: Fault currents\n",
        "*   RC_150Hz: Fault currents\n",
        "*   RC_<100Hz: Fault currents\n",
        "*   RC_100Hz-1kHz: Fault currents\n",
        "*   RC_>10kHz: Fault currents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "qIhc9bwK2926",
        "outputId": "f20f7d66-7e02-4471-d4b8-db803593d277",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  time       PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "0  2020-06-01 00:00:00  1141.0819  519.5034  482.9381  398.8613  400.1982   \n",
              "1  2020-06-01 00:01:00  1145.1162  519.1807  491.4436  398.6934  400.1579   \n",
              "2  2020-06-01 00:02:00  1140.9558  743.3837  484.9942  398.4367  400.1205   \n",
              "3  2020-06-01 00:03:00  1151.9409  741.4836  487.4224  398.9800  400.4375   \n",
              "4  2020-06-01 00:04:00  1142.1594  741.9858  486.7629  398.7133  400.3145   \n",
              "\n",
              "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3     FREQ  RC_DC  RC_AC  RC_50Hz  \\\n",
              "0  395.6010    0.8091    0.6864    0.4875  49.9927    4.0   91.0     10.0   \n",
              "1  395.5431    0.8080    0.6903    0.4904  49.9779    5.0   64.0      7.0   \n",
              "2  395.5259    0.8113    0.9274    0.4806  49.9782    4.0   64.0      7.0   \n",
              "3  395.8621    0.8249    0.9123    0.4778  49.9850    5.0   66.0      8.0   \n",
              "4  395.6446    0.8081    0.9291    0.4552  49.9856    4.0   85.0     11.0   \n",
              "\n",
              "   RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "0      39.0       36.0           86.0      82.0        7.0  \n",
              "1      27.0       25.0           60.0      55.0        2.0  \n",
              "2      27.0       25.0           60.0      55.0        2.0  \n",
              "3      28.0       25.0           61.0      57.0        2.0  \n",
              "4      45.0       41.0           75.0      68.0        6.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ce6717c-32ec-4988-a3ca-3536100a5243\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-01 00:00:00</td>\n",
              "      <td>1141.0819</td>\n",
              "      <td>519.5034</td>\n",
              "      <td>482.9381</td>\n",
              "      <td>398.8613</td>\n",
              "      <td>400.1982</td>\n",
              "      <td>395.6010</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.6864</td>\n",
              "      <td>0.4875</td>\n",
              "      <td>49.9927</td>\n",
              "      <td>4.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-01 00:01:00</td>\n",
              "      <td>1145.1162</td>\n",
              "      <td>519.1807</td>\n",
              "      <td>491.4436</td>\n",
              "      <td>398.6934</td>\n",
              "      <td>400.1579</td>\n",
              "      <td>395.5431</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6903</td>\n",
              "      <td>0.4904</td>\n",
              "      <td>49.9779</td>\n",
              "      <td>5.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-01 00:02:00</td>\n",
              "      <td>1140.9558</td>\n",
              "      <td>743.3837</td>\n",
              "      <td>484.9942</td>\n",
              "      <td>398.4367</td>\n",
              "      <td>400.1205</td>\n",
              "      <td>395.5259</td>\n",
              "      <td>0.8113</td>\n",
              "      <td>0.9274</td>\n",
              "      <td>0.4806</td>\n",
              "      <td>49.9782</td>\n",
              "      <td>4.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-01 00:03:00</td>\n",
              "      <td>1151.9409</td>\n",
              "      <td>741.4836</td>\n",
              "      <td>487.4224</td>\n",
              "      <td>398.9800</td>\n",
              "      <td>400.4375</td>\n",
              "      <td>395.8621</td>\n",
              "      <td>0.8249</td>\n",
              "      <td>0.9123</td>\n",
              "      <td>0.4778</td>\n",
              "      <td>49.9850</td>\n",
              "      <td>5.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-01 00:04:00</td>\n",
              "      <td>1142.1594</td>\n",
              "      <td>741.9858</td>\n",
              "      <td>486.7629</td>\n",
              "      <td>398.7133</td>\n",
              "      <td>400.3145</td>\n",
              "      <td>395.6446</td>\n",
              "      <td>0.8081</td>\n",
              "      <td>0.9291</td>\n",
              "      <td>0.4552</td>\n",
              "      <td>49.9856</td>\n",
              "      <td>4.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ce6717c-32ec-4988-a3ca-3536100a5243')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ce6717c-32ec-4988-a3ca-3536100a5243 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ce6717c-32ec-4988-a3ca-3536100a5243');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset = pd.read_csv('data_factory.csv')\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZAyQ-cA2926"
      },
      "source": [
        "Once we have the dataset, we should prepare it. Finding the missing or the NaN values and replace them with suitable values (in this case we use the previous value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNTHq6mO2927",
        "outputId": "ac9d5fe2-d310-4f50-eac1-9d2d095c8461",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with NaN values before cleaning: 2546\n",
            "Number of rows with NaN values after cleaning: 0\n",
            "Total number of samples: 63360\n",
            "Number of features: 19\n"
          ]
        }
      ],
      "source": [
        "# Replace all mising values with NaN\n",
        "dataset = dataset.replace(' ', np.nan)\n",
        "# Search for all the rows with NaN values\n",
        "nan_values = dataset[dataset.isna().any(axis=1)]\n",
        "# Print the shape to know how many are there\n",
        "print(f'Number of rows with NaN values before cleaning: {nan_values.shape[0]}') \n",
        "\n",
        "# Fill all NaN values with the previous row value\n",
        "dataset_clean = dataset.fillna(method='ffill')\n",
        "\n",
        "# Check that there isn't any NaN values\n",
        "nan_values = dataset_clean[dataset_clean.isna().any(axis=1)]\n",
        "# Print the shape to know how many are there\n",
        "print(f'Number of rows with NaN values after cleaning: {nan_values.shape[0]}') \n",
        "\n",
        "#Total number of samples\n",
        "print(f'Total number of samples: {dataset_clean.shape[0]}')\n",
        "print(f'Number of features: {dataset_clean.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d44xLGPbjDhp"
      },
      "source": [
        "# Distribution of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6R7YF-T2928"
      },
      "source": [
        "Now we look at the distribution of the different features of the data over different time intervals.\n",
        "First we take a look of the min and max values, mean and median value and the standard deviation of every feature."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_data = False\n",
        "\n",
        "if print_data is True:\n",
        "  for column in dataset_clean.columns:\n",
        "    if column == 'time':\n",
        "      print(column)\n",
        "      print('Min value: ', dataset_clean[column].min())\n",
        "      print('Max value: ', dataset_clean[column].max())\n",
        "      print('')\n",
        "    else:\n",
        "      print(column)\n",
        "      print('Min value: ', dataset_clean[column].min())\n",
        "      print('Max value: ', dataset_clean[column].max())\n",
        "      print('Mean value: ', dataset_clean[column].mean())\n",
        "      print('Median value: ', dataset_clean[column].median())\n",
        "      print('Standard deviation: ', dataset_clean[column].std())\n",
        "      print('')"
      ],
      "metadata": {
        "id": "pseEB_3qChk4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tQ0vhNNv2928",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Set to True to print the graphs\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "\n",
        "  for i, column in enumerate(dataset_clean.columns):\n",
        "    if i > 0:\n",
        "      # Feature in a weekly interval\n",
        "      utils_bsc.week_plot(dataset_clean, i, column)\n",
        "      # Feature in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
        "      utils_bsc.daily_plot(dataset_clean, i, column)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We print some graphs showing the density distribution of every feature\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_clean.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_clean, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "sJIFPsqkiezx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After looking to the different data graphs i notice there two very different \"time slots\" when the data differs. One is Weekdays between 4:00 and 19:30. The other is Weekdays bewteen 19:30 and 4:00 and Weekends."
      ],
      "metadata": {
        "id": "cWFCmrIH5oA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create two extra data sets, one with the weekdays between 4:00 and 18:30 and one with the rest.\n",
        "dataset_clean_time = pd.to_datetime(dataset_clean['time'])\n",
        "\n",
        "day_mask = dataset_clean_time.dt.day_name()\n",
        "\n",
        "time_mask = (dataset_clean_time.dt.hour >= 4) & ((dataset_clean_time.dt.hour < 19) | ((dataset_clean_time.dt.hour == 19) & (dataset_clean_time.dt.minute <= 30))) & ((day_mask == ('Monday')) | (day_mask == ('Tuesday')) | (day_mask == ('Wednesday')) | (day_mask == ('Thursday')) | (day_mask == ('Friday')))\n",
        "\n",
        "dataset_weekdays = dataset_clean[time_mask]\n",
        "\n",
        "for i in range(len(time_mask)):\n",
        "  if time_mask[i] == False:\n",
        "    time_mask[i] = True\n",
        "  elif time_mask[i] == True:\n",
        "    time_mask[i] = False\n",
        "\n",
        "dataset_weekend = dataset_clean[time_mask]\n",
        "\n",
        "print(f'Weekdays dataset size: {len(dataset_weekdays)}')\n",
        "print(f'Weekend dataset size: {len(dataset_weekend)}')"
      ],
      "metadata": {
        "id": "hVOHl2YDmFV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b515d2-14f3-41eb-877f-447b88be1479"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weekdays dataset size: 29792\n",
            "Weekend dataset size: 33568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekdays.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekdays, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "jYbGTF6mSz5v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekend.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekend, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "hqupNsJw6bzH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this time we have three different datasets:\n",
        "\n",
        "* dataset_clean (Whole dataset)\n",
        "* dataset_weekdays (Entries from weekdays from 4:00 to 19:30)\n",
        "* dataset_weekend (Entries from Weekends and from weekdays from 19:30 to 4:00)\n",
        "\n"
      ],
      "metadata": {
        "id": "mgEydMmqTHtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset normalisation\n",
        "\n",
        "The scale of the data of the different features is very dofferent. Its better to have all of the features in the same scale. Therefore we perform a data normalisation. We choose to do a mean/stddev normalisation. We substract from every value the mean value of the feature and divide the result value by the std dev of this specific feature to have feature values with mean 0 and stddev of 1."
      ],
      "metadata": {
        "id": "B6iRPxmuJzVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the mean / stddev scaling in Pandas using the .mean() and .std() methods\n",
        "def normalize_mean_std_dataset(df):\n",
        "    # copy the dataframe\n",
        "    df_norm = df.copy()\n",
        "    # apply mean / stddev scaling\n",
        "    for column in tqdm(df_norm.columns):\n",
        "      if column != 'time':\n",
        "        df_norm[column] = (df_norm[column] - df_norm[column].mean()) / df_norm[column].std()\n",
        "    return df_norm"
      ],
      "metadata": {
        "id": "HBGfdNkAxxbN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the data normalisation in the whole dataset. We can print the distribution of the data if we want.\n",
        "dataset_norm = normalize_mean_std_dataset(dataset_clean)\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_norm.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_norm, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "1VhzsSn37b_0",
        "outputId": "bbeb7993-ae19-48d4-dfa6-3a939821d34f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 517.70it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the data normalisation in the weekdays dataset. We can print the distribution of the data if we want.\n",
        "dataset_weekdays_norm = normalize_mean_std_dataset(dataset_weekdays)\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekdays_norm.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekdays_norm, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "SuS8dhouVCec",
        "outputId": "dffc2b0c-904c-4160-f94e-22eb2df4123e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 1379.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the data normalisation in the weekdays dataset. We can print the distribution of the data if we want.\n",
        "dataset_weekend_norm = normalize_mean_std_dataset(dataset_weekend)\n",
        "\n",
        "print_graphs = False\n",
        "\n",
        "if print_graphs is True:\n",
        "  for column in tqdm(dataset_weekend_norm.columns):\n",
        "    if column != 'time':\n",
        "      sns.displot(dataset_weekend_norm, x=column, kind=\"kde\")"
      ],
      "metadata": {
        "id": "MH07VtqpVdez",
        "outputId": "ebce2395-7e8d-4ca6-c0fe-c14d2591e9ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 904.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_norm.head()"
      ],
      "metadata": {
        "id": "FDUnKkascXyI",
        "outputId": "c352a67c-8fed-4917-e5a2-9cc8088f5017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "0  2020-06-01 00:00:00 -1.075593 -1.045021 -1.051232  0.063478 -0.098312   \n",
              "1  2020-06-01 00:01:00 -1.074875 -1.045103 -1.048747  0.027004 -0.107515   \n",
              "2  2020-06-01 00:02:00 -1.075615 -0.988316 -1.050631 -0.028760 -0.116055   \n",
              "3  2020-06-01 00:03:00 -1.073661 -0.988798 -1.049922  0.089264 -0.043667   \n",
              "4  2020-06-01 00:04:00 -1.075401 -0.988670 -1.050114  0.031327 -0.071754   \n",
              "\n",
              "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
              "0 -0.618908 -1.868350 -1.835847 -1.500292 -0.345935 -0.817380  0.632551   \n",
              "1 -0.632738 -1.884005 -1.803753 -1.486828 -1.139728  0.678985 -0.849829   \n",
              "2 -0.636846 -1.837041  0.147415 -1.532327 -1.123638 -0.817380 -0.849829   \n",
              "3 -0.556540 -1.643493  0.023152 -1.545327 -0.758922  0.678985 -0.740023   \n",
              "4 -0.608493 -1.882582  0.161405 -1.650254 -0.726741 -0.817380  0.303134   \n",
              "\n",
              "    RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "0  1.075812  0.995360   1.143832       0.694697  0.747095   2.141318  \n",
              "1 -0.918340 -0.792166  -0.630653      -0.822036 -0.777047  -1.175568  \n",
              "2 -0.918340 -0.792166  -0.630653      -0.822036 -0.777047  -1.175568  \n",
              "3 -0.253623 -0.643206  -0.630653      -0.763700 -0.664147  -1.175568  \n",
              "4  1.740530  1.889123   1.950416       0.053002 -0.043201   1.477941  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd64dc24-ee58-4bda-af22-bbdf4a1a444f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-01 00:00:00</td>\n",
              "      <td>-1.075593</td>\n",
              "      <td>-1.045021</td>\n",
              "      <td>-1.051232</td>\n",
              "      <td>0.063478</td>\n",
              "      <td>-0.098312</td>\n",
              "      <td>-0.618908</td>\n",
              "      <td>-1.868350</td>\n",
              "      <td>-1.835847</td>\n",
              "      <td>-1.500292</td>\n",
              "      <td>-0.345935</td>\n",
              "      <td>-0.817380</td>\n",
              "      <td>0.632551</td>\n",
              "      <td>1.075812</td>\n",
              "      <td>0.995360</td>\n",
              "      <td>1.143832</td>\n",
              "      <td>0.694697</td>\n",
              "      <td>0.747095</td>\n",
              "      <td>2.141318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-01 00:01:00</td>\n",
              "      <td>-1.074875</td>\n",
              "      <td>-1.045103</td>\n",
              "      <td>-1.048747</td>\n",
              "      <td>0.027004</td>\n",
              "      <td>-0.107515</td>\n",
              "      <td>-0.632738</td>\n",
              "      <td>-1.884005</td>\n",
              "      <td>-1.803753</td>\n",
              "      <td>-1.486828</td>\n",
              "      <td>-1.139728</td>\n",
              "      <td>0.678985</td>\n",
              "      <td>-0.849829</td>\n",
              "      <td>-0.918340</td>\n",
              "      <td>-0.792166</td>\n",
              "      <td>-0.630653</td>\n",
              "      <td>-0.822036</td>\n",
              "      <td>-0.777047</td>\n",
              "      <td>-1.175568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-01 00:02:00</td>\n",
              "      <td>-1.075615</td>\n",
              "      <td>-0.988316</td>\n",
              "      <td>-1.050631</td>\n",
              "      <td>-0.028760</td>\n",
              "      <td>-0.116055</td>\n",
              "      <td>-0.636846</td>\n",
              "      <td>-1.837041</td>\n",
              "      <td>0.147415</td>\n",
              "      <td>-1.532327</td>\n",
              "      <td>-1.123638</td>\n",
              "      <td>-0.817380</td>\n",
              "      <td>-0.849829</td>\n",
              "      <td>-0.918340</td>\n",
              "      <td>-0.792166</td>\n",
              "      <td>-0.630653</td>\n",
              "      <td>-0.822036</td>\n",
              "      <td>-0.777047</td>\n",
              "      <td>-1.175568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-01 00:03:00</td>\n",
              "      <td>-1.073661</td>\n",
              "      <td>-0.988798</td>\n",
              "      <td>-1.049922</td>\n",
              "      <td>0.089264</td>\n",
              "      <td>-0.043667</td>\n",
              "      <td>-0.556540</td>\n",
              "      <td>-1.643493</td>\n",
              "      <td>0.023152</td>\n",
              "      <td>-1.545327</td>\n",
              "      <td>-0.758922</td>\n",
              "      <td>0.678985</td>\n",
              "      <td>-0.740023</td>\n",
              "      <td>-0.253623</td>\n",
              "      <td>-0.643206</td>\n",
              "      <td>-0.630653</td>\n",
              "      <td>-0.763700</td>\n",
              "      <td>-0.664147</td>\n",
              "      <td>-1.175568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-01 00:04:00</td>\n",
              "      <td>-1.075401</td>\n",
              "      <td>-0.988670</td>\n",
              "      <td>-1.050114</td>\n",
              "      <td>0.031327</td>\n",
              "      <td>-0.071754</td>\n",
              "      <td>-0.608493</td>\n",
              "      <td>-1.882582</td>\n",
              "      <td>0.161405</td>\n",
              "      <td>-1.650254</td>\n",
              "      <td>-0.726741</td>\n",
              "      <td>-0.817380</td>\n",
              "      <td>0.303134</td>\n",
              "      <td>1.740530</td>\n",
              "      <td>1.889123</td>\n",
              "      <td>1.950416</td>\n",
              "      <td>0.053002</td>\n",
              "      <td>-0.043201</td>\n",
              "      <td>1.477941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd64dc24-ee58-4bda-af22-bbdf4a1a444f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd64dc24-ee58-4bda-af22-bbdf4a1a444f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd64dc24-ee58-4bda-af22-bbdf4a1a444f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_weekdays_norm.head()"
      ],
      "metadata": {
        "id": "mQo9ewweclhz",
        "outputId": "f7ebf34f-3fa6-4531-9ab1-db8ae3e4ff2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "240  2020-06-01 04:00:00 -3.844526 -2.815111 -3.811858  1.679619  1.570822   \n",
              "241  2020-06-01 04:01:00 -3.846186 -3.787824 -3.823188  1.763631  1.696076   \n",
              "242  2020-06-01 04:02:00 -3.839272 -1.875102 -2.712874  1.852445  1.730759   \n",
              "243  2020-06-01 04:03:00 -3.842709 -3.088604 -3.827000  1.832063  1.744944   \n",
              "244  2020-06-01 04:04:00 -3.844287 -2.842539 -3.450520  1.753998  1.623568   \n",
              "\n",
              "         ULL3  COS_PHI1  COS_PHI2   COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
              "240  1.782563 -1.458455 -0.043591 -11.695581 -0.570289 -0.884008 -3.224201   \n",
              "241  1.843617 -1.467086 -2.835547 -11.782866  0.903443  2.133621 -3.224201   \n",
              "242  1.917486 -1.557711  0.058113  -1.543490  0.445873  0.624807 -1.273229   \n",
              "243  1.905749 -1.475716 -0.716154 -12.237347 -0.219683  0.624807 -1.923553   \n",
              "244  1.808403 -1.527502 -0.430725  -5.973931 -0.611886 -0.884008 -1.842262   \n",
              "\n",
              "      RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "240 -1.568103 -1.701045  -1.466370      -3.271799 -2.865462  -1.695805  \n",
              "241 -1.568103 -1.701045  -1.466370      -3.357651 -2.939190  -1.695805  \n",
              "242 -0.765503 -1.118658  -0.885575      -1.211362 -0.948518  -0.928865  \n",
              "243 -1.568103 -1.312787  -1.272772      -2.069878 -1.538347  -0.928865  \n",
              "244 -0.765503 -1.312787  -1.272772      -2.069878 -1.464618  -0.928865  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c1d5dc4-5969-471c-95c5-11bf84435d9b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>2020-06-01 04:00:00</td>\n",
              "      <td>-3.844526</td>\n",
              "      <td>-2.815111</td>\n",
              "      <td>-3.811858</td>\n",
              "      <td>1.679619</td>\n",
              "      <td>1.570822</td>\n",
              "      <td>1.782563</td>\n",
              "      <td>-1.458455</td>\n",
              "      <td>-0.043591</td>\n",
              "      <td>-11.695581</td>\n",
              "      <td>-0.570289</td>\n",
              "      <td>-0.884008</td>\n",
              "      <td>-3.224201</td>\n",
              "      <td>-1.568103</td>\n",
              "      <td>-1.701045</td>\n",
              "      <td>-1.466370</td>\n",
              "      <td>-3.271799</td>\n",
              "      <td>-2.865462</td>\n",
              "      <td>-1.695805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>2020-06-01 04:01:00</td>\n",
              "      <td>-3.846186</td>\n",
              "      <td>-3.787824</td>\n",
              "      <td>-3.823188</td>\n",
              "      <td>1.763631</td>\n",
              "      <td>1.696076</td>\n",
              "      <td>1.843617</td>\n",
              "      <td>-1.467086</td>\n",
              "      <td>-2.835547</td>\n",
              "      <td>-11.782866</td>\n",
              "      <td>0.903443</td>\n",
              "      <td>2.133621</td>\n",
              "      <td>-3.224201</td>\n",
              "      <td>-1.568103</td>\n",
              "      <td>-1.701045</td>\n",
              "      <td>-1.466370</td>\n",
              "      <td>-3.357651</td>\n",
              "      <td>-2.939190</td>\n",
              "      <td>-1.695805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>2020-06-01 04:02:00</td>\n",
              "      <td>-3.839272</td>\n",
              "      <td>-1.875102</td>\n",
              "      <td>-2.712874</td>\n",
              "      <td>1.852445</td>\n",
              "      <td>1.730759</td>\n",
              "      <td>1.917486</td>\n",
              "      <td>-1.557711</td>\n",
              "      <td>0.058113</td>\n",
              "      <td>-1.543490</td>\n",
              "      <td>0.445873</td>\n",
              "      <td>0.624807</td>\n",
              "      <td>-1.273229</td>\n",
              "      <td>-0.765503</td>\n",
              "      <td>-1.118658</td>\n",
              "      <td>-0.885575</td>\n",
              "      <td>-1.211362</td>\n",
              "      <td>-0.948518</td>\n",
              "      <td>-0.928865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>2020-06-01 04:03:00</td>\n",
              "      <td>-3.842709</td>\n",
              "      <td>-3.088604</td>\n",
              "      <td>-3.827000</td>\n",
              "      <td>1.832063</td>\n",
              "      <td>1.744944</td>\n",
              "      <td>1.905749</td>\n",
              "      <td>-1.475716</td>\n",
              "      <td>-0.716154</td>\n",
              "      <td>-12.237347</td>\n",
              "      <td>-0.219683</td>\n",
              "      <td>0.624807</td>\n",
              "      <td>-1.923553</td>\n",
              "      <td>-1.568103</td>\n",
              "      <td>-1.312787</td>\n",
              "      <td>-1.272772</td>\n",
              "      <td>-2.069878</td>\n",
              "      <td>-1.538347</td>\n",
              "      <td>-0.928865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>2020-06-01 04:04:00</td>\n",
              "      <td>-3.844287</td>\n",
              "      <td>-2.842539</td>\n",
              "      <td>-3.450520</td>\n",
              "      <td>1.753998</td>\n",
              "      <td>1.623568</td>\n",
              "      <td>1.808403</td>\n",
              "      <td>-1.527502</td>\n",
              "      <td>-0.430725</td>\n",
              "      <td>-5.973931</td>\n",
              "      <td>-0.611886</td>\n",
              "      <td>-0.884008</td>\n",
              "      <td>-1.842262</td>\n",
              "      <td>-0.765503</td>\n",
              "      <td>-1.312787</td>\n",
              "      <td>-1.272772</td>\n",
              "      <td>-2.069878</td>\n",
              "      <td>-1.464618</td>\n",
              "      <td>-0.928865</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c1d5dc4-5969-471c-95c5-11bf84435d9b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c1d5dc4-5969-471c-95c5-11bf84435d9b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c1d5dc4-5969-471c-95c5-11bf84435d9b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_weekend_norm.head()"
      ],
      "metadata": {
        "id": "TBgx07hRcodl",
        "outputId": "53aee7b2-dd36-4406-c122-c0e45c35daac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
              "0  2020-06-01 00:00:00 -0.520051 -0.469417 -0.491179 -0.852017 -1.003068   \n",
              "1  2020-06-01 00:01:00 -0.518390 -0.469592 -0.485656 -0.905465 -1.016009   \n",
              "2  2020-06-01 00:02:00 -0.520102 -0.348132 -0.489844 -0.987181 -1.028018   \n",
              "3  2020-06-01 00:03:00 -0.515582 -0.349161 -0.488267 -0.814230 -0.926227   \n",
              "4  2020-06-01 00:04:00 -0.519607 -0.348889 -0.488696 -0.899130 -0.965723   \n",
              "\n",
              "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
              "0 -1.783292 -1.338808 -1.189834 -0.885658 -0.479759 -0.761410  1.276387   \n",
              "1 -1.803094 -1.356629 -1.159350 -0.870606 -1.233069  0.728477 -0.330467   \n",
              "2 -1.808977 -1.303165  0.693881 -0.921471 -1.217799 -0.761410 -0.330467   \n",
              "3 -1.693993 -1.082826  0.575856 -0.936003 -0.871684  0.728477 -0.211441   \n",
              "4 -1.768380 -1.355009  0.707168 -1.053303 -0.841144 -0.761410  0.919308   \n",
              "\n",
              "    RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
              "0  1.388355  1.509262   1.555410       1.427389  1.381491   2.307679  \n",
              "1 -0.570467 -0.350376  -0.254028      -0.283821 -0.298828  -0.881879  \n",
              "2 -0.570467 -0.350376  -0.254028      -0.283821 -0.298828  -0.881879  \n",
              "3  0.082473 -0.195407  -0.254028      -0.218005 -0.174360  -0.881879  \n",
              "4  2.041296  2.439081   2.377882       0.703416  0.510214   1.669767  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e165a91e-7665-4ea7-91e2-aabe1074c6d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>PLN1</th>\n",
              "      <th>PLN2</th>\n",
              "      <th>PLN3</th>\n",
              "      <th>ULL1</th>\n",
              "      <th>ULL2</th>\n",
              "      <th>ULL3</th>\n",
              "      <th>COS_PHI1</th>\n",
              "      <th>COS_PHI2</th>\n",
              "      <th>COS_PHI3</th>\n",
              "      <th>FREQ</th>\n",
              "      <th>RC_DC</th>\n",
              "      <th>RC_AC</th>\n",
              "      <th>RC_50Hz</th>\n",
              "      <th>RC_150Hz</th>\n",
              "      <th>RC_&lt;100Hz</th>\n",
              "      <th>RC_100Hz-1kHz</th>\n",
              "      <th>RC_&gt;1kHz</th>\n",
              "      <th>RC_&gt;10kHz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-01 00:00:00</td>\n",
              "      <td>-0.520051</td>\n",
              "      <td>-0.469417</td>\n",
              "      <td>-0.491179</td>\n",
              "      <td>-0.852017</td>\n",
              "      <td>-1.003068</td>\n",
              "      <td>-1.783292</td>\n",
              "      <td>-1.338808</td>\n",
              "      <td>-1.189834</td>\n",
              "      <td>-0.885658</td>\n",
              "      <td>-0.479759</td>\n",
              "      <td>-0.761410</td>\n",
              "      <td>1.276387</td>\n",
              "      <td>1.388355</td>\n",
              "      <td>1.509262</td>\n",
              "      <td>1.555410</td>\n",
              "      <td>1.427389</td>\n",
              "      <td>1.381491</td>\n",
              "      <td>2.307679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-01 00:01:00</td>\n",
              "      <td>-0.518390</td>\n",
              "      <td>-0.469592</td>\n",
              "      <td>-0.485656</td>\n",
              "      <td>-0.905465</td>\n",
              "      <td>-1.016009</td>\n",
              "      <td>-1.803094</td>\n",
              "      <td>-1.356629</td>\n",
              "      <td>-1.159350</td>\n",
              "      <td>-0.870606</td>\n",
              "      <td>-1.233069</td>\n",
              "      <td>0.728477</td>\n",
              "      <td>-0.330467</td>\n",
              "      <td>-0.570467</td>\n",
              "      <td>-0.350376</td>\n",
              "      <td>-0.254028</td>\n",
              "      <td>-0.283821</td>\n",
              "      <td>-0.298828</td>\n",
              "      <td>-0.881879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-01 00:02:00</td>\n",
              "      <td>-0.520102</td>\n",
              "      <td>-0.348132</td>\n",
              "      <td>-0.489844</td>\n",
              "      <td>-0.987181</td>\n",
              "      <td>-1.028018</td>\n",
              "      <td>-1.808977</td>\n",
              "      <td>-1.303165</td>\n",
              "      <td>0.693881</td>\n",
              "      <td>-0.921471</td>\n",
              "      <td>-1.217799</td>\n",
              "      <td>-0.761410</td>\n",
              "      <td>-0.330467</td>\n",
              "      <td>-0.570467</td>\n",
              "      <td>-0.350376</td>\n",
              "      <td>-0.254028</td>\n",
              "      <td>-0.283821</td>\n",
              "      <td>-0.298828</td>\n",
              "      <td>-0.881879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-01 00:03:00</td>\n",
              "      <td>-0.515582</td>\n",
              "      <td>-0.349161</td>\n",
              "      <td>-0.488267</td>\n",
              "      <td>-0.814230</td>\n",
              "      <td>-0.926227</td>\n",
              "      <td>-1.693993</td>\n",
              "      <td>-1.082826</td>\n",
              "      <td>0.575856</td>\n",
              "      <td>-0.936003</td>\n",
              "      <td>-0.871684</td>\n",
              "      <td>0.728477</td>\n",
              "      <td>-0.211441</td>\n",
              "      <td>0.082473</td>\n",
              "      <td>-0.195407</td>\n",
              "      <td>-0.254028</td>\n",
              "      <td>-0.218005</td>\n",
              "      <td>-0.174360</td>\n",
              "      <td>-0.881879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-01 00:04:00</td>\n",
              "      <td>-0.519607</td>\n",
              "      <td>-0.348889</td>\n",
              "      <td>-0.488696</td>\n",
              "      <td>-0.899130</td>\n",
              "      <td>-0.965723</td>\n",
              "      <td>-1.768380</td>\n",
              "      <td>-1.355009</td>\n",
              "      <td>0.707168</td>\n",
              "      <td>-1.053303</td>\n",
              "      <td>-0.841144</td>\n",
              "      <td>-0.761410</td>\n",
              "      <td>0.919308</td>\n",
              "      <td>2.041296</td>\n",
              "      <td>2.439081</td>\n",
              "      <td>2.377882</td>\n",
              "      <td>0.703416</td>\n",
              "      <td>0.510214</td>\n",
              "      <td>1.669767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e165a91e-7665-4ea7-91e2-aabe1074c6d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e165a91e-7665-4ea7-91e2-aabe1074c6d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e165a91e-7665-4ea7-91e2-aabe1074c6d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this moment we have six different datasets to use:\n",
        "* dataset_clean (Whole dataset)\n",
        "* dataset_weekdays (Entries from weekdays from 4:00 to 19:30)\n",
        "* dataset_weekend (Entries from Weekends and from weekdays from 19:30 to 4:00)\n",
        "* dataset_norm (Whole dataset, mean/stddev normalised)\n",
        "* dataset_weekdays_norm (Entries from weekdays from 4:00 to 19:30, mean/stddev normalised)\n",
        "* dataset_weekend_norm (Entries from Weekends and from weekdays from 19:30 to 4:00, mean/stddev normalised)"
      ],
      "metadata": {
        "id": "hnu9AcwDW8ZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Covariance matrix of all features"
      ],
      "metadata": {
        "id": "AqX61PrGpaxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "set_ = dataset_norm.iloc[:,1:].values\n",
        "\n",
        "print(set_.shape)\n",
        "print(type(set_[0][0]))\n",
        "\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
        "cov_matrix = np.cov(set_.T)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "# Adds subplot on position 1\n",
        "ax = fig.add_subplot(121)\n",
        "ax.matshow(cov_matrix)\n",
        "plt.show()\n",
        "\n",
        "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "\n",
        "print(eigenvalues)\n",
        "\n",
        "explained_variance = []\n",
        "\n",
        "for i in eigenvalues:\n",
        "    explained_variance.append(i/sum(eigenvalues))\n",
        "\n",
        "print(explained_variance)"
      ],
      "metadata": {
        "id": "wRWPIDDnpWhW",
        "outputId": "0afac382-edf4-4a09-cc9f-9be9c0c5a207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(63360, 18)\n",
            "<class 'numpy.float64'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.572 2.940 1.352 0.989 0.970 0.891 0.405 0.251 0.230 0.177 0.072 0.052\n",
            " 0.039 0.031 0.012 0.004 0.004 0.007]\n",
            "[0.5317647804810274, 0.16335739298653476, 0.07511546472382995, 0.054921627068028424, 0.05390616867076577, 0.04952232661739343, 0.022486349463995598, 0.013932731902136385, 0.012792662672300325, 0.009829012007199104, 0.004024926426955747, 0.002893959610103366, 0.002163271201445878, 0.001741116222641519, 0.0006928432299862775, 0.00021826337426103455, 0.00023351820917083064, 0.0004035851322244031]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJeKUzS0jDhq"
      },
      "source": [
        "# Preparation Training and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvocvIBA292-"
      },
      "source": [
        "Once the dataset is prepared, make batches of data,put them togheter in an array and split them into train and test sets.\n",
        "After looking through the dataset and the features, i decided to takeonly the values with a timestap of a weekday between 4:00 and 19:30. In many of the features in the interval outside those timestamps there i only noise, which can be a sign that the machine is off in that time interval."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloaders(dataset_norm):\n",
        "\n",
        "  # Create a dataset with pairs data / Target (in this case data is one measure (18 features) and target is the next measure (18 features))\n",
        "  # When you plug in one measure, the model should out the next measure\n",
        "\n",
        "  pair_set = []\n",
        "\n",
        "  for i in tqdm(range(len(dataset_norm) -1)):\n",
        "    data = np.array([j for j in dataset_norm.iloc[i, 1:]])\n",
        "    target = np.array([j for j in dataset_norm.iloc[i+1, 1:]])\n",
        "    \n",
        "    pair_set.append((data, target))\n",
        "\n",
        "  dataset_pairs = np.array(pair_set)\n",
        "\n",
        "  training_data_pairs, testing_data_pairs = train_test_split(dataset_pairs, test_size=0.1, random_state=25)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in training_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  training_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  training_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in testing_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  test_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  test_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  print(f'length of training set (whole dataset): {training_data.shape[0]}')\n",
        "  print(f'length of test set (whole dataset): {test_data.shape[0]}')\n",
        "  print('\\n')\n",
        "\n",
        "  # Create data loader to feed the FFN in mini batches\n",
        "\n",
        "  loader_train = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(training_data, training_target),\n",
        "      batch_size=64,\n",
        "      shuffle=True\n",
        "  )\n",
        "\n",
        "  # Create data loader for testing the model\n",
        "  loader_test = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(test_data, test_target),\n",
        "      batch_size=64,\n",
        "      shuffle=True\n",
        "  )\n",
        "\n",
        "  return loader_train, loader_test"
      ],
      "metadata": {
        "id": "eI6P8KvabrMO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_train, loader_test = create_dataloaders(dataset_norm)"
      ],
      "metadata": {
        "id": "kgHc7L9_cfN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcbc3a78-ff3a-4bec-8121-fc785ed5dce2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63359/63359 [00:22<00:00, 2849.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set (whole dataset): 57023\n",
            "length of test set (whole dataset): 6336\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Baseline Model\n",
        "\n",
        "I am taking the Last step as prediction of all features to create a baselinemodel. I will use this baseline model to compare the results of the actual model with it. Everything that works better than this baseline model could be an improvement."
      ],
      "metadata": {
        "id": "VazanvM-f9cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "\n",
        "losses_train = []\n",
        "\n",
        "for i in loader_train:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_train.append(loss.item())\n",
        "\n",
        "losses_test = []\n",
        "\n",
        "for i in loader_test:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_test.append(loss.item())\n",
        "\n",
        "print(\"Training set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_train))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_train))\n",
        "print('\\n')\n",
        "print(\"Test set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_test))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_test))\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me_JXHtgZyuE",
        "outputId": "0f191069-b7c6-48cd-84c9-c48a4708526c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set\n",
            "Mean Loss of baselinemodel:  0.47378840905381103\n",
            "Standard deviation Loss of baselinemodel:  0.09045313580668875\n",
            "\n",
            "\n",
            "Test set\n",
            "Mean Loss of baselinemodel:  0.46593057236286123\n",
            "Standard deviation Loss of baselinemodel:  0.09445233370243061\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a simple Feed Forward Neural Network\n",
        "\n",
        "I trained a simple FFN Network to have a second baseline model. The final model training should have also a better performance than this FFN."
      ],
      "metadata": {
        "id": "aX-B-7HMqFeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN_relu(nn.Module):\n",
        "\n",
        "    def __init__(self, D_in, D_out):\n",
        "        super(ANN_relu, self).__init__()\n",
        "        self.linear1 = nn.Linear(D_in, 180)\n",
        "        self.linear2 = nn.Linear(180, 360)\n",
        "        self.linear3 = nn.Linear(360, 360)\n",
        "        self.linear4 = nn.Linear(360, 180)\n",
        "        self.linear5 = nn.Linear(180, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.linear1(x))\n",
        "        x = torch.relu(self.linear2(x))\n",
        "        x = torch.relu(self.linear3(x))\n",
        "        x = torch.relu(self.linear4(x))\n",
        "        return self.linear5(x)\n",
        "\n",
        "# This function trains the model for one epoch\n",
        "def train(model, criterion, optimizer, train_loader, test_loader, n_epochs):\n",
        "\n",
        "    epoch_loss_train = []\n",
        "    epoch_loss_test = []\n",
        "\n",
        "    for e in range(1, n_epochs +1):\n",
        "      print(f'\\nEpoch {e}:')\n",
        "\n",
        "      print('Train')\n",
        "      model.train()\n",
        "\n",
        "      for i in tqdm(train_loader):\n",
        "\n",
        "        data, target = i[0], i[1]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward Pass\n",
        "        output = model(data)\n",
        "\n",
        "        #Compute loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        #Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        #Optimization\n",
        "        optimizer.step()\n",
        "\n",
        "      losses = []\n",
        "\n",
        "      print('\\nTest with training set')\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for i in tqdm(train_loader):\n",
        "\n",
        "          data, target = i[0], i[1]\n",
        "\n",
        "          output = model(data)\n",
        "              \n",
        "          losses.append (float(criterion(output, target).item()))\n",
        "\n",
        "      print('\\nCurrent Mean loss Train: ', np.mean(losses))\n",
        "      epoch_loss_train.append(losses)\n",
        "\n",
        "      losses = []\n",
        "\n",
        "      print('\\nTest with test set')\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for i in tqdm(test_loader):\n",
        "\n",
        "          data, target = i[0], i[1]\n",
        "\n",
        "          output = model(data)\n",
        "            \n",
        "          losses.append (float(criterion(output, target).item()))\n",
        "\n",
        "\n",
        "      print('\\nCurrent Mean loss: ', np.mean(losses))\n",
        "      epoch_loss_test.append(losses)\n",
        "\n",
        "    return model, epoch_loss_train, epoch_loss_test"
      ],
      "metadata": {
        "id": "n9961Y_qY190"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 50\n",
        "lr=0.01\n",
        "\n",
        "# Create model FFN instance\n",
        "model_FFN_whole = ANN_relu(18, 18).to(device)\n",
        "print(model_FFN_whole)\n",
        "\n",
        "# Define Loss\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer_whole = torch.optim.SGD(model_FFN_whole.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "train_FFN = False\n",
        "\n",
        "params_not_trained_whole = model_FFN_whole.parameters()\n",
        "\n",
        "if train_FFN is True:\n",
        "  trained_model_FFN_whole , train_losses_whole, test_losses_whole = train(model_FFN_whole, criterion, optimizer_whole, loader_train, loader_test, n_epochs)\n"
      ],
      "metadata": {
        "id": "XXhL658rVs8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3afa9c19-b5e4-4e7f-b577-cc1c7f6a105d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN_relu(\n",
            "  (linear1): Linear(in_features=18, out_features=180, bias=True)\n",
            "  (linear2): Linear(in_features=180, out_features=360, bias=True)\n",
            "  (linear3): Linear(in_features=360, out_features=360, bias=True)\n",
            "  (linear4): Linear(in_features=360, out_features=180, bias=True)\n",
            "  (linear5): Linear(in_features=180, out_features=18, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if train_FFN is True:\n",
        "\n",
        "  # Show results of the loss function whole\n",
        "\n",
        "  fig = plt.figure(figsize = (10,10))\n",
        "\n",
        "  ax = fig.add_subplot(111)\n",
        "  plt.ion()\n",
        "\n",
        "  fig.show()\n",
        "  fig.canvas.draw()\n",
        "\n",
        "  baseline = [np.mean(losses_train) for i in range(len(train_losses_whole))]\n",
        "\n",
        "  ax.plot(baseline, label='Baseline')\n",
        "  ax.plot([np.mean(i) for i in train_losses_whole], label= 'Train_loss')\n",
        "  ax.plot([np.mean(i) for i in test_losses_whole], label= 'Test_loss')\n",
        "  ax.set_title(\"Full Forward Neural Network (Whole dataset)\")\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.set_ylabel('Mean Squared Error')\n",
        "  ax.legend()\n",
        "  fig.canvas.draw()"
      ],
      "metadata": {
        "id": "7kSeRG2ILQ65"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We do the same process with the Weekend dataset and the Weekdays dataset, to see if its any improve taking only those datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "HbE_EzsRLT0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader_train_weekdays, loader_test_weekdays = create_dataloaders(dataset_weekdays_norm)\n",
        "loader_train_weekend, loader_test_weekend = create_dataloaders(dataset_weekend_norm)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "losses_train_weekdays = []\n",
        "\n",
        "for i in loader_train_weekdays:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_train_weekdays.append(loss.item())\n",
        "\n",
        "losses_test_weekend = []\n",
        "\n",
        "for i in loader_test_weekend:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_test_weekend.append(loss.item())\n",
        "\n",
        "print(\"Training set\")\n",
        "print(\"Mean Loss of baselinemodel Weekdays: \", np.mean(losses_train_weekdays))\n",
        "print(\"Standard deviation Loss of baselinemodel Weekdays: \", np.std(losses_train_weekdays))\n",
        "print('\\n')\n",
        "print(\"Test set\")\n",
        "print(\"Mean Loss of baselinemodel Weekend: \", np.mean(losses_test_weekend))\n",
        "print(\"Standard deviation Loss of baselinemodel Weekend: \", np.std(losses_test_weekend))\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "YIq_bRl3GkCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77e4c01a-75ec-4932-915c-f4d237ad6983"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29791/29791 [00:09<00:00, 3014.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set (whole dataset): 26811\n",
            "length of test set (whole dataset): 2980\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33567/33567 [00:13<00:00, 2558.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set (whole dataset): 30210\n",
            "length of test set (whole dataset): 3357\n",
            "\n",
            "\n",
            "Training set\n",
            "Mean Loss of baselinemodel Weekdays:  0.4248717778266757\n",
            "Standard deviation Loss of baselinemodel Weekdays:  0.11051199594606315\n",
            "\n",
            "\n",
            "Test set\n",
            "Mean Loss of baselinemodel Weekend:  0.761363573794095\n",
            "Standard deviation Loss of baselinemodel Weekend:  0.13065155490701008\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 50\n",
        "lr=0.01\n",
        "\n",
        "# Create model FFN instance\n",
        "model_FFN_weekday = ANN_relu(18, 18).to(device)\n",
        "print(model_FFN_weekday)\n",
        "\n",
        "# Define Loss\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer_weekday = torch.optim.SGD(model_FFN_weekday.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "train_FFN = False\n",
        "\n",
        "params_not_trained_weekday = model_FFN_weekday.parameters()\n",
        "\n",
        "if train_FFN is True:\n",
        "  trained_model_FFN_weekday , train_losses_weekday, test_losses_weekday = train(model_FFN_weekday, criterion, optimizer_weekday, loader_train_weekdays, loader_test_weekdays, n_epochs)\n",
        "\n",
        "\n",
        "n_epochs = 50\n",
        "lr=0.01\n",
        "\n",
        "# Create model FFN instance\n",
        "model_FFN_weekend = ANN_relu(18, 18).to(device)\n",
        "print(model_FFN_weekend)\n",
        "\n",
        "# Define Loss\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer_weekend = torch.optim.SGD(model_FFN_weekend.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "train_FFN = False\n",
        "\n",
        "params_not_trained_weekend = model_FFN_weekend.parameters()\n",
        "\n",
        "if train_FFN is True:\n",
        "  trained_model_FFN_weekend , train_losses_weekend, test_losses_weekend = train(model_FFN_weekend, criterion, optimizer_weekend, loader_train_weekend, loader_test_weekend, n_epochs)"
      ],
      "metadata": {
        "id": "ssGQuSMwGwsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "686a304e-b601-4e42-f944-cf7a8c043179"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN_relu(\n",
            "  (linear1): Linear(in_features=18, out_features=180, bias=True)\n",
            "  (linear2): Linear(in_features=180, out_features=360, bias=True)\n",
            "  (linear3): Linear(in_features=360, out_features=360, bias=True)\n",
            "  (linear4): Linear(in_features=360, out_features=180, bias=True)\n",
            "  (linear5): Linear(in_features=180, out_features=18, bias=True)\n",
            ")\n",
            "ANN_relu(\n",
            "  (linear1): Linear(in_features=18, out_features=180, bias=True)\n",
            "  (linear2): Linear(in_features=180, out_features=360, bias=True)\n",
            "  (linear3): Linear(in_features=360, out_features=360, bias=True)\n",
            "  (linear4): Linear(in_features=360, out_features=180, bias=True)\n",
            "  (linear5): Linear(in_features=180, out_features=18, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if train_FFN is True:\n",
        "\n",
        "  # Show results of the loss function weekdays\n",
        "\n",
        "  fig = plt.figure(figsize = (10,10))\n",
        "\n",
        "  ax = fig.add_subplot(111)\n",
        "  plt.ion()\n",
        "\n",
        "  fig.show()\n",
        "  fig.canvas.draw()\n",
        "\n",
        "  baseline = [np.mean(losses_train_weekdays) for i in range(len(train_losses_weekday))]\n",
        "\n",
        "  ax.plot(baseline, label='Baseline')\n",
        "  ax.plot([np.mean(i) for i in train_losses_weekday], label= 'Train_loss')\n",
        "  ax.plot([np.mean(i) for i in test_losses_weekday], label= 'Test_loss')\n",
        "  ax.set_title(\"Full Forward Neural Network (Weekday dataset)\")\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.set_ylabel('Mean Squared Error')\n",
        "  ax.legend()\n",
        "  fig.canvas.draw()\n",
        "\n",
        "  # Show results of the loss function weekends\n",
        "\n",
        "  fig = plt.figure(figsize = (10,10))\n",
        "\n",
        "  ax = fig.add_subplot(111)\n",
        "  plt.ion()\n",
        "\n",
        "  fig.show()\n",
        "  fig.canvas.draw()\n",
        "\n",
        "  baseline = [np.mean(losses_train_weekend) for i in range(len(train_losses_weekend))]\n",
        "\n",
        "  ax.plot(baseline, label='Baseline')\n",
        "  ax.plot([np.mean(i) for i in train_losses_weekend], label= 'Train_loss')\n",
        "  ax.plot([np.mean(i) for i in test_losses_weekend], label= 'Test_loss')\n",
        "  ax.set_title(\"Full Forward Neural Network (Weekend dataset)\")\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.set_ylabel('Mean Squared Error')\n",
        "  ax.legend()\n",
        "  fig.canvas.draw()"
      ],
      "metadata": {
        "id": "Lw2ntQMUafOF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions FFN\n",
        "\n",
        "We can see that using the weekends or weekdays dataset doesn't bring any improvement. Therefore we can forget them and use only the whole dataset for the next models."
      ],
      "metadata": {
        "id": "nzJPbmTPOleH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Model\n",
        "\n",
        "We train before a standard RNN and see which results we can expected with a small and easy solution.\n",
        "I am using this template (https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb) and make changes using it as a base.\n",
        "\n",
        "1) torch.nn.RNN (https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)\n",
        "\n",
        "Parameters\n",
        "* input_size – The number of expected features in the input x\n",
        "* hidden_size – The number of features in the hidden state h\n",
        "* num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1\n",
        "* nonlinearity – The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'\n",
        "* bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
        "* batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: False\n",
        "* dropout – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
        "* bidirectional – If True, becomes a bidirectional RNN. Default: False\n",
        "\n",
        "2) torch.nn.Linear (https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
        "\n",
        "Parameters\n",
        "* in_features – size of each input sample\n",
        "* out_features – size of each output sample\n",
        "* bias – If set to False, the layer will not learn an additive bias. Default: True\n"
      ],
      "metadata": {
        "id": "wLCXaTbSsHRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequece_dataloaders(dataset_norm):\n",
        "\n",
        "  # Create a dataset with pairs data / Target (in this case data is one sequence of 30 measures (18 features) and target are the next sequence of 30 \n",
        "  # measures (18 features)). When you plug in one measure, the model should out the next measure\n",
        "\n",
        "  pair_set = []\n",
        "\n",
        "  for i in tqdm(range(len(dataset_norm) - 60)):\n",
        "    data = np.array(dataset_norm.iloc[i:i+30, 1:])\n",
        "    target = np.array(dataset_norm.iloc[i+30:i+60, 1:])\n",
        "    \n",
        "    pair_set.append((data, target))\n",
        "\n",
        "  dataset_pairs = np.array(pair_set)\n",
        "\n",
        "  training_data_pairs, testing_data_pairs = train_test_split(dataset_pairs, test_size=0.1, random_state=25)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in training_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  training_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  training_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in testing_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  test_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  test_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  print(f'length of training set (whole dataset): {training_data.shape[0]}')\n",
        "  print(f'length of test set (whole dataset): {test_data.shape[0]}')\n",
        "  print('\\n')\n",
        "\n",
        "  # Create data loader to feed the FFN in mini batches\n",
        "\n",
        "  loader_train = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(training_data, training_target),\n",
        "      batch_size=30,\n",
        "      shuffle=False\n",
        "  )\n",
        "\n",
        "  # Create data loader for testing the model\n",
        "  loader_test = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(test_data, test_target),\n",
        "      batch_size=30,\n",
        "      shuffle=False\n",
        "  )\n",
        "\n",
        "  return loader_train, loader_test"
      ],
      "metadata": {
        "id": "eGr5DfpAQ25U"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_train, loader_test = create_sequece_dataloaders(dataset_norm)"
      ],
      "metadata": {
        "id": "sQbJaAtaRBUM",
        "outputId": "cdb08d31-ea68-4fdd-f287-e7bc19d10948",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63300/63300 [00:20<00:00, 3146.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set (whole dataset): 56970\n",
            "length of test set (whole dataset): 6330\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers, seq_length, device, batch_first = True, dropout = 0):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.device = device\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_size = hidden_dim, num_layers = n_layers, batch_first = batch_first, nonlinearity='relu', dropout = dropout)   \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim*seq_length, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        h0 = torch.zeros(self.n_layers, x.size(0), self.hidden_dim).to(device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out.reshape(out.shape[0], -1)\n",
        "        out = self.fc(out)\n",
        "      \n",
        "        return out\n"
      ],
      "metadata": {
        "id": "VOL1v_mjsEDe"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_RNN(model, criterion, optimizer, train_loader, test_loader, n_epochs):\n",
        "\n",
        "  epoch_loss_train = []\n",
        "  epoch_loss_test = []\n",
        "\n",
        "  # Training Run\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "    print('\\nTraining:')\n",
        "    print(f'Epoch {epoch}')\n",
        "\n",
        "    for batch in tqdm(train_loader):\n",
        "\n",
        "      data = batch[0]\n",
        "      targets = batch[1]\n",
        "\n",
        "      print(data.size())\n",
        "\n",
        "      data = data.to(device).squeeze(1)\n",
        "      print(data.size())\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      output = model(data)\n",
        "      loss = criterion (output, targets)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(train_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        output, hidden = model(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_train.append (float(criterion(output, target).item()))\n",
        "\n",
        "    print('\\nTest with test set')\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(test_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        output, hidden = model(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_test.append (float(criterion(output, target).item()))\n",
        "\n",
        "\n",
        "    print('\\nCurrent Mean loss Train Set: ', np.mean(losses_train))\n",
        "    epoch_loss_train.append(np.mean(losses_train))\n",
        "\n",
        "    print('\\nCurrent Mean loss Test Set: ', np.mean(losses_test))\n",
        "    epoch_loss_test.append(np.mean(losses_test))\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "  return epoch_loss_train, epoch_loss_test, model"
      ],
      "metadata": {
        "id": "IzAT4IPPwfZx"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model with hyperparameters\n",
        "model_rnn = RNN(input_size = 18,\n",
        "                output_size = 18,\n",
        "                seq_length= 30,\n",
        "                hidden_dim = 64,\n",
        "                n_layers = 1,\n",
        "                batch_first = True,\n",
        "                dropout = 0,\n",
        "                device = device)\n",
        "\n",
        "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
        "model_rnn = model_rnn.to(device)\n",
        "\n",
        "# Define hyperparameters\n",
        "n_epochs = 50\n",
        "lr=0.01\n",
        "\n",
        "# Define Loss, Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model_rnn.parameters(), lr=lr)\n",
        "\n",
        "train_RNN = True\n",
        "\n",
        "if train_RNN is True:\n",
        "  train_losses, test_losses, trained_model_RNN = training_RNN(model_rnn, criterion, optimizer, loader_train, loader_test, n_epochs)"
      ],
      "metadata": {
        "id": "kZQzvqz0aU5r",
        "outputId": "91e6b262-fec9-414d-de69-1811bf924821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training:\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1899 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([30, 30, 18])) that is different to the input size (torch.Size([30, 18])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "  2%|▏         | 33/1899 [00:00<00:05, 324.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 66/1899 [00:00<00:05, 326.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 99/1899 [00:00<00:05, 320.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▊         | 166/1899 [00:00<00:05, 318.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 232/1899 [00:00<00:05, 316.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 298/1899 [00:00<00:04, 321.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 364/1899 [00:01<00:04, 318.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 431/1899 [00:01<00:04, 327.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 498/1899 [00:01<00:04, 325.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 564/1899 [00:01<00:04, 322.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 630/1899 [00:01<00:03, 323.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 695/1899 [00:02<00:03, 319.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 760/1899 [00:02<00:03, 319.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▎     | 828/1899 [00:02<00:03, 326.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 894/1899 [00:02<00:03, 320.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 961/1899 [00:02<00:02, 323.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n",
            "torch.Size([30, 30, 18])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 970/1899 [00:03<00:02, 320.17it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-f178a6bdfa75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain_RNN\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_model_RNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_RNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-3eb0a780d534>\u001b[0m in \u001b[0;36mtraining_RNN\u001b[0;34m(model, criterion, optimizer, train_loader, test_loader, n_epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if train_RNN is True:\n",
        "\n",
        "  # Show results of the loss function\n",
        "\n",
        "  fig = plt.figure()\n",
        "\n",
        "  ax = fig.add_subplot(111)\n",
        "  plt.ion()\n",
        "\n",
        "  fig.show()\n",
        "  fig.canvas.draw()\n",
        "\n",
        "  baseline = [np.mean(losses_train) for i in range(len(train_losses))]\n",
        "\n",
        "  ax.plot(baseline)\n",
        "  ax.plot([np.mean(i) for i in train_losses])\n",
        "  ax.plot([np.mean(i) for i in test_losses])\n",
        "  ax.set_title(\"Mean Squared Error RNN\")\n",
        "  fig.canvas.draw()"
      ],
      "metadata": {
        "id": "989Pq-hNLX7r"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last basemodel i am going to use is a simple RNN. The final model should also have a better performance than this RNN."
      ],
      "metadata": {
        "id": "Y93gczvmqiT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequece_dataloaders(dataset_norm):\n",
        "\n",
        "  # Create a dataset with pairs data / Target (in this case data is one sequence of 30 measures (18 features) and target are the next sequence of 30 \n",
        "  # measures (18 features)). When you plug in one measure, the model should out the next measure\n",
        "\n",
        "  pair_set = []\n",
        "\n",
        "  for i in tqdm(range(len(dataset_norm) - 60)):\n",
        "    data = np.array(dataset_norm.iloc[i:i+30, 1:])\n",
        "    target = np.array(dataset_norm.iloc[i+30:i+60, 1:])\n",
        "    \n",
        "    pair_set.append((data, target))\n",
        "\n",
        "  dataset_pairs = np.array(pair_set)\n",
        "\n",
        "  training_data_pairs, testing_data_pairs = train_test_split(dataset_pairs, test_size=0.1, random_state=25)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in training_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  training_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  training_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in testing_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  test_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  test_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  print(f'length of training set (whole dataset): {training_data.shape[0]}')\n",
        "  print(f'length of test set (whole dataset): {test_data.shape[0]}')\n",
        "  print('\\n')\n",
        "\n",
        "  # Create data loader to feed the FFN in mini batches\n",
        "\n",
        "  loader_train = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(training_data, training_target),\n",
        "      batch_size=15,\n",
        "      shuffle=False\n",
        "  )\n",
        "\n",
        "  # Create data loader for testing the model\n",
        "  loader_test = torch.utils.data.DataLoader(\n",
        "      dataset=torch.utils.data.TensorDataset(test_data, test_target),\n",
        "      batch_size=15,\n",
        "      shuffle=False\n",
        "  )\n",
        "\n",
        "  return loader_train, loader_test"
      ],
      "metadata": {
        "id": "6E3nOOEDkOCp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_train, loader_test = create_sequece_dataloaders(dataset_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loolRFt_jhgV",
        "outputId": "2c69208b-ce75-4371-998c-0925a7d2e5a9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63300/63300 [00:19<00:00, 3205.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set (whole dataset): 56970\n",
            "length of test set (whole dataset): 6330\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "\n",
        "losses_train = []\n",
        "\n",
        "for i in loader_train:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_train.append(loss.item())\n",
        "\n",
        "losses_test = []\n",
        "\n",
        "for i in loader_test:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_test.append(loss.item())\n",
        "\n",
        "print(\"Training set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_train))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_train))\n",
        "print('\\n')\n",
        "print(\"Test set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_test))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_test))\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeZYKAbqkvUY",
        "outputId": "08d6b279-e66a-4838-d6cd-44a9f0528530"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set\n",
            "Mean Loss of baselinemodel:  0.7443867036312615\n",
            "Standard deviation Loss of baselinemodel:  0.11228539154408188\n",
            "\n",
            "\n",
            "Test set\n",
            "Mean Loss of baselinemodel:  0.750549325445817\n",
            "Standard deviation Loss of baselinemodel:  0.10785673408274579\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXX8lu3jjDhr"
      },
      "source": [
        "# Transformer Model settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dUCsWWo292_"
      },
      "source": [
        "Now, we define a class with the transformer model that we are going to use:\n",
        "\n",
        "Using the already written pytorch library for Transformers:\n",
        "\n",
        "1) torch.nn.TransformerEncoderLayer (https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html)\n",
        "\n",
        "*   d_model –> the number of expected features in the input (required).\n",
        "*   nhead –> the number of heads in the multiheadattention models (required).\n",
        "*   dropout –> the dropout value (default=0.1).\n",
        "*   activation –> the activation function of the intermediate layer, can be a string (“relu” or “gelu”) or a unary callable. (default: relu)\n",
        "*   layer_norm_eps –> the eps value in layer normalization components (default=1e-5).\n",
        "*   batch_first –> If True, then the input and output tensors are provided as (batch, seq, feature). (default: False)\n",
        "*   norm_first –> if True, layer norm is done prior to attention and feedforward operations, respectivaly. Otherwise it’s done after. (default: False (after))\n",
        "\n",
        "2) torch.nn.TransformerDecoderLayer\n",
        "\n",
        "* d_model –> the number of expected features in the input (required).\n",
        "* nhead –> the number of heads in the multiheadattention models (required).\n",
        "* dim_feedforward –> the dimension of the feedforward network model (default=2048).\n",
        "* dropout –> the dropout value (default=0.1).\n",
        "* activation –> the activation function of the intermediate layer, can be a string (“relu” or “gelu”) or a unary callable. Default: relu\n",
        "* layer_norm_eps –> the eps value in layer normalization components (default=1e-5).\n",
        "* batch_first –> If True, then the input and output tensors are provided as (batch, seq, feature). Default: False.\n",
        "* norm_first –> if True, layer norm is done prior to self attention, multihead attention and feedforward operations, respectivaly. Otherwise it’s done after. Default: False (after).\n",
        "\n",
        "3) torch.nn.TransformerEncoder\n",
        "\n",
        "* encoder_layer –> an instance of the TransformerEncoderLayer() class (required).\n",
        "* num_layers –> the number of sub-encoder-layers in the encoder (required).\n",
        "* norm –> the layer normalization component (optional).\n",
        "\n",
        "\n",
        "4) torch.nn.TransformerDecoder\n",
        "\n",
        "* decoder_layer – an instance of the TransformerDecoderLayer() class (required).\n",
        "* num_layers – the number of sub-decoder-layers in the decoder (required).\n",
        "* norm – the layer normalization component (optional).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "tCC_Bava293A",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def positional_encoding(seq_len: int, dim_model: int, device):\n",
        "    \n",
        "    # Tensor with the positions of every sequence element (0 to seq_len)\n",
        "    pos = torch.arange(seq_len, dtype=float32, device=device).reshape(1, -1, 1)\n",
        "    \n",
        "    # Tensor with the positions of every feature in the sequence (0 to dim_model)\n",
        "    dim = torch.arange(dim_model, dtype=float32, device=device).reshape(1, 1, -1)\n",
        "\n",
        "    phase = pos / (1e4 ** (torch.div(dim, dim_model, rounding_mode='floor')))\n",
        "\n",
        "    position_encoding = torch.where(dim.long() % 2 == 0, sin(phase), cos(phase))\n",
        "\n",
        "    return position_encoding.to(device)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, feature_size, output_size, num_encoder_layers, num_heads, num_decoder_layers, device, dropout: float =0.1, batch_first: bool = False):\n",
        "        super(Transformer, self).__init__()\n",
        "        \n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model= feature_size, nhead= num_heads, dropout=dropout, device=device, batch_first=batch_first)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model= feature_size, nhead= num_heads, dropout=dropout, device=device, batch_first=batch_first)\n",
        "        \n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers= num_encoder_layers)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers= num_decoder_layers)\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.device = device\n",
        "\n",
        "    def generate_square_mask(self, dim):\n",
        "        return torch.triu(torch.ones(dim, dim) * float('-inf'), diagonal=1).to(self.device)\n",
        "        \n",
        "    def forward (self, src):\n",
        "        \n",
        "        mask = self.generate_square_mask(len(src))\n",
        "\n",
        "        #src_pos = src + positional_encoding(src.shape[1], src.shape[2], self.device)\n",
        "\n",
        "        output = self.encoder (src, mask)\n",
        "        \n",
        "        output = self.decoder (src, output, mask)\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should define an optimizer too.\n",
        "For this, we use the pytorch library:\n",
        "\n",
        "* SGD –> Stochastic gradient descent.\n",
        "\n",
        "1) torch.optim.SDG (https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)\n",
        "\n",
        "* params (iterable) – iterable of parameters to optimize or dicts defining parameter groups\n",
        "* lr (float) – learning rate\n",
        "* momentum (float, optional) – momentum factor (default: 0)\n",
        "* weight_decay (float, optional) – weight decay (L2 penalty) (default: 0)\n",
        "* dampening (float, optional) – dampening for momentum (default: 0)\n",
        "* nesterov (bool, optional) – enables Nesterov momentum (default: False)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8EANo5UFE15A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_transformer(model, optimizer, criterion, train_loader, test_loader, n_epochs):\n",
        "  epoch_loss_train = []\n",
        "  epoch_loss_test = []\n",
        "\n",
        "  for e in range(1, n_epochs + 1):\n",
        "\n",
        "    print(f'Epoch: {e} of {n_epochs}')\n",
        "\n",
        "    print('Training:')\n",
        "    model.train()\n",
        "\n",
        "    for i in tqdm(train_loader):\n",
        "\n",
        "      # Initialize optimizer gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      input = i[0]\n",
        "\n",
        "      target = i[1]\n",
        "\n",
        "      net_out = model.forward(input)\n",
        "\n",
        "      #Compute loss\n",
        "      loss = criterion(net_out, target)\n",
        "\n",
        "      #Backpropagation\n",
        "      loss.backward()\n",
        "\n",
        "      #Optimization\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    losses_train = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(train_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        net_out = model.forward(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_train.append (float(criterion(net_out, target).item()))\n",
        "\n",
        "    \n",
        "    print('\\nCurrent Mean loss Train Set: ', np.mean(losses_train))\n",
        "    epoch_loss_train.append(losses_train)\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    losses_test = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(test_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        net_out = model.forward(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_test.append (float(criterion(net_out, target).item()))\n",
        "\n",
        "    print('\\nCurrent Mean loss Test Set: ', np.mean(losses_test))\n",
        "    epoch_loss_test.append(losses_test)\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "  return model, epoch_loss_train, epoch_loss_test"
      ],
      "metadata": {
        "id": "SZ8UZSHPQLT5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup model Ok\n",
            "Setup optimizer Ok\n",
            "Epoch: 1 of 50\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 1408/3798 [00:24<00:42, 56.59it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-26ed60183b8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain_transformer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mtrained_model_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-efe2077d6e12>\u001b[0m in \u001b[0;36mtraining_transformer\u001b[0;34m(model, optimizer, criterion, train_loader, test_loader, n_epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mnet_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;31m#Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-041dc401cab4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#src_pos = src + positional_encoding(src.shape[1], src.shape[2], self.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Initialize Transformer Model and Optimizer\n",
        "\n",
        "model_transformer = Transformer (num_encoder_layers=3,\n",
        "                     num_decoder_layers=3,\n",
        "                     feature_size=18,\n",
        "                     output_size=18,\n",
        "                     num_heads=3,\n",
        "                     device = device,\n",
        "                     batch_first=False)\n",
        "\n",
        "n_epochs = 50\n",
        "\n",
        "print('Setup model Ok')\n",
        "\n",
        "optimizer = torch.optim.Adam(model_transformer.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print('Setup optimizer Ok')\n",
        "\n",
        "\n",
        "train_transformer = True\n",
        "\n",
        "if train_transformer is True:\n",
        "  trained_model_transformer, train_losses, test_losses = training_transformer(model_transformer, optimizer, criterion, loader_train, loader_test, n_epochs)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Muhz9Q2qjDhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "9d058b42-71ef-4bd1-9923-57a4b1776042"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgrbFBLS293A",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if train_transformer is True:\n",
        "\n",
        "  # Show results of the loss function\n",
        "\n",
        "  fig = plt.figure()\n",
        "\n",
        "  ax = fig.add_subplot(111)\n",
        "  plt.ion()\n",
        "\n",
        "  fig.show()\n",
        "  fig.canvas.draw()\n",
        "\n",
        "  baseline = [np.mean(losses_train) for i in range(len(train_losses))]\n",
        "\n",
        "  ax.plot(baseline)\n",
        "  ax.plot([np.mean(i) for i in train_losses])\n",
        "  ax.plot([np.mean(i) for i in test_losses])\n",
        "  ax.set_title(\"Mean Squared Error RNN\")\n",
        "  fig.canvas.draw()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequece_pairs(dataset_norm):\n",
        "\n",
        "  # Create a dataset with pairs data / Target (in this case data is one sequence of 30 measures (18 features) and target are the next sequence of 30 \n",
        "  # measures (18 features)). When you plug in one measure, the model should out the next measure\n",
        "\n",
        "  pair_set = []\n",
        "\n",
        "  for i in tqdm(range(len(dataset_norm) - 60)):\n",
        "    data = np.array(dataset_norm.iloc[i:i+30, 1:])\n",
        "    target = np.array(dataset_norm.iloc[i+30:i+60, 1:])\n",
        "    \n",
        "    pair_set.append((data, target))\n",
        "\n",
        "  dataset_pairs = np.array(pair_set)\n",
        "\n",
        "  training_data_pairs, testing_data_pairs = train_test_split(dataset_pairs, test_size=0.1, random_state=25)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in training_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  training_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  training_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  data = []\n",
        "  target = []\n",
        "  for i in testing_data_pairs:\n",
        "    data.append(i[0])\n",
        "    target.append(i[1])\n",
        "\n",
        "  test_data = torch.from_numpy(np.array(data)).float().to(device)\n",
        "  test_target = torch.from_numpy(np.array(target)).float().to(device)\n",
        "\n",
        "  return (training_data, training_target), (test_data, test_target)"
      ],
      "metadata": {
        "id": "cEOlIPX4EcA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pairs, test_pairs = create_sequece_pairs(dataset_norm)"
      ],
      "metadata": {
        "id": "0NyICzR4EpUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_pairs))\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "losses_train = []\n",
        "\n",
        "for i in train_pairs:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_train.append(loss.item())\n",
        "\n",
        "losses_test = []\n",
        "\n",
        "for i in test_pairs:\n",
        "  output = i[0]\n",
        "  target = i[1]\n",
        "  loss = criterion(output, target)\n",
        "  losses_test.append(loss.item())\n",
        "\n",
        "print(\"Training set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_train))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_train))\n",
        "print('\\n')\n",
        "print(\"Test set\")\n",
        "print(\"Mean Loss of baselinemodel: \", np.mean(losses_test))\n",
        "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_test))\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "a5-laMb6Dngn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_transformer(model, optimizer, criterion, train_loader, test_loader, n_epochs):\n",
        "  epoch_loss_train = []\n",
        "  epoch_loss_test = []\n",
        "\n",
        "  for e in range(1, n_epochs + 1):\n",
        "\n",
        "    print(f'Epoch: {e} of {n_epochs}')\n",
        "\n",
        "    print('Training:')\n",
        "    model.train()\n",
        "\n",
        "    for i in tqdm(train_loader):\n",
        "\n",
        "      # Initialize optimizer gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      input = i[0]\n",
        "\n",
        "      target = i[1]\n",
        "\n",
        "      net_out = model.forward(input)\n",
        "\n",
        "      #Compute loss\n",
        "      loss = criterion(net_out, target)\n",
        "\n",
        "      #Backpropagation\n",
        "      loss.backward()\n",
        "\n",
        "      #Optimization\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    losses_train = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(train_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        net_out = model.forward(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_train.append (float(criterion(net_out, target).item()))\n",
        "\n",
        "    \n",
        "    print('\\nCurrent Mean loss Train Set: ', np.mean(losses_train))\n",
        "    epoch_loss_train.append(losses_train)\n",
        "\n",
        "    print('\\nTest with training set')\n",
        "    losses_test = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in tqdm(test_loader):\n",
        "        input = i[0]\n",
        "        target = i[1]\n",
        "\n",
        "        net_out = model.forward(input)\n",
        "\n",
        "        #Compute loss\n",
        "        losses_test.append (float(criterion(net_out, target).item()))\n",
        "\n",
        "    print('\\nCurrent Mean loss Test Set: ', np.mean(losses_test))\n",
        "    epoch_loss_test.append(losses_test)\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "  return model, epoch_loss_train, epoch_loss_test"
      ],
      "metadata": {
        "id": "ZrzzO5EECjJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Transformer Model and Optimizer\n",
        "\n",
        "model_transformer = Transformer (num_encoder_layers=3,\n",
        "                     num_decoder_layers=3,\n",
        "                     feature_size=18,\n",
        "                     output_size=18,\n",
        "                     num_heads=3,\n",
        "                     device = device,\n",
        "                     batch_first=False)\n",
        "\n",
        "\n",
        "print('Setup model Ok')\n",
        "\n",
        "n_epochs = 50\n",
        "optimizer = torch.optim.Adam(model_transformer.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print('Setup optimizer Ok')\n",
        "\n",
        "print(train_pairs[0].shape)\n",
        "\n",
        "train_transformer = True\n",
        "\n",
        "if train_transformer is True:\n",
        "  trained_model_transformer, train_losses, test_losses = training_transformer(model_transformer, optimizer, criterion, train_pairs, test_pairs, n_epochs)"
      ],
      "metadata": {
        "id": "m2Vy5m7GCqvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS8DcLC-293B"
      },
      "source": [
        "Ideas, things to remember, to search, etc...\n",
        "\n",
        "reconstruction, vergelich mit base line model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "bsc_arbeit.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python392jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}